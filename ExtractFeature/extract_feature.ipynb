{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      "SEQ_ID            1000 non-null int64\n",
      "PATIENT_ID        1000 non-null int64\n",
      "PATIENT_NO        1000 non-null object\n",
      "INPATIENT_NO      1000 non-null int64\n",
      "INDEX2            0 non-null float64\n",
      "PARENTNODENAME    1000 non-null object\n",
      "SOURCEDATA        1000 non-null object\n",
      "NODENAME          1000 non-null object\n",
      "NODEVALUE         1000 non-null object\n",
      "HOSPITAL_CODE     1000 non-null object\n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 78.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQ_ID</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>PATIENT_NO</th>\n",
       "      <th>INPATIENT_NO</th>\n",
       "      <th>INDEX2</th>\n",
       "      <th>PARENTNODENAME</th>\n",
       "      <th>SOURCEDATA</th>\n",
       "      <th>NODENAME</th>\n",
       "      <th>NODEVALUE</th>\n",
       "      <th>HOSPITAL_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12409215</td>\n",
       "      <td>617387</td>\n",
       "      <td>10036263</td>\n",
       "      <td>722318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>住院病历\\现病史</td>\n",
       "      <td>患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...</td>\n",
       "      <td>经常咳嗽_稳定期</td>\n",
       "      <td>有</td>\n",
       "      <td>12150000460028258G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12409215</td>\n",
       "      <td>617387</td>\n",
       "      <td>10036263</td>\n",
       "      <td>722318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>住院病历\\现病史</td>\n",
       "      <td>患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...</td>\n",
       "      <td>双下肢水肿_加重期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>12150000460028258G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12409215</td>\n",
       "      <td>617387</td>\n",
       "      <td>10036263</td>\n",
       "      <td>722318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>住院病历\\现病史</td>\n",
       "      <td>患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...</td>\n",
       "      <td>经常胸闷_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>12150000460028258G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12409215</td>\n",
       "      <td>617387</td>\n",
       "      <td>10036263</td>\n",
       "      <td>722318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>住院病历\\现病史</td>\n",
       "      <td>患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...</td>\n",
       "      <td>经常活动后气促_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>12150000460028258G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12409215</td>\n",
       "      <td>617387</td>\n",
       "      <td>10036263</td>\n",
       "      <td>722318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>住院病历\\现病史</td>\n",
       "      <td>患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...</td>\n",
       "      <td>经常咳痰_稳定期</td>\n",
       "      <td>有</td>\n",
       "      <td>12150000460028258G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SEQ_ID  PATIENT_ID PATIENT_NO  INPATIENT_NO  INDEX2 PARENTNODENAME  \\\n",
       "0  12409215      617387   10036263        722318     NaN       住院病历\\现病史   \n",
       "1  12409215      617387   10036263        722318     NaN       住院病历\\现病史   \n",
       "2  12409215      617387   10036263        722318     NaN       住院病历\\现病史   \n",
       "3  12409215      617387   10036263        722318     NaN       住院病历\\现病史   \n",
       "4  12409215      617387   10036263        722318     NaN       住院病历\\现病史   \n",
       "\n",
       "                                          SOURCEDATA     NODENAME NODEVALUE  \\\n",
       "0  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常咳嗽_稳定期         有   \n",
       "1  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...    双下肢水肿_加重期       未提及   \n",
       "2  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常胸闷_稳定期       未提及   \n",
       "3  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...  经常活动后气促_稳定期       未提及   \n",
       "4  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常咳痰_稳定期         有   \n",
       "\n",
       "        HOSPITAL_CODE  \n",
       "0  12150000460028258G  \n",
       "1  12150000460028258G  \n",
       "2  12150000460028258G  \n",
       "3  12150000460028258G  \n",
       "4  12150000460028258G  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sourceData_01 = pd.read_csv('./现病史20190114内蒙古100患者.csv')\n",
    "print(df_sourceData_01.info())\n",
    "df_sourceData_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1008 entries, 0 to 1007\n",
      "Data columns (total 10 columns):\n",
      "SEQ_ID            1008 non-null int64\n",
      "PATIENT_ID        544 non-null object\n",
      "PATIENT_NO        1008 non-null object\n",
      "INPATIENT_NO      1008 non-null int64\n",
      "INDEX2            1008 non-null object\n",
      "PARENTNODENAME    1008 non-null object\n",
      "SOURCEDATA        1008 non-null object\n",
      "NODENAME          1008 non-null object\n",
      "NODEVALUE         1008 non-null object\n",
      "HOSPITAL_CODE     1000 non-null float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 78.8+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQ_ID</th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>PATIENT_NO</th>\n",
       "      <th>INPATIENT_NO</th>\n",
       "      <th>INDEX2</th>\n",
       "      <th>PARENTNODENAME</th>\n",
       "      <th>SOURCEDATA</th>\n",
       "      <th>NODENAME</th>\n",
       "      <th>NODEVALUE</th>\n",
       "      <th>HOSPITAL_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3F2DF800C38BE92687B4D5EA9F207C52</td>\n",
       "      <td>1074211</td>\n",
       "      <td>陈锦欢</td>\n",
       "      <td>入院记录\\病史\\现病史</td>\n",
       "      <td>患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...</td>\n",
       "      <td>经常咳嗽_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>1.240000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3F2DF800C38BE92687B4D5EA9F207C52</td>\n",
       "      <td>1074211</td>\n",
       "      <td>陈锦欢</td>\n",
       "      <td>入院记录\\病史\\现病史</td>\n",
       "      <td>患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...</td>\n",
       "      <td>经常喘息_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>1.240000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>731177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3F2DF800C38BE92687B4D5EA9F207C52</td>\n",
       "      <td>1074211</td>\n",
       "      <td>陈锦欢</td>\n",
       "      <td>入院记录\\病史\\现病史</td>\n",
       "      <td>患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...</td>\n",
       "      <td>经常胸闷_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>1.240000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3F2DF800C38BE92687B4D5EA9F207C52</td>\n",
       "      <td>1074211</td>\n",
       "      <td>陈锦欢</td>\n",
       "      <td>入院记录\\病史\\现病史</td>\n",
       "      <td>患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...</td>\n",
       "      <td>经常活动后气促_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>1.240000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3F2DF800C38BE92687B4D5EA9F207C52</td>\n",
       "      <td>1074211</td>\n",
       "      <td>陈锦欢</td>\n",
       "      <td>入院记录\\病史\\现病史</td>\n",
       "      <td>患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...</td>\n",
       "      <td>经常咳痰_稳定期</td>\n",
       "      <td>未提及</td>\n",
       "      <td>1.240000e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEQ_ID PATIENT_ID                        PATIENT_NO  INPATIENT_NO INDEX2  \\\n",
       "0  731177        NaN  3F2DF800C38BE92687B4D5EA9F207C52       1074211    陈锦欢   \n",
       "1  731177        NaN  3F2DF800C38BE92687B4D5EA9F207C52       1074211    陈锦欢   \n",
       "2  731177        NaN  3F2DF800C38BE92687B4D5EA9F207C52       1074211    陈锦欢   \n",
       "3  731177        NaN  3F2DF800C38BE92687B4D5EA9F207C52       1074211    陈锦欢   \n",
       "4  731177        NaN  3F2DF800C38BE92687B4D5EA9F207C52       1074211    陈锦欢   \n",
       "\n",
       "  PARENTNODENAME                                         SOURCEDATA  \\\n",
       "0    入院记录\\病史\\现病史  患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...   \n",
       "1    入院记录\\病史\\现病史  患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...   \n",
       "2    入院记录\\病史\\现病史  患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...   \n",
       "3    入院记录\\病史\\现病史  患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...   \n",
       "4    入院记录\\病史\\现病史  患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、...   \n",
       "\n",
       "      NODENAME NODEVALUE  HOSPITAL_CODE  \n",
       "0     经常咳嗽_稳定期       未提及   1.240000e+17  \n",
       "1     经常喘息_稳定期       未提及   1.240000e+17  \n",
       "2     经常胸闷_稳定期       未提及   1.240000e+17  \n",
       "3  经常活动后气促_稳定期       未提及   1.240000e+17  \n",
       "4     经常咳痰_稳定期       未提及   1.240000e+17  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sourceData_02 = pd.read_csv('./深圳现病史.csv')\n",
    "print(df_sourceData_02.info())\n",
    "df_sourceData_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2008 entries, 0 to 1007\n",
      "Data columns (total 10 columns):\n",
      "SEQ_ID            2008 non-null int64\n",
      "PATIENT_ID        1544 non-null object\n",
      "PATIENT_NO        2008 non-null object\n",
      "INPATIENT_NO      2008 non-null int64\n",
      "INDEX2            1008 non-null object\n",
      "PARENTNODENAME    2008 non-null object\n",
      "SOURCEDATA        2008 non-null object\n",
      "NODENAME          2008 non-null object\n",
      "NODEVALUE         2008 non-null object\n",
      "HOSPITAL_CODE     2000 non-null object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 172.6+ KB\n",
      "None\n",
      "     SEQ_ID PATIENT_ID PATIENT_NO  INPATIENT_NO INDEX2 PARENTNODENAME  \\\n",
      "0  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "1  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "2  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "3  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "4  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "\n",
      "                                          SOURCEDATA     NODENAME NODEVALUE  \\\n",
      "0  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常咳嗽_稳定期         有   \n",
      "1  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...    双下肢水肿_加重期       未提及   \n",
      "2  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常胸闷_稳定期       未提及   \n",
      "3  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...  经常活动后气促_稳定期       未提及   \n",
      "4  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常咳痰_稳定期         有   \n",
      "\n",
      "        HOSPITAL_CODE  \n",
      "0  12150000460028258G  \n",
      "1  12150000460028258G  \n",
      "2  12150000460028258G  \n",
      "3  12150000460028258G  \n",
      "4  12150000460028258G  \n"
     ]
    }
   ],
   "source": [
    "df_sourceData = pd.concat([df_sourceData_01, df_sourceData_02], axis=0)\n",
    "print(df_sourceData.info())\n",
    "print(df_sourceData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1936 entries, 0 to 1007\n",
      "Data columns (total 10 columns):\n",
      "SEQ_ID            1936 non-null int64\n",
      "PATIENT_ID        1472 non-null object\n",
      "PATIENT_NO        1936 non-null object\n",
      "INPATIENT_NO      1936 non-null int64\n",
      "INDEX2            1008 non-null object\n",
      "PARENTNODENAME    1936 non-null object\n",
      "SOURCEDATA        1936 non-null object\n",
      "NODENAME          1936 non-null object\n",
      "NODEVALUE         1936 non-null object\n",
      "HOSPITAL_CODE     1928 non-null object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 166.4+ KB\n",
      "None\n",
      "     SEQ_ID PATIENT_ID PATIENT_NO  INPATIENT_NO INDEX2 PARENTNODENAME  \\\n",
      "0  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "1  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "2  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "3  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "4  12409215     617387   10036263        722318    NaN       住院病历\\现病史   \n",
      "\n",
      "                                          SOURCEDATA     NODENAME NODEVALUE  \\\n",
      "0  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常咳嗽_稳定期         有   \n",
      "1  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...    双下肢水肿_加重期       未提及   \n",
      "2  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常胸闷_稳定期       未提及   \n",
      "3  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...  经常活动后气促_稳定期       未提及   \n",
      "4  患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给...     经常咳痰_稳定期         有   \n",
      "\n",
      "        HOSPITAL_CODE  \n",
      "0  12150000460028258G  \n",
      "1  12150000460028258G  \n",
      "2  12150000460028258G  \n",
      "3  12150000460028258G  \n",
      "4  12150000460028258G  \n"
     ]
    }
   ],
   "source": [
    "df_sourceData_withFullFeature = df_sourceData.groupby('SOURCEDATA').filter(lambda x:len(x) == 16)\n",
    "print(df_sourceData_withFullFeature.info())\n",
    "print(df_sourceData_withFullFeature.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2天前，患者受凉感冒后出现咳嗽、咳痰，痰液粘稠，不易咳出，无咯血、痰中带血，无发热，无潮热、盗汗、消瘦，无恶心、反酸、烧心，无鼻后滴流感，无气短、胸闷、呼吸困难，无心悸、胸闷、气促，无夜间阵发性呼吸困难，自服药物未见好转。今日来我院门诊肺部CT示1、右侧第6-10肋骨骨折。2、两肺上叶肺气肿。3、右侧少量胸腔积液。4、主动脉及两侧冠状动脉硬化。收入我科治疗，起病以来，精神、睡眠、饮食可，大小便未见明显异常，体重无明显改变。。起病以来，患者睡眠、食欲稍差，大便正常。患者约1周前肋骨骨折。': Int64Index([864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876,\n",
      "            877, 878, 879],\n",
      "           dtype='int64'), '4年前，患者受凉后出现咳嗽、咳痰，活动时气喘、气短不适，休息后稍好转，我科住院诊断COPD，经治疗好转。后多于受凉感冒，天气变化时上述症状再发。病程中无明显活动受限，无双下肢水肿，无夜间阵发性呼吸困难。10天前受凉后上述症状再发，咳嗽，咳黄绿色粘痰，伴胸痛，咳嗽、活动时加重，无咯血、痰中带血，无心悸、胸闷，无发热，活动时感气短不适。院外治疗未见好转，具体用药不详。为求进一步诊治收入。': Int64Index([416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "            429, 430, 431],\n",
      "           dtype='int64'), '半月前，患者受凉感冒后出现咳嗽、咳痰，痰液较少，易咳出，伴活动时气短、胸闷，无咯血、痰中带血，无发热，无潮热、盗汗、消瘦，无恶心、反酸、烧心，无鼻后滴流感，无气短、胸闷、呼吸困难，无心悸、气促，无夜间阵发性呼吸困难，自服药物未见好转。今日来我院门诊胸片示右下肺感染，收入我科治疗，起病以来，精神、睡眠、饮食可，大小便未见明显异常，体重无明显改变。': Int64Index([592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
      "            605, 606, 607],\n",
      "           dtype='int64'), '患者10余年前反复出现受凉后咳嗽、咳痰，为白色粘稠痰，无发热，无咯血，无盗汗，无胸痛，无呼吸困难，无恶心、呕吐，后逐渐出现活动后胸闷、气促，效果欠佳。近3年患者自觉活动后气促，多次在我院住院治疗，诊断“慢性阻塞性肺疾病急性加重期支气管扩张症”，予抗感染、祛痰、平喘等对症治疗后症状可好转出院，但咳嗽、咳痰、气促症状易反复发作。3天前患者受凉后再次出现咳嗽、活动后气促，现为进一步诊治，今日来我院急诊就诊，收入我科治疗。起病以来，精神、睡眠、饮食一般，大小便未见明显异常，体重无明显改变。': Int64Index([144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "            157, 158, 159],\n",
      "           dtype='int64'), '患者10余年前因天气变凉后反复出现咳嗽，咳白粘痰，伴活动后气喘不适，无盗汗、午后潮热，无端坐呼吸。曾反复在我科住院，最后1次住院为2016年3月，出院诊断考虑“慢性阻塞性肺疾病急性加重期、肺部感染、左肺尖局限性气胸、陈旧性肺结核、颈椎退行性病变”，予抗感染、祛痰、平喘、吸氧等处理，病情好转出院。在家坚持吸氧治疗，定期吸入“舒利迭、思力华”等药物。平素上楼、上坡、疾步走有气喘。1周前患者无明显诱因出现明显气喘，活动后加重，1天前出现咳嗽，咳较多黄痰，伴胸闷、心悸，无发热，无头痛、头晕，无夜间端坐呼吸，无咳粉红色泡沫痰。持续吸入氧气后无明显缓解，为进一步治疗收入我科住院。本次起病以来患者精神尚可，食欲、睡眠差，大小便尚正常，近3月体重下降5kg。': Int64Index([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "            141, 142, 143],\n",
      "           dtype='int64'), '患者10余年前开始出现反复咳嗽、咳白色黏痰，无咯血，多于受凉后出现，多次在当地社康医院予消炎治疗后好转（具体诊疗不详）。患者2016年1月3日至1月11日在我科住院，出院诊断为“慢性支气管炎急性发作肺部感染冠心病不稳定型心绞痛经皮冠脉腔内成形术及支架术后陈旧性心肌梗死心功能I级高血压病3级很高危组高尿酸血症慢性肾功能不全氮质血症期”，予头孢曲松抗炎，氨溴索祛痰、沙丁胺醇、布地奈德等雾化、他汀类稳定粥样斑块、阿司匹林抗血小板聚集，及支持对症治疗。并予胸腔穿刺+胸水闭式引流，患者症状好转出院。7天前患者无明显诱因下再次出现咳嗽、咳白色粘液痰，伴活动后气促、胸闷，无发热、盗汗；无胸痛、心悸、端坐呼吸；无腹痛、腹胀等不适。6天前至我院门诊，查胸片1、双下肺感染，左下肺感染较前好转。左侧胸腔积液较前吸收，右侧少量胸腔积液同前相仿。心脏增大，心包积液待排，余老年性心肺改变。发病以来，患者食欲下降，大小便正常。近期体重无明显改变。': Int64Index([496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508,\n",
      "            509, 510, 511],\n",
      "           dtype='int64'), '患者10余年前开始反复出现咳嗽、咳痰，伴气喘，活动后加重，夜间可平卧，自服中药后症状可好转。曾多次于我院住院治疗，上次住院时间为2015.11.18-2015.11.27,诊断“慢性阻塞性肺疾病急性加重期肺部感染支气管扩张慢性肺源性心脏病肺大疱”，予抗感染、平喘、化痰等治疗后好转出院。长期家庭氧疗及规律布地奈德福莫特罗雾化吸入治疗，平时行走约50米即出现气喘，偶有头痛，自服中药后可缓解。3天前患者无明显诱因出现咳嗽、咳少量白色泡沫样痰，轻微活动时出现气喘，伴发热，体温最高38.1℃，全身乏力，偶有胸痛，与活动无关，无畏寒、寒战，无鼻塞、流涕、咽痛，无咯血，无心悸、无恶心、呕吐，无头晕，现患者为进一步诊治收住我科。本次起病以来，患者精神、食欲可，睡眠欠佳，夜尿次数增多，6-8次/晚，无尿急、尿痛，大便正常，近期体重无明显变化。': Int64Index([528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540,\n",
      "            541, 542, 543],\n",
      "           dtype='int64'), '患者10余年前无明显诱因出现咳嗽、咳痰，伴活动后气喘，无发热，无咯血，无胸痛、胸闷，无盗汗，无心慌，无恶心、呕吐，曾诊断“慢性支气管炎”，予对症治疗后咳嗽、咳痰、气喘可好转，但上述症状易反复发作。1周前患者受凉后再次出现咳嗽、咳黄痰，痰不易咳出，伴活动后气喘，3天前至我院门诊就诊，予抗感染、祛痰、平喘等对症治疗，患者咳嗽、咳痰、气喘症状较前好转。现为进一步诊治，门诊以“慢性支气管炎急性发作期”收入我科。起病以来，精神、睡眠、饮食一般，大小便未见明显异常，体重无明显改变。': Int64Index([912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924,\n",
      "            925, 926, 927],\n",
      "           dtype='int64'), '患者10余年前无明显诱因出现活动后气促，运动时明显，休息后可缓解，无畏寒、发热，无咳嗽、咳痰，无胸闷、心悸，无胸痛、咯血，无头晕、头痛，无恶心、呕吐，无腹痛、腹泻等不适，一直未予重视。1天前无明显诱因出现胸闷、气促，呼吸困难，偶有咳嗽，咳少量白痰，可咳出，无端坐呼吸，无夜间阵发性呼吸困难，无双下肢浮肿，无畏寒、发热，无胸痛、咯血等不适，遂至我院急诊就诊，查血常规WBC14.82*109/L，N%82.5%；超敏CRP8.94↑mg/L；胸部CT见右肺上叶磨玻璃密度结节，性质待定，早期肿瘤性病变不除外；附见降主动脉旁异常致密影。予以吸氧、抗感染、平喘等对症支持治疗后，患者自觉胸闷、气促较前缓解，现为进一步诊治，急诊拟“胸闷、气促查因”收入我科。起病以来，患者精神一般，饮食、睡眠可，大小便如常，近期体重无明显减轻。': Int64Index([544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556,\n",
      "            557, 558, 559],\n",
      "           dtype='int64'), '患者10余年前无明显诱因出现间断活动后气短，伴咳嗽、咳痰，休息后可缓解，病情反复发作，活动耐力逐渐下降，曾于我院诊断“慢性阻塞性肺疾病”，给予抗感染、化痰等对症治疗，症状好转后出院。1月前无明显诱因咳嗽、咳痰，为黄色粘痰，量少，痰利，活动后喘息气短，遂来我科就诊，我科拟以“慢性阻塞性肺疾病急性加重期”收入院。患者自发病以来偶有反酸、烧心，无咯血及呕血，无心悸及胸前区疼痛，精神、饮食及睡眠一般，大小便正常，体重未见明显改变。\\n': Int64Index([848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860,\n",
      "            861, 862, 863],\n",
      "           dtype='int64'), '患者10余年来反复咳嗽，咳白色粘痰，在冬春季节及气温骤变时咳嗽、咳痰明显。无胸痛、胸闷，无心悸、气促。未系统诊治。今天上午患者无明显诱因下咳嗽、咳痰加重，咯血，为整口鲜血，总量约100ml。伴胸闷。无畏寒、发热，无胸痛。至我院急诊科就诊，胸部CT提示“慢支、肺气肿；双肺多发炎症”，收入我科住院。本次起病以来患者精神、食欲、睡眠欠佳，大小便正常，体重无改变。': Int64Index([736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748,\n",
      "            749, 750, 751],\n",
      "           dtype='int64'), '患者10天前出现肛周疼痛，因既往有痔疮病史故给予痔疮栓治疗，症状不缓解。一周前就诊于外院，给予相应治疗（具体方法及用药不详）,此后患者出现畏寒、发热，体温未测,自觉乏力,肛周疼痛明显,无大便习惯及性状改变。未做特殊处理,上诉症状逐渐加重并肛周疼痛加重。今为求诊治而入院,门诊结合病史及查体，以“直肠肿物”收入院。病后患者精神可，饮食一般,大便次数减少，小便如常。\\n': Int64Index([240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "            253, 254, 255],\n",
      "           dtype='int64'), '患者10天前感冒后出现咳嗽、咳痰症状，咳黄痰，无异味，无痰中带血，较易咳出，气短，活动后为著，无夜间阵发性呼吸困难，无发热、胸痛等症状，自服抗感冒药物疗效差，就诊呼市第一医院，胸片示左肺下野斑片状密度增高阴影，考虑肺炎可能，今为了进一步诊治入我院，自发病以来，无恶心、呕吐，无头晕、头痛，无发热、胸痛等症状，精神、饮食、睡眠欠佳，大小便正常。\\n': Int64Index([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "            205, 206, 207],\n",
      "           dtype='int64'), '患者10天前无明显诱因出现胸憋、胸痛，呈阵发性，有缓解期，自服止痛药（具体名称剂量不详）可缓解，症状反复，未予系统治疗。今为进一步诊治就诊于我院，门诊以“胸痛原因待查”收住院，患者自入院以来无咳嗽、咳痰，无阵发性呼吸困难及后背放散痛，无恶心、呕吐，无腹痛、腹泻，无尿频、尿急、尿痛，精神饮食一般，大小便正常，体重无明显变化。\\n': Int64Index([975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "            988, 989, 990],\n",
      "           dtype='int64'), '患者10年余前开始反复出现受凉后咳嗽、咳痰，多为白色泡沫状痰，偶为黄色粘痰，伴活动后气促，多次在我院就诊，诊断\"慢性阻塞性肺疾病\"。近8年来气促较前明显加重，严重时爬一层楼或行走100米即感气促，平素使用家庭氧疗、雾化，但症状常反复发作。2015年12月03日至2015年12月12日曾于我科住院治疗。3天前自觉因天气变化再次出现活动后气促，无咳嗽、白痰、发热、咯血。家庭氧疗、雾化未见明显好转。今日为进一步诊治入院。患者近来无头晕、头痛，无胸闷，无恶心、呕吐，无腹痛、腹泻，精神、胃纳、睡眠可，二便如常，体重未见明显变化': Int64Index([304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
      "            317, 318, 319],\n",
      "           dtype='int64'), '患者10年前出现反复咳嗽、咳痰，咳为白色粘痰或白色泡沫样痰，伴气急，胸闷，心悸，每遇冬春季节好发，常以受凉、上感为诱因。半月前上感后上述症状再次加重，咳嗽，咳白色粘痰，不易咳出，伴气急，伴胸闷，心悸，自服药物（具体药物剂量不详），症状无明显缓解，为进一步明确诊治，今来我院，门诊收入。病后无发热，无咯血及盗汗，无头痛，无恶心、呕吐，无腹痛、腹胀，无双下肢浮肿。患者自发病以来，精神可，睡眠欠佳，服用安定，食欲差，大便干燥，小便正常，体重无明显变化。\\n': Int64Index([104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "            117, 118, 119],\n",
      "           dtype='int64'), '患者10年前开始反复出现咳嗽、咳痰、气喘，曾就诊于当地医院住院治疗，诊断慢性阻塞性肺疾病，予抗感染、祛痰、解痉、平喘治疗后症状稍有缓解。平素未进行氧疗及雾化吸入治疗。1月前患者出现活动后气促，如厕、吃饭等日常活动亦可出现气促，无畏寒、发热、盗汗、咯血，再次就诊于当地医院，予头孢克洛抗感染治疗，及平喘、祛痰治疗后，活动后气促无明显缓解，今日入我院急诊，查血常规WBC4.89×10^9/L，NEUT%63.2%，HGB147g/L，PLT135×10^9/L；胸部CT(对比2012-8-9)1.慢支肺气肿并多发肺大泡形成，同前。两肺间质性炎症，较前进展。2.主动脉及冠状动脉硬化，升主动脉瘤样扩张。3.附见肝右叶低密度灶，肝前缘水样低密度灶。起病以来，患者精神食欲尚可，二便正常，体重无明显下降。': Int64Index([944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956,\n",
      "            957, 958, 959],\n",
      "           dtype='int64'), '患者10年前开始反复出现咳嗽、气喘，曾于当地医院住院治疗（具体不详），予抗感染、解痉、平喘治疗后好转。1年前开始长期规律使用无创呼吸机辅助呼吸治疗，每日通气5-6小时，并间断出现双下肢对称性水肿。3月前开始规律吸入噻托溴铵治疗。3天前受凉后出现咳嗽、气喘加重，咳少量白色粘液痰，无畏寒、发热，为进一步诊治收入院。起病以来，精神食欲可，二便正常，体重无明显变化。': Int64Index([352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "            365, 366, 367],\n",
      "           dtype='int64'), '患者10年前开始每于天气转凉或气候变化易出现咳嗽，咳白痰，并逐渐出现活动后气促，无盗汗、低热，每年发病大于3个月，曾多次于医院门诊或住院治疗，诊断为“慢性阻塞性肺疾病，多发肺大泡，陈旧性肺结核”，予抗感染、止咳化痰、解痉平喘等治疗后好转。平素间中吸入“沙美特罗替卡松、噻托溴铵”治疗。2月前受凉后出现咳嗽，咳黄绿色脓痰，无畏寒、发热，无鼻塞、流涕，曾就诊我院门诊予“阿莫西林、茶碱”口服及上述药物吸入，效果一般。10天前逐渐出现喘息,日常生活尚不受限，无胸闷、胸痛、咯血等，未予注意。半天前无诱因突发喘息加重，不能平卧，无咳粉红色泡沫痰，遂就诊我院急诊，查血气分析示“PH7.351，PCO251.4mmHg,PO290mmHg”，予“氨茶碱、地塞米松、速尿、西地兰、硝酸甘油”等药物治疗，现为进一步诊治收入我科。患者此次起病以来，胃纳、睡眠欠佳，大小便正常，体重无明显改变。': Int64Index([96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
      "            110, 111],\n",
      "           dtype='int64'), '患者10年前感冒、受凉后出现咳嗽、咳痰，偶尔咳白色粘稠痰，痰量少，无特殊气味，气短活动后明显，常在冬春季节发作，每年发作持续时间超过3个月以上，未系统诊治，间断在当地诊所输注哌拉西林和口服中药（具体名称及用量不详）后症状可缓解；今年未用任何药物治疗，2个月前症状加重，未诊治，为求进一步诊治，门诊以“慢性阻塞性肺疾病急性加重期”收入院。患病以来，精神状态尚可，无发热，无头晕，偶有头痛，无乏力，午后低热，无咳血，但有双下肢浮肿，右侧腹股沟处疼痛。饮食正常，睡眠正常，夜间小便3-5次，每次量不多，大便正常。\\n': Int64Index([72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87], dtype='int64'), '患者10月余前因受凉后出现咳嗽，伴咽痛不适，无发热，无鼻塞、流涕，无咳痰、咯血、胸痛、呼吸困难，未就诊，咳嗽持续1月余无缓解。后于龙岗第二医院就诊，考虑“慢性支气管炎”，予“头孢类”抗感染治疗1周（具体不详），上述症状曾有好转，但反复发作，多于受凉后或天气变化时出现。10天前患者再次因受凉后出现咳嗽，呈阵发性，夜间明显加重，伴有气促，自诉可闻及胸部“喘鸣音”，无咳痰、咯血，无胸痛、心悸，无反酸、嗳气、恶心、呕吐，无发热、盗汗，于我院门诊就诊，查胸片示两肺纹理稍强，心膈未见异常。门诊考虑慢性支气管炎急性发作，予“复方甲氧那明、孟鲁司特、氯雷他定”口服治疗，咳嗽、气促症状稍有好转。1天前患者咳嗽、气促症状突发加重，不能平卧，现为进一步诊治收住我科。起病以来，患者精神、胃纳可，睡眠不佳，二便正常，体重无明显变化。': Int64Index([928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940,\n",
      "            941, 942, 943],\n",
      "           dtype='int64'), '患者11年来反复于冬春季节或受凉感冒后咳嗽、咳痰，以白色泡沫痰居多，伴活动气急，平素自服“氨茶碱、索米痛”可缓解，或于症状较重时就近诊所输液（具体用药不详）可缓解，病情逐年加重，1年前于我院住院治疗，经查肺CT、肺功能、心彩超、血气分析等诊断“慢性阻塞性肺疾病、慢性肺源性心脏病”，治疗好转出院，出院后间断家庭氧疗。3天前无明显诱因上述症状加重，轻咳少痰，活动气急，双下肢浮肿，自服“氨茶碱”无效，为进一步治疗入院。患者发病来饮食、睡眠可，大小便正常，无胸痛、痰血、发热、盗汗及夜间阵发性呼吸困难。\\n': Int64Index([430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
      "            443, 444, 445],\n",
      "           dtype='int64'), '患者15天前因受凉感冒后出现胸憋气短伴喘息不适症状，自行口服“感冒药”治疗4天（具体药物不详），上症未见明显改善，后就诊于凉城县中蒙医院，行相关检查化验后给予抗感染、支气管扩张等对症支持治疗10天（具体药物及剂量不详），胸憋喘息气短不适症状有所改善。1天前无明显诱因出现胸憋气短喘息加重伴无法平卧，今晨急就诊于我院急诊科行相关化验示：血气分析：酸碱度7.32↓，二氧化碳分压52.0mmHg↑，血氧分压56.0mmHg↓。血常规：中性粒细胞比值95.74%↑。急诊科给予无创呼吸机辅助通气、抗感染、解痉、补液等对症支持治疗，上症未见明显改善，请我科会诊以“支气管哮喘急性发作”收入院。此次发病以来伴咳嗽咳痰，黄痰不易咳出，无发热，无臭味，无咯血，无胸痛，无头晕头痛，精神睡眠状态较差，饮食较差，大小便正常。\\n': Int64Index([446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "            459, 460, 461],\n",
      "           dtype='int64'), '患者15年前无明显诱因出现反复咳嗽，咳少量白痰，伴气喘，晨间为甚，每年发作2-3次，每次持续1周左右，予抗炎祛痰平喘、对症支持治疗后，症状能缓解。但容易复发。患者2015年1月18日至2015年1月27日因咳嗽气促再发至我科就诊，查肺功能提示重度混合性通气功能障碍，支气管舒张试验阴性。支气管镜支气管腔内见大量脓性分泌物，呼气气管及主支气管可见明显塌陷，风湿免疫病筛查颗粒型阳性，多核点型阳性。过敏原筛查示户尘螨、蟑螂、苋、虾敏感，总IgE＞200/μL。睡眠呼吸监测中度阻塞性睡眠呼吸暂停低通气综合征。CT1、两上肺胸膜下少许间质性改变；左上肺前段胸膜下小结节，性质待定，建议随访复查。2、附见脂肪肝。出院诊断为“慢性阻塞性肺疾病急性加重期间质性肺改变左上肺小结节性质待定中度阻塞性睡眠呼吸暂停低通气综合征高血压病（2级，高危组）2型糖尿病高脂血症低钠血症轻度脂肪肝风湿结缔组织病可能”，予抗炎平喘解痉治疗，症状好转出院。出院后患者坚持使用信必可、塞托溴胺、乙酰半胱氨酸，并定期复查胸部CT。1周前患者少量咳嗽、咳白痰，伴活动时气促，剧烈活动或体力活动时感前胸隐痛，停止运动休息时则胸痛在2-3分钟内逐渐消失。前日复查胸部CT示“两肺间质性病变，基本同前，脂肪肝”。为明确间质性病变性质，再次入院。发病来，无咯血及咳粉红色泡沫痰，无颜面四肢水肿，大小便正常。无明显消瘦。': Int64Index([480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
      "            493, 494, 495],\n",
      "           dtype='int64'), '患者15年前每于冬春季节受凉或感冒后出现咳嗽、咳痰及气短，痰为白色粘痰，无长期咳大量脓臭痰，无低热、盗汗及咯血，无刺激性干咳及声嘶，病情呈反复发作，每年约持续3月余。2天前受凉后上述症状加重，性质同前，较前加重，伴呼吸困难及全身乏力，被迫坐位，睡眠下仍间断憋醒，无寒战、高热，无咳粉红色泡沫痰，遂就诊于我院急诊科，2018-4-8生化2检验报告：酸碱度7.39，二氧化碳分压45.8mmHg↑，血氧分压135.0mmHg↑。2018-4-8[危]急诊检验报告：钾2.86mmol/L↓。N-端脑钠肽前体：5690.00ng/l↑，给予抗感染、改善心功能等对症治疗，今为求专科诊治我科以“慢性阻塞性肺疾病急性加重”收住院治疗。患者自发病以来精神、饮食及睡眠差，无头晕及头痛，无恶心及呕吐，无腹痛及腹泻，无尿频、尿急及尿痛，体重无明显增减。\\n': Int64Index([318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "            331, 332, 333],\n",
      "           dtype='int64'), '患者1个月前因咳嗽、气短就诊于当地县医院，摄胸部CT考虑肺部感染，住院治疗18天，症状略好转出院，2天前患者无明显诱因开始发热，在家中未测体温，昨日病情加重，精神状态差，食欲差，出现高热伴呼吸困难，家属为求明确诊治，就诊于我院，我科以“肺部感染？”收入院，病程中患者一般状态差，饮食睡眠差，无胸痛、咯血，无夜间阵发性呼吸困难，二便如常。\\n': Int64Index([832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "            845, 846, 847],\n",
      "           dtype='int64'), '患者1天前摔致右侧胸痛、气促，为持续性钝痛，偶有阵发性咳嗽，痰较多，无明显呼吸困难，无头痛、双下肢痛，无昏迷，无呕吐，无心慌、口渴，无咯血，无腹痛、腹泻、呕血、血便，当地医院X光片检查示“1.老年性心肺改变；慢支并感染2.右侧第8肋骨折，第7、9肋可疑骨折”，为求进一步诊治来我院就诊，门诊拟“肋骨骨折”收入我科。起病以来，食欲、精神尚可，体重无下降。二便正常。': Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype='int64'), '患者1年前受凉后开始出现反复咳嗽、咳黄色粘痰，咳嗽、咳痰与天气变化及刺激性气体无明显关系，偶有流清涕，咳嗽剧烈时伴有气促，无发热，无头晕、头痛，无胸闷、无盗汗、乏力、纳差，无反酸、烧心等不适，多次于当地门诊就诊，行胸片检查一次，自诉未见明显异常（未见报告与片子），给予药物治疗（具体不详）后上述症状缓解，未行肺功能检查。1周前患者受凉后出现呼吸困难，轻微活动即可出现，休息时缓解，伴有咳嗽、咳少量黄白色粘痰，自觉痰多不易咳出，偶有流清涕，有夜间憋醒，无咳粉红色泡沫痰，无发热，无咽痛，无盗汗、乏力，无胸痛、四肢酸痛等不适，先后于中医院、罗湖区人民医院门诊就诊，给予药物治疗（具体不详），上述症状无缓解。现患者为求进一步治疗，入住我科，自此次起病以来，睡眠、精神稍差，食欲尚可，二便正常，近期体重无明显变化。': Int64Index([368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "            381, 382, 383],\n",
      "           dtype='int64'), '患者1年前开始反复出现咳嗽、咳痰，受凉或季节变化时易出现，自服药物可改善，自认为为“感冒”，10余天前受凉后再次出现咳嗽、咳痰，为黄色脓痰，量较多，易咳出，无发热，上楼、上坡有气促，无胸痛，无头晕，自服药物（不详），未见改善，并纳差明显，夜间小便多，夜间可平卧，无咳粉红色泡沫痰，无心慌等，为求进一步诊治，今日入住我科，病程中大便不畅，近期体重有所下降（不详）。': Int64Index([816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828,\n",
      "            829, 830, 831],\n",
      "           dtype='int64'), '患者20余年前受凉后出现咳嗽、咳痰，无发热，无咯血，无头晕、头痛，无恶心、呕吐，无心悸、气促，无呼吸困难，在诊所予对症治疗后症状可好转，但咳嗽、咳痰症状，多于受凉感冒、天气变化时反复发作。病程中渐出现活动时气短，双下肢水肿。20余天前，患者咳嗽、咳痰、气喘症状较前明显加重，无发热，无咯血，无胸闷、胸痛，无恶心、呕吐，无心悸，无呼吸困难，无夜间不能平卧，症状持续未见好转，为求治疗收入。起病以来，精神、睡眠、饮食一般，大小便未见明显异常。': Int64Index([768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780,\n",
      "            781, 782, 783],\n",
      "           dtype='int64'), '患者20余年前受凉感冒后出现咳嗽、咳痰，无咯血，无头晕、头痛，无心悸不适，无胸痛，在诊所予对症治疗后症状可好转，但咳嗽、咳痰症状易反复发作，多次我科就诊，渐出现活动后气喘、气促，活动受限，夜间不能平卧，双下肢水肿。考虑诊断COPD、肺源性心脏病。1月余前，咳嗽、气喘再发，在我科予抗感染、抗真菌、祛痰、平喘等对症治疗后咳嗽、咳痰、气喘症状好转，今日办理出院。但2小时前患者再次出现气喘，较前加重，伴咳嗽，咳黄白痰，痰不易咳出，无咯血，现为进一步诊治收入我科。患者近来饮食、精神、睡眠一般，尿频，排尿稍困难，大便如常，体重未见明显变化。': Int64Index([400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412,\n",
      "            413, 414, 415],\n",
      "           dtype='int64'), '患者20余年前始常于受凉、感冒后反复出现咳嗽、咳痰，无喘息、气短，以冬季为著，消炎止咳治疗症状缓解。近5天上述症状加重，咳嗽、咳白色粘痰，量少，不易咳出，无气短、喘息，无发热，就诊于四子王旗医院，给予查胸部CT回报：慢支、肺气肿、肺大泡，右肺上叶感染，陈旧性胸膜炎，给予口服“麻黄止嗽胶囊、罗红霉素、麝香通心滴丸”口服，具体剂量不详，患者咳嗽无明显好转，于今晨出现手抖明显，周身无力，今为进一步诊治来我院，以“慢性阻塞性肺疾病急性加重”收入院。患者病程中无心悸，无恶心、呕吐，无腹痛、腹胀，无腹泻，精神状态一般，饮食及睡眠可，二便同常，近期体重未减轻。\\n': Int64Index([800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812,\n",
      "            813, 814, 815],\n",
      "           dtype='int64'), '患者20余年无明显诱因出现咳嗽、咳痰，痰多粘稠不易咳出，多发生于劳累及季节变化后，呈反复发作，10余年前上诉症状加重，就诊于内蒙古中医医院，诊断为“慢性阻塞性肺气肿”，给予对症治疗后病情好转出院。入院前15天患者于劳累后出现再次出现上述症状，自觉程度较前明显加重，伴有呼吸困难，于清水河县医院治疗后好转出院，3天后上诉症状再次发生于内蒙古中医医院治疗，诊断“呼吸衰竭、心力衰竭”，经治疗病情未见好转，4月3日由“120”送入我院急诊，首诊患者意识不清，双侧瞳孔对光反射迟钝，监测血气提示二氧化碳严重潴留，考虑病情危重，遂以“肺性脑病”收入我科。患者病程中，精神状态差，食欲不佳，无发热，无恶心呕吐，无腹痛腹泻，小便量少，大便如常，体重无明显变化。\\n': Int64Index([270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
      "            283, 284, 285],\n",
      "           dtype='int64'), '患者20多年前开始常于受凉后咳嗽、咳痰、气促，曾在我科住院，诊断“支气管扩张，COPD”，于对症治疗可好转。1周前患者受凉后再次出现咳嗽，咳黄白痰，活动后气促，晚夜间气促明显，偶感左上胸痛，无发热，无咯血，无心悸，在我院急诊予“阿奇霉素”治疗2天，无明显好转，昨晚咳嗽明显，难以入睡，今来我院门诊，以“支气管扩张”收入我科。自起病以来，患者精神、食欲、睡眠一般，大小便尚正常，近期体重变化不详。': Int64Index([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268,\n",
      "            269, 270, 271],\n",
      "           dtype='int64'), '患者20天前无明显诱因出现咳嗽，病初咳白色泡沫痰，量少，不易咳出，伴活动后胸憋、气短，于卓资县医院静点头孢地嗪、红花黄色素、奥美拉唑一周，上述症状无明显缓解，住院2天后出现夜间发热，体温最高达38.5℃，咳痰转为黑色粘痰，未见血丝，量中等，易咳出，遂来我院，门诊行胸部平扫：1.右肺中叶不张，右中叶支气管闭塞、右下叶支气管狭窄，闭塞和狭窄处钙化影；2.右肺下叶炎症，支气管狭窄并肺门部肿块影，结核性？3.考虑双肺继发型结核，上叶明显，部分硬结、钙化；4.考虑细支气管炎；5.气管内痰栓；6.右肺门、纵隔多发增大淋巴结，大部钙化；7.右侧胸腔积液，心包积液；8.双侧胸膜局部增厚；9.胸5椎体及右侧第4后肋高密度小结节。血常规：白细胞19.01*10^9/L↑，中性粒细胞比值86.24%↑，C反应蛋白118.900mg/L↑。门诊以“肺部阴影性质待查”收住我科。病程中患者无乏力、盗汗，无咯血，无心悸、胸痛，无夜间阵发性呼吸困难，睡眠、食欲尚可，大、小便如常，体重未见明显变化。\\n': Int64Index([507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "            520, 521, 522],\n",
      "           dtype='int64'), '患者20年前出现咳嗽、咳痰，咳白色粘痰或白色泡沫样痰，每遇冬春季节好发，常以受凉、感冒为诱因，每次发作持续时间较长，开始病情较轻，不用药也可缓解，以后病情逐渐加重，需要静脉用药才能控制，3天前上述症状再次加重，咳黄色粘痰，量多，不易咳出，痰中无血丝，无异味，喘息、气急较重，活动受限，伴有发热，一直未测体温，发热前有畏寒、无寒战，无声音嘶哑及吞咽困难，无胸痛及消瘦，伴有乏力，口服感冒药3天（具体药剂不详），为了进一步诊治入我院，发病以来，精神饮食差，近2天完全不进食水，二便正常。\\n': Int64Index([816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828,\n",
      "            829, 830, 831],\n",
      "           dtype='int64'), '患者20年前出现气短、咳嗽、咳白色粘痰，量少不易咳出，无心悸、气短、发热、咯血、盗汗，在附近社区医院口服药物（具体不详）治疗，症状可缓解，随后每年于冬春季节发病，持续2-3月，呈进行性加重，劳动耐力逐年下降，2月前出现活动后气短加重，咳嗽、咳痰无明显变化，无心悸、夜间阵发性呼吸困难，偶有反酸，无烧心，院外自行口服药物（苓桂咳喘宁胶囊、螺内酯、辛伐他汀）治疗，上述症状无明显改善，今为求进一步治疗，特来我院，门诊查以“慢性阻塞性肺疾病急性加重”收入院，此次患病来精神、睡眠、饮食可，大小便正常，双下肢轻度水肿，无明显消瘦。\\n': Int64Index([651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663,\n",
      "            664, 665, 666],\n",
      "           dtype='int64'), '患者20年前每于冬春季节受凉或感冒后出现咳嗽、咳痰，痰为白色粘痰，伴气短，病情呈反复发作，每年约持续3月余，1年前因气短症状加重、双下肢浮肿入我院治疗，诊为“AECOPD、慢阻肺、肺心病、心衰、呼吸衰竭、肺大疱”，住院治疗19天好转出院，出院后患者活动后气急有所改善，在家中间断吸氧，10天前患者于感冒后出现咳嗽、咳痰及气急加重，在家中未做任何处理，今为求进一步诊治入我科，病程中患者无发热，饮食睡眠欠佳，二便如常，无咯血、胸痛，无夜间阵发性呼吸困难。\\n': Int64Index([398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
      "            411, 412, 413],\n",
      "           dtype='int64'), '患者2余月前无明显诱因开始出现反复右侧胸部疼痛，呈隐痛，与呼吸无关，可放射至后背部，疼痛以夜间为主，平卧位时明显加重，左侧卧位可减轻，自行涂抹“黄道益活络油”或打嗝后疼痛可有缓解，无咳嗽、咳痰，无发热，无胸闷、气促，无夜间盗汗、乏力，未就诊。5天前患者开始出现反酸，返流液中有少许血丝，色鲜红，无血凝块，无恶心、呕吐、烧心感、腹痛不适。2015-12-15于宝安中医院就诊，查胸片提见两肺野多发散在边缘模糊结节灶，大小不一。后于龙岗区中心医院行胸部CT检查示双肺多发结节，以气管为中心，伴渗出改变。现为进一步诊治收住我科。起病以来，精神、睡眠尚可，胃纳欠佳，二便正常。近期体重无明显变化。': Int64Index([848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860,\n",
      "            861, 862, 863],\n",
      "           dtype='int64'), '患者2周前于感冒后出现咳嗽、咳大量白痰，易咳出，期间于家中自服抗感染止咳类药物（具体用药不详）5天无效，2天前出现发热，体温达38.7℃，就诊于丰镇市医院，摄胸片考虑双肺炎症，给予口服“茶碱缓释片、硫酸沙丁胺醇口腔崩解片、氨溴索口服液、肺力咳合剂”并静滴“左氧氟沙星、多索茶碱”2天无效，为进一步明确诊治今日就诊于我院急诊科，摄肺CT见双肺下叶见实变影，考虑“肺炎”，遂入院治疗。患者发病来饮食一般，睡眠差，大小便正常，无胸痛、痰血、气急盗汗及夜间阵发性呼吸困难。\\n': Int64Index([784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796,\n",
      "            797, 798, 799],\n",
      "           dtype='int64'), '患者2天前受凉后出现咳嗽，稍有咳痰，伴发热，体温最高达39.0℃，稍感头晕、气促，无咯血，无盗汗，无胸痛、胸闷，无心慌，无呼吸困难，无恶心、呕吐，无腹痛、腹泻，无尿频、尿急、尿痛，在诊所予对症治疗后，体温可降至正常，但仍有咳嗽、活动后气促。现为进一步诊治，今日来我院急诊就诊，急诊查胸部CT示1、右肺感染，右肺中叶及左肺上叶舌段慢性炎症2、主动脉硬化，急诊以“肺部感染”收入我科。起病以来，精神、睡眠、饮食稍差，大小便未见明显异常，体重无明显改变。': Int64Index([512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "            525, 526, 527],\n",
      "           dtype='int64'), '患者2年前受凉后出现咳嗽、咳痰，咳少量白痰，以干咳为主，伴气喘，活动后明显，需坐位，无发热、胸痛、咯血，无盗汗、乏力，无心慌、胸闷，曾于我院中医科住院，具体诊治过程不详，症状好转后出现，此后天气变化时上述症状反复，未系统诊治。后多次因急性发作于我科住院治疗，最后一次为2015.12.03出院，出院诊断考虑慢性支气管炎急性发作、肺部感染、支气管轻度扩张、右下肺小结节、前列腺增生症、双肾结石、高糖血症、高尿酸血症等，出院后患者未家庭氧疗及吸入药物治疗，曾行肺功能检查，无法配合，4天前无明显诱因下，患者再次出现气喘加重，有咳嗽、咳痰，为黄白粘痰，痰液不易咳出，无发热，无胸痛，无咯血，无盗汗，今日就诊我院门诊，给予氨茶碱及甲泼尼龙应用，为求进一步诊治，今日入住我科，病程中，食欲可，精神可，大小便正常，体重无明显下降。': Int64Index([336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
      "            349, 350, 351],\n",
      "           dtype='int64'), '患者2年前开始反复受凉后咳嗽、咳痰、气喘，曾在我科住院，诊断“慢性阻塞性肺疾病急性加重期”，行抗感染、平喘等治疗后患好转。平素使用“沙美特罗替卡松50/250”吸入。1周前受凉后再次出现气喘，发热，自测体温38.1℃，无明显咳嗽、咳痰，无头晕、头痛，无心悸，无鼻塞、流涕，在我院门诊先后予“左氧氟沙星、甲强龙、拉氧头孢”治疗，现无发热，以“AECOPD”收入我科。起病以来，患者精神、食欲稍差，大小便正常。': Int64Index([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], dtype='int64'), '患者2年前开始反复咳嗽、咳痰、气促，1年前曾在我科住院诊断“COPD”，行对症治疗后好转出院。长期使用“信必可”等药，症状控制可。1周前受凉后再次出现咳嗽、咳黄痰，来我院门诊，予“罗红霉素、按柠派胶囊”等药口服，症状无好转，近3天来出现活动后气促，无头晕、头痛，无胸痛、心悸，无咯血，无端坐呼吸，无下肢水肿，昨日上午来我院急诊，测体温37.7℃，予“阿奇霉素、甲强龙”等药治疗，体温正常，仍有咳嗽、咳痰、气促，收入我科行进一步治疗。发病以来，患者精神可，进食稍差，睡眠可，大小便正常。': Int64Index([672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684,\n",
      "            685, 686, 687],\n",
      "           dtype='int64'), '患者2年来间断无明显诱因咳嗽，干咳为主，发作时自服“甘草片”可缓解，因症状相对较轻，从未系统诊治。5天前无明显诱因上述症状加重，咳少量白色稀薄样痰，伴有胸闷、气短，并周身乏力，自服“止咳类糖浆”（具体不详）无效，且昨夜喘息加重，今日就诊于我院急诊科，摄肺CT见右侧肺门影明显增大，右肺上中叶及左肺上叶大片状实变影，其内可见空气支气管征，右侧胸腔内积液，给予静滴“喜炎平、二羟丙茶碱”，症状略减轻，为进一步明确诊治入院。患者病程中无痰血、发热、盗汗及夜间阵发性呼吸困难，精神及饮食差，睡眠差，大便不畅，小便正常，近期体重无明显变化。\\n': Int64Index([539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
      "            552, 553, 554],\n",
      "           dtype='int64'), '患者2月前出现呼吸困难,多于活动后出现;偶有咳嗽,咳痰;自服阿奇霉素分散片等药物后症状缓解;上述症状反复发作；1周前患者呼吸困难加重，喘息；夜间不能平卧，呈端坐呼吸；无发热，有白色粘痰；就诊于乌兰察布市中心医院心内科；给予抗炎，平喘，抗心衰治疗后患者症状无明显缓解；为进一步诊治来我院；患者饮食尚可，近日饮水少，尿量偏少。\\n': Int64Index([736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748,\n",
      "            749, 750, 751],\n",
      "           dtype='int64'), '患者30余年前出现咳嗽、咳痰，咳白色粘痰，每遇冬春季节好发，常以受凉、感冒为诱因，每次发作持续时间较长，开始病情减轻，不用药也可缓解，以后病情逐渐加重，伴有进行性加重的呼吸困难，活动耐力逐渐下降，曾多次入我科住院治疗，诊断“慢性阻塞性肺病、慢性肺源性心脏病”，给予抗感染、平喘、对症治疗，患者病情稳定出院。平素家庭氧疗及间断无创呼吸机治疗。近6天“感冒”后上述症状再次加重，咳嗽频、咳痰不利，活动后胸憋、气急明显，双下肢浮肿，无发热，在家未予特殊治疗，症状逐渐加重，为求进一步诊治入我科。患病以来，精神及进食差，无脓臭痰，无胸痛，无盗汗，小便不利，大便正常。\\n': Int64Index([366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "            379, 380, 381],\n",
      "           dtype='int64'), '患者30余年前开始常于受凉后发生咳嗽、咳痰、气喘，痰液多为白色泡沫状，偶为黄色粘稠样，伴活动后胸闷、气促，曾有数次少量咳血，多次在我院住院，诊断“支气管哮喘、支气管扩张症、肺源性心脏病”等，行抗感染、平喘等治疗可好转，长期家庭氧疗，雾化吸入沙丁胺醇等药物。1周前晚受凉后出现黄痰、咽痛、发热、寒战，未测体温，有咳血丝痰，服用云南白药后好转。无心悸、胸痛，为进一步治疗，特来我院，门诊收入院治疗。患者病来精神、饮食、睡眠稍差，二便如常，体重未见明显变化。': Int64Index([80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95], dtype='int64'), '患者30年前起出现反复咳嗽、咳痰，病情迁延不愈，未治疗；15年前出现活动后喘息、气短，活动耐力逐渐下降，休息症状可缓解。2015年12月曾因“左房粘液瘤”我院心血管外科住院行左房粘液瘤切除术+三尖瓣成形术，好转后出院。出院诊断：“左房粘液瘤左心衰竭右心衰竭肺动脉高压（中重度）三尖瓣重度反流肺动脉瓣轻度反流冠心病甲状腺结节脂肪肝双下肢动脉粥样硬化左侧股总动脉右侧大隐静脉曲张脂肪肝前列腺增生伴囊肿左肺上叶肺大泡局限性肺气肿”。出院医嘱：华法林，地高辛，倍他乐克，瑞舒伐他丁，呋塞米等。口服一年后自行停药。1月前着凉后患者出现发热，未测体温，大汗淋漓，咳痰，白色粘痰，气短，活动重度受限，不能平卧，乏力，双下肢浮肿，在门诊就诊，相关检查：胸片：1.胸部术后2.心影中度增大3.肺气肿、左肺肺大泡可能，请对比旧片4.右肺上叶钙化小结节可能，请对比旧片/复查5.双肺索条6.左侧胸膜增厚。2018-5-30心脏超声检查报告：右心、左房增大右室壁增厚三尖瓣反流（中度）肺动脉高压（重度）。给予口服药“匹多莫德，补肺活血胶囊，噻托溴铵，强苯磺酸钙”等药物，家庭无创呼吸机辅助通气治疗，症状较前缓解，2天前再次出现气短加重，今日为进一步诊治，收入我科。病程中，患者精神状况较差，有夜间憋醒，不能平卧，心慌，无胸痛，无痰中带血，无头晕、头痛，无恶心、呕吐，无盗汗，乏力、纳差，睡眠差，二便正常，无明显消瘦。\\n': Int64Index([414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
      "            427, 428, 429],\n",
      "           dtype='int64'), '患者3天前无明显诱因出现发热，体温高至39℃，伴寒战，伴头晕，伴咳嗽、咳黄痰，痰量不多，易咳出，不伴乏力、盗汗，不伴胸痛、咯血，不伴周身皮疹，不伴结膜充血，不伴夜间憋醒，当地医院给予退热处理后体温降至正常，后体温反复升高，为求进一步治疗就诊于我院，门诊以“肺部感染”收入我院，病程中，无意识障碍，无恶心、呕吐，无心前区疼痛，无腹痛、腹泻，双下肢无明显浮肿，近来体重未见明显下降。\\n': Int64Index([768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780,\n",
      "            781, 782, 783],\n",
      "           dtype='int64'), '患者3年前开始反复出现咳嗽、咳痰，受凉后易出现，偶有气促，曾反复于社康输液治疗或住院治疗（不详），症状可改善，患者10余天前因进食油炸食物后出现咳嗽、咳白色粘痰，咳嗽以夜间为甚，咳嗽剧烈时伴气促、头晕，偶可闻及喘鸣音，偶有打喷嚏，咽痛，无发热，无鼻塞、流涕、四肢酸痛，无夜间盗汗，乏力，无胸闷、心悸等不适。2016.01.04于深圳市龙岗中心医院门诊就诊查血常规示白细胞计数6.95*10^9/L,中性粒细胞百分比66.5%，单核细胞比值10.1%，嗜酸粒细胞比值0.1%，血红蛋白浓度107g/L。予口服“头孢呋辛”抗感染治疗，症状无明显好转，2016.01.07复查血常规较前无明显变化，肺功能检查示FEV160%,FEV1/FVCex104%；1、中度限制性通气功能障碍；2、支气管舒张试验阴性；3、患者配合欠佳，请结合临床考虑，此结果仅供参考。胸片提示支气管炎；主动脉硬化。予以“氨茶碱、头孢克肟”口服后上述症状无明显好转。现患者为求进一步治疗，入住我科，自起病以来，精神、睡眠、食欲较差，大小便正常，近期体重无明显变化。': Int64Index([640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652,\n",
      "            653, 654, 655],\n",
      "           dtype='int64'), '患者3年前开始反复出现咳嗽咳痰，经治疗后可好转（具体不详）。1月余前（3月11日）咳嗽咳痰加重，并有呼吸困难及低热（具体不详），联系120送至西乡人民医院住院（3月11日至4月20日），予吸痰、抗感染（先后予哌拉西林舒巴坦、头孢哌酮舒巴坦、克林霉素、左氧氟沙星）、平喘等治疗，患者呼吸困难较前有所好转，偶有低热(37.5℃)，痰仍多，自主咳痰能力差，需间断吸痰。现为进一步诊治收入我科。患者自起病以来，精神差、睡眠节律错乱，鼻饲进食，小便长期失禁，大便近1月次数增多，消瘦明显（具体不详）。': Int64Index([608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620,\n",
      "            621, 622, 623],\n",
      "           dtype='int64'), '患者3年前无明显诱因出现反复咳嗽、气促，感冒后加重，伴少许咳痰，未规范诊治，症状逐渐加重，10天前受凉后出现咳嗽、咳痰，伴发热，体温38.5度，渐出现气喘加重，伴胸闷，无头痛、头昏，无咽痛、咽痒，无胸痛、咯血，无心慌、心前区压榨感，无端坐呼吸、咯粉红色泡沫痰，无盗汗、乏力，至当地医院就诊，予抗感染、止咳等对症治疗，症状未明显减轻，遂至我院急诊就诊，考虑“慢性支气管炎急性发作”，给予解痉、平喘等对症处理，现为求进一步诊治，收入我科治疗。起病以来，神清，食欲、睡眠一般，二便正常，近期体重无明显变化。': Int64Index([192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
      "            205, 206, 207],\n",
      "           dtype='int64'), '患者3年多前无明显诱因出现胸闷、气喘，活动后气促明显，无咳嗽、咳痰，无胸痛，无头晕、头痛，无恶心、呕吐，无腹痛、腹胀，至我院急诊就诊，查胸片示右肺上叶不张，双中下肺野炎症渗出灶，双侧胸腔积液，BNP8197pg/ml，CRP83mg/L，予抗感染、利尿等治疗后症状好转。曾多次于我院住院治疗，最后1次住院为2015年1月，诊断考虑慢性支气管炎急性发作，阻塞性肺气肿，II型呼吸衰竭，代谢性酸中毒合并呼吸性酸中毒，慢性肺源性心脏病，肺部感染，双侧胸腔积液，高血压病2级极高危组，2型糖尿病，慢性肾功能不全，冠状动脉粥样硬化性心脏病，心功能Ⅲ级，中度贫血，胆囊结石，双肾萎缩，右肾囊肿，左肾内结石，前列腺增生症。入院后予给予抗感染、化痰、控制血压、血糖、维持水电解质平衡等治疗，症状好转出院，出院后未长期家庭氧疗，未长期吸入药物治疗，平素上楼上坡有轻度气促，20余天前受凉后再次出现咳嗽、气喘发作，咳嗽较轻，气喘明显，夜间科平卧，无发热，今日就诊我院急诊，给予阿奇霉素、喘定、地塞米松、拉氧头孢等对症处理，为求进一步诊治，入住我科，病程中，食欲可，近日尿量约每天800-1000ml，大便正常，近期体重无下降。': Int64Index([784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796,\n",
      "            797, 798, 799],\n",
      "           dtype='int64'), '患者3年来反复于冬春季节或受凉感冒后咳嗽、咳痰，以白色泡沫痰居多，伴活动气急，病情逐年加重，近2年间断出现双下肢浮肿，曾多次于正镶白旗医院住院治疗，诊断“肺气肿、肺心病”，好转出院。半个月前于感冒后上述症状加重，咳嗽、咳多量黄痰，痰不利，气急，活动明显受限，并腹胀、双下肢浮肿，于正镶白旗医院住院半个月（具体诊治不详）症状改善不理想，今为明确诊治入我院。患者发病来饮食睡眠一般，大便正常，小便量少，无胸痛、痰血、发热、盗汗及夜间阵发性呼吸困难。\\n': Int64Index([752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764,\n",
      "            765, 766, 767],\n",
      "           dtype='int64'), '患者40余年前即开始受凉后反复咳嗽、气喘，能听到“喘鸣音”，无咯血、大量咳痰，病情呈逐渐进展趋势，偶有双下肢浮肿、胸痛，多次在外院诊治，诊断COPD、呼吸衰竭、肺心病、肺大泡，平素家庭氧疗，间中无创通气，配合不佳，并吸入舒利迭。2月前咳嗽、气喘加重，3天前开始少量血痰，无发热、咳脓痰，无夜间阵发性呼吸困难，无浮肿，曾在外院治疗，效欠佳，为进一步诊治急诊拟“COPD”收住我科。此次起病以来，精神可，食欲欠佳，大小便尚可，近期体重无明显改变。': Int64Index([208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "            221, 222, 223],\n",
      "           dtype='int64'), '患者4天前无明显诱因出现发热，最高体温38.8℃，无畏寒及寒战，咳嗽，咳少量灰黄色痰，稍感气短，无心悸及胸痛，自服“感康、布洛芬、整肠生、利君沙”（具体不详），无效，今就诊我院，查血常规：白细胞8.51×109/L，中性粒细胞比值78.1%。CRP54.52mg/L。胸片示：右下肺斑片状致密影，以右下肺肺炎收入院。发病以来，患者进食欠佳，无恶心、呕吐，腹泻3次，为黄色稀便，感乏力、头痛、全身酸痛，无盗汗及明显消瘦。\\n': Int64Index([927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939,\n",
      "            940, 941, 942],\n",
      "           dtype='int64'), '患者4年前始每于受凉后出现反复咳嗽、咳痰、气喘，快步行走及上楼梯时气喘明显，在外院诊断“慢性阻塞性肺疾病”，予对症治疗后症状可好转，但咳嗽、咳痰、气喘症状易反复发作。4天前患者受凉后再次出现咳嗽、咳痰、气喘，痰不易咳出，活动后气喘明显，伴发热、周身乏力，体温最高达39.8℃，无咯血，无盗汗，无腹痛、腹泻，遂急来我院急诊就诊，查胸部CT示1、右肺上叶斑片影，考虑感染2、心影增大，主动脉及冠状动脉硬化3、肝脏内多发类圆形低密度影，囊肿可能。予抗感染、祛痰、退热、补液、平喘等对症治疗，患者体温降至正常，咳嗽、气喘症状较前稍好转。现为进一步诊治，今日来我院门诊就诊，门诊以“肺部感染、慢性阻塞性肺疾病急性加重期”收入我科。起病以来，精神、睡眠、饮食一般，大小便未见明显异常，体重无明显改变。': Int64Index([224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "            237, 238, 239],\n",
      "           dtype='int64'), '患者4年前开始反复出现咳嗽、咳黄白色粘液痰，多于受凉后出现，每次咳嗽可持续3月左右，无气促、发热等伴随症状，未就诊。10天前患者受凉后再次出现咳嗽、咳痰，咳少许黄白色粘痰，伴活动后气促，休息后可缓解，无畏寒、发热，无胸闷、胸痛，无心悸、气促，无恶心、呕吐等症状，曾在当地医院门诊就诊，考虑“支气管炎”，予对症治疗，具体不详，症状无缓解。故今日来我院门诊就诊，门诊摄胸片示“左下肺少许感染可能”，呼出NO21ppb。为进一步诊治门诊以“慢阻肺左下肺感染”收入我科。此次起病以来，精神一般，食欲及睡眠可，大便4-5天未解，小便正常，体重无明显变化。': Int64Index([384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
      "            397, 398, 399],\n",
      "           dtype='int64'), '患者4年前开始反复出现咳嗽、疾步走有气喘，受凉后易出现，未诊治，后症状好转，一直未正规治疗。10余天前无明显诱因下出现咳嗽、气喘，有较多白痰，稀薄，有气喘，活动后易出现，有发热，未测体温，今晨自觉体温更高（未测），食欲欠佳，为求进一步诊治，入住我科，病程中，无腹痛、腹泻，无头痛、头晕，无关节疼痛，大小便较少，近期体重无明显。': Int64Index([752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764,\n",
      "            765, 766, 767],\n",
      "           dtype='int64'), '患者4年来反复咳嗽、咳痰，伴活动后气喘，多于冬春季和天气骤变时发作。多次在我院呼吸科及干部病科住院，诊断为“慢性阻塞性肺疾病、肺心病”，经治疗病情可暂时缓解，但反复发作,未长期吸氧及雾化治疗。2012年8月住院期间因大量痰液行气管切开术，家属长期予吸痰、翻身护理，最后1次住院时间是2015-1-21至2015-3-20。2天前患者出现咳痰量增多，今晨出现气喘，无发热。家属将其送至我院就诊。近2天来患者精神尚可，大小便正常，体重无改变。': Int64Index([112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "            125, 126, 127],\n",
      "           dtype='int64'), '患者5余年前于天气变化时开始出现“感冒”症状，伴有咳嗽、咳少量白痰，每次大约持续1周左右，未系统诊治。9天前患者受凉后开始出现咳嗽、自觉有痰不易咳出，偶有鼻塞、流涕、打喷嚏，无发热、畏寒、无头晕、头痛，无恶心、呕吐，于当地医院输液治疗4天（具体诊治经过不详）症状无明显缓解并加重，表现为咳嗽、咳黄色粘痰，不易咳出，伴有发热，体温最高37.6℃，有活动后气促明显，夜间不能平卧，无夜间阵发性呼吸困难，无咳粉红色泡沫痰，无胸闷、胸痛，2016-1-10行心脏彩超提示重度二尖瓣反流，中度三尖瓣反流，建议上级医院就诊治疗，遂于01-13于孙逸仙心血管医院住院治疗，查血常规示白细胞计数5.20X10^9/L,中性粒细胞比值85.70%，行胸部CT提示1、左上肺陈旧性病变，请结合临床病史；2、右肺中叶、两肺下叶间质性病变。3、纵隔内多发稍大淋巴结；心脏彩超提示双房扩大，二尖瓣、三尖瓣、主动脉瓣轻度返流，左室整体收缩功能未见异常。LVEF50%。对症予舒普森抗感染、氨溴索化痰、强心、利尿等治疗后症状有所缓解，但仍有反复，现为求进一步治疗，入住我科，此次病程，睡眠稍差，精神、饮食尚可，大小便尚可，近期体重无明显变化。': Int64Index([976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988,\n",
      "            989, 990, 991],\n",
      "           dtype='int64'), '患者5年前常于冬春季节或受凉感冒后出现气急，活动后明显，伴咳嗽，咳痰，未治疗。症状逐年加重，活动耐力逐渐下降。7天前因受凉后气急、喘息加重，夜间不能平卧。伴咳嗽、咳痰，痰为白色，易咳出。伴流清涕，冷空气接触加重。在社区服务站给予“头孢呋辛钠3.75g，利巴韦林0.5g，地塞米松5mg，喘定0.5g”输液治疗两天,患者自觉症状略有缓解。今日为进一步诊治入住我院。病程中患者无发热，无咽痛，无咯血及痰血，无胸痛，无恶心、呕吐，无腹痛、腹泻，无尿频、尿急、尿痛及肉眼血尿。患者自发病以来，精神可，睡眠、饮食欠佳，大小便正常。\\n': Int64Index([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], dtype='int64'), '患者5年前开始反复出现咳嗽、咳痰，白痰，伴气短，有时喘息，多于受凉后出现，就诊于当地卫生院给予药物治疗（具体剂量不详），症状无明显缓解，遂至内蒙古医科大学附属医院就诊，诊断为“支气管哮喘”，并住院治疗，好转出院，后一直吸入信必可都保，1吸/日或2吸/日，发作时加服孟鲁司特钠片（1片每晚一次），自觉效果好，很少门诊随诊。5天前患者受凉后症状加重，伴咽痛，自行口服复方氨酚烷胺片、左氧氟沙星、咳特灵、盐酸氨溴索等药物（具体剂量不详）治疗，无明显缓解；今为进一步治疗来我院就诊，门诊以“支气管哮喘急性发作”收治入院；患者此次发病以来，无发热，无胸痛、咯血，无夜间阵发性呼吸困难，无浮肿，无恶心呕吐，精神、夜眠欠佳，进食差、小便减少，便秘。\\n': Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype='int64'), '患者5年前无明显诱因下出现咳嗽、咳痰、气喘，为白色粘痰，伴活动后胸闷、气喘、乏力，无胸痛、心悸。曾在我科住院，诊断为“慢性阻塞性肺疾病II型呼吸衰竭”。出院后使用无创呼吸机辅助通气。5天前患者受凉后出现咽痛、咳嗽，咳白色粘痰，痰液较难咳出，伴胸闷、气喘，无畏寒、发热，无咳粉红色泡沫痰，无心前区压榨样疼痛，无夜间阵发性呼吸困难。今天至我院急诊科就诊，胸部CT提示“对比2014.7.16旧片，右上肺前段新见团片状磨玻璃影；左肺切除术后改变”，拟“气促查因、肺部感染、呼吸衰竭”收入我科住院。本次起病以来患者精神、食欲正常，睡眠尚可，大小便正常，体重无改变。': Int64Index([688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700,\n",
      "            701, 702, 703],\n",
      "           dtype='int64'), '患者6余年前出现咳嗽、咳痰，咳白色粘痰或白色泡沫样痰，每遇冬春季节好发，常以受凉、感冒为诱因，每次发作持续时间较长，开始病情较轻，不用药也可缓解，以后病情逐渐加重，需要静脉用药才能控制，3年前因呼吸困难、咳嗽、痰多在我科住院治疗诊断为：慢性阻塞性肺病急性加重期，给予积极治疗后好转出院，普食能正常生活。此次入院前一周受凉感冒后，出现咳嗽嗽、黄痰多，且进行性加重的呼吸困难，痰不易咳出，痰中无血丝，无异味，今日来我院门诊就诊，为了进一步诊治入我院。自发病以来，无发热伴盗汗，无胸痛及晕厥，无黄脓痰及消瘦、乏力，精神饮食尚可，二便正常，夜眠好。\\n': Int64Index([208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "            221, 222, 223],\n",
      "           dtype='int64'), '患者6年前始反复出现咳嗽、咳痰，咳少量白粘痰，痰不易咳出，伴活动后气短，每于“受凉、感冒”诱发加重，抗炎等对症治疗好转，未系统治疗。2年前开始上述症状明显加重，曾多次就诊于内蒙古医科大学附属医院，平素吸入噻托溴氨粉吸入剂、信必可都保，自觉效果好。3天前“感冒”后咳嗽加重，干咳为主，伴气短、喘息，胸憋，不能活动，在家未予特殊治疗，昨日就诊我院急诊，给予静点“喘定0.25、甲强龙40mg、左氧氟沙星0.3”治疗1日，症状缓解不明显，今为求进一步治疗入我科。患者自发病以来，无发热，无胸痛、咯血，无夜间阵发性呼吸困难，无浮肿、少尿，精神、夜眠欠佳，进食差、便秘，小便正常。\\n': Int64Index([491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "            504, 505, 506],\n",
      "           dtype='int64'), '患者6年前始天气变化时易反复出现咳嗽、咳痰、气喘，咳白色粘痰。每次发作持续半月，予抗炎平喘治疗后，症状能缓解。2年前始患者自觉间歇游走性前胸痛，每次持续数分钟，疼痛严重时需服用止痛药物。患者曾多次于我科住院治疗，最后1次住院为2015.05.17-2015.05.25，诊断“慢性阻塞性肺疾病急性加重期肺部感染电解质紊乱低钾血症轻度阻塞性睡眠呼吸暂停低通气综合征左肺小结节性质待定肝血管瘤可能前列腺增生症伴钙化慢性浅表性胃炎阑尾炎切除术后足藓过敏性皮炎”等，于抗感染、化痰、平喘等对症支持治疗，症状缓解，出院后自诉规律吸入“沙美特罗氟替卡松”，7天前受凉后再次出现咳嗽咳痰气喘加重，并再次感前胸游走性疼痛，昨日胸痛明显，再次服用止痛药物。为进一步治疗，再次收入我科。自起病以来，患者自觉双下肢乏力，双足轻度水肿，纳差，大便便秘，小便一般。近期体重无明显变化。': Int64Index([320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
      "            333, 334, 335],\n",
      "           dtype='int64'), '患者6年前开始渐出现受凉后咳嗽、咳痰，痰液多为白色泡沫状，偶为黄色粘稠样，无血丝及脓臭味。不伴胸痛、胸闷及气急。反复发作。3年前渐开始出现活动时气促、气短，先后多次在我科住院，诊断为“慢性阻塞性肺疾病”，行对症治疗后好转出院。在家未坚持氧疗，未坚持用药。今日再次出现咳嗽，咳白痰，胸闷，活动后气喘明显，全身酸痛，故来我院，以“AECOPD”收入我科。患病以来，精神、食欲欠佳。': Int64Index([272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
      "            285, 286, 287],\n",
      "           dtype='int64'), '患者6年前感冒后出现发热，体温不详，伴有咳痰、气促，活动后为主，无发冷、寒战，无恶心、呕吐，无尿频、尿急、尿痛，于我科住院治疗，完善相关检查，具体诊治过程不详，诊断“慢阻肺、肺部感染等”，给予对症处理，症状好转出院。此后天气变化时间断咳痰、气促发作，规律门诊复诊，在家坚持长期氧疗，对症药物治疗（具体不详），平素活动尚可，快步走及上楼均可。半年前患者无明显诱因出现气促加重，活动后明显，行走100m左右或上二楼即可出现，伴有咳痰，痰粘不易咳出，伴有心悸，无发热，无胸闷、胸痛，无夜间憋醒，行肺功能示极重度混合型通气功能障碍，FEV125%，FEV1/FVC50.73%，建议住院治疗，患者拒绝，此次气促逐渐加重，夜间不能平卧，无夜间阵发性呼吸困难，无咳粉红色泡沫样痰，无咯血，无胸痛，于11月20日在我院体健查胸片示慢性支气管炎，双下肺感染，心电图提示窦性心律不齐，现为求进一步诊治收入我科，病来患者精神状态可，饮食、睡眠可，大小便正常，体重未见明显变化。': Int64Index([ 992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1002,\n",
      "            1003, 1004, 1005, 1006, 1007],\n",
      "           dtype='int64'), '患者6年前无明显诱因反复于冬春季节或受凉感冒后咳嗽、咳痰，咳白色泡沫痰多，平时自服肺宝三效、氨茶碱、25味肺病胶囊等，症状可缓解，曾于呼市第一医院住院2次，诊断“慢性阻塞性肺疾病、慢性肺源性心脏病”，治疗好转出院。曾多次住我科，诊断为“慢性阻塞性肺疾病、慢性肺源性心脏病”给予抗炎、平喘、无创呼吸机辅助通气治疗好转出院，20余天前患者咳嗽、咳痰加重，咳黄色粘痰，伴明显气短，于家中口服药物对症治疗（具体不详），患者未见明显好转，1周前开始出现神志模糊，胡言乱语，今为进一步诊治收入我科。患者发病以来精神及进食、睡眠差，近20余天卧床，无胸痛、无脓臭痰、无痰中带血、无盗汗，大小便正常。\\n': Int64Index([334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346,\n",
      "            347, 348, 349],\n",
      "           dtype='int64'), '患者7天前因感冒后出现咳嗽，基本以干咳为主，伴有胸憋气短，活动不受限，无夜间阵发性呼吸困难，无发热及胸痛，无心悸及心前区不适，无吞咽困难及声音嘶哑。昨日于我院门诊静滴哌拉西林舒巴坦1次，病情未缓解。为了进一步诊治入我科，发病以来精神食欲尚可，二便正常。\\n': Int64Index([619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631,\n",
      "            632, 633, 634],\n",
      "           dtype='int64'), '患者7年前开始反复出现咳嗽，咳少量白痰，无呼吸困难，一般于气候变化时出现，每年咳嗽、咳痰症状持续时间大于3个月。近4年余开始反复出现气喘，曾多次于我科住院治疗，2周余前我科住院时诊断为慢性阻塞性肺疾病急性加重期、慢性II型呼吸衰竭、慢性肺源性心脏病、肺动脉重度高压，经抗感染、化痰、平喘、吸氧等对症处理，好转出院。出院后规律吸入“沙美特罗替卡松”及雾化，长期家庭氧疗，每天吸氧约10小时。1周前患者出现气喘症状加重，伴有咳嗽、咳少量黄痰，平地走4米后出现气喘，休息后可缓解，夜间可平卧，无咳粉红色泡沫痰，无咯血，无发热、盗汗，无胸闷、胸痛，无恶心、呕吐，无双下肢水肿，现为进一步治疗收住我院。起病以来，患者精神、睡眠可，食欲欠佳，二便正常，近期体重无明显变化。': Int64Index([880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892,\n",
      "            893, 894, 895],\n",
      "           dtype='int64'), '患者7年前感冒后出现咳嗽，咳少量白色黏液痰，伴发热，体温最高38.5℃，伴畏寒、盗汗，伴鼻塞、流涕，无气喘，无胸痛、胸闷，无夜间阵发性呼吸困难，至外院就诊，诊断“肺炎”，予抗感染、止咳、祛痰治疗，后症状缓解出院。患者7年间咳嗽、咳痰反复发作，曾多次于外院就诊，均予抗感染、止咳、祛痰治疗，症状均可缓解。2月前无明显诱因咳嗽再发，伴咳少量白色黏液痰，无咯血，无发热，无胸闷、胸痛，无夜间阵发性呼吸困难，现为进一步诊治至我院就诊，拟“咳嗽查因”收入我科。患者起病以来，饮食可，睡眠欠佳，大小便正常，体重有无明显改变。': Int64Index([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], dtype='int64'), '患者7年前无明显诱因出现咳嗽、气喘，爬楼时明显，多于天气变化时发作，自服“茶碱片”可缓解，未正规症状。4月余前受凉后出现咳嗽、发热，最高体温不详，咳白粘痰，伴气喘，无胸闷、胸痛，无心悸等症状，曾在深圳市仁爱医院及北大深圳医院就诊，考虑“AECOPD”，予“左氧氟沙星”抗感染，“甲强龙”平喘等对症治疗，症状无好转，2月前感咳嗽、咳痰、气喘加重，伴有夜间阵发性呼吸困难，后至北京大学深圳医院心内科就诊，予“利尿”等对症治疗，自觉症状有好转。2天前再次出现发热，体温不详，故来我院就诊，为进一步诊治以“咳嗽查因冠心病”收入我科。此次起病以来，精神一般，食欲及睡眠可，大小便正常，体重无明显变化。': Int64Index([240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "            253, 254, 255],\n",
      "           dtype='int64'), '患者7年前无明显诱因开始反复发作咳嗽、气喘，自闻喘鸣音，咳白色泡沫痰，受凉、感冒后易发作，服\"茶碱\"治疗，症状可缓解，近3年来气促发作较前频繁，服用上述药物后气喘不能完全缓解，多次在我院诊治，考虑“慢性阻塞性肺疾病”，予化痰、雾化平喘、抗感染等治疗后好转。曾并发气胸，在我院诊治，予穿刺引流后好转，5天前天气转凉后出现咳嗽、气喘再发，无明显咳痰，稍活动即气喘明显，夜间能平卧，无发热，无咯血，无盗汗，无咳粉红色泡沫痰，无胸痛、心悸，来我院就诊，查血常规中性粒细胞比值NEUT%79.7↑%；电解质钠NA125.1↓mmol/L；超敏C-反应蛋白定量SCRP-J14.8↑mg/L；予\"左氧氟沙星（国）0.4\"等静滴治疗，症状略改善。为进一步诊治，收入我科。起病以来，无恶心、呕吐、反酸、纳差、腹痛、腹胀、黑便；精神倦，胃纳可，睡眠欠佳，大便正常，小便频数，夜尿4次/天，近期体重无明显变化。': Int64Index([448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "            461, 462, 463],\n",
      "           dtype='int64'), '患者8年前多于天气变化或受凉后出现反复咳嗽，干咳为主，无明显咳痰，无气促，无发热，无胸闷、胸痛，曾多次于我院门诊及我科住院治疗，诊断“慢性阻塞性肺病”，平素坚持长期家庭氧疗及应用“舒利迭、噻托溴铵”吸入药物治疗。1月前患者在公园不慎受凉后再次出现咳嗽，无明显咳痰，无发热，无胸闷、气促，于我院门诊就诊,完善胸片提示左下肺野感染可能,对症予阿奇霉素抗感染治疗后症状好转,近2日患者感少许气促伴心前区胀痛,无夜间阵发性呼吸困难,无咳粉红色泡沫样痰,无夜间盗汗，现为求进一步诊治收入我科.此次起病以来,一般状态可,饮食、睡眠可,二便正常，近期体重无明显变化。': Int64Index([720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
      "            733, 734, 735],\n",
      "           dtype='int64'), '患者8年前开始反复出现咳嗽、气喘，受凉后或冬季易发作，2013年曾于我科住院，考虑“慢性阻塞性肺疾病急性加重期”，长期吸入“舒利迭”及长期家庭氧疗（每日约5),近2年上楼、上坡、冲凉有气喘，10余天前受凉后再次出现咳嗽、气喘发作，咳嗽明显，少许白色粘痰，无发热，无胸痛，无盗汗，食欲可，精神可，无头痛、头晕，自行吸入上述药物及延长吸氧18小时，症状未见改善，后就诊于罗湖区人民医院，给予“头孢替安”应用，皮试出现过敏，后改为“左氧氟沙星、克拉霉素”抗感染及氨茶碱应用，症状有减轻，为求进一步诊治，今日入住我科，病程中，食欲可，精神一般，大小便正常，体重无下降。': Int64Index([624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "            637, 638, 639],\n",
      "           dtype='int64'), '患者于10余年前开始反复出现咳嗽，咳白粘痰，伴喘息，无发热，无咯血，无头晕、头痛，无恶心、呕吐，在诊所予对症治疗后症状可好转，但咳嗽、咳痰症状易反复发作，渐出现活动后气喘、气促，2周着凉感冒后，上述症状再发，自觉气短、气促，伴乏力，咳嗽、痰液粘稠，不易咳出。于深圳是第二人民医院就诊“慢性阻塞性肺部急性加重期肺源性心脏病”。给予抗感染、平喘对症治疗，无好转，为求治疗收入院。近来精神、饮食稍差，睡眠可，尿频、尿急，大便如常，体重未见明显变化。': Int64Index([704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716,\n",
      "            717, 718, 719],\n",
      "           dtype='int64'), '患者于10余年前无明显诱因下开始出现咳嗽、咳痰、气喘，咳白色粘液痰，量少，不易咳出。气喘以活动后明显，多于天气变化或受凉后出现，无发热，无头痛、头晕，无胸闷、心悸，7年前曾于外院查胸片示肺气肿。患者于1月余前电话购物途径自行购买药物服用后（含中药，具体不明确）出现双下肢水肿，水肿为对称、凹陷性。20天前出现腹胀，自觉消化不良，现为进一步诊治，收入我科。起病以来，睡眠、精神、胃纳可，大小便减少，体重无明显变化。': Int64Index([576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588,\n",
      "            589, 590, 591],\n",
      "           dtype='int64'), '患者于10余年前无明显诱因开始出现咳嗽，咳白粘痰，气喘，无明显呼吸困难，多于受凉后出现，于2010年4月于我科住院，诊断为“慢性阻塞性肺气肿性支气管炎、慢性肺源性心脏病、心功能不全、II型呼吸衰竭”，予抗感染、平喘等治疗后病情可好转。病情可反复，在家未规律吸入“舒利迭”等治疗，无家庭氧疗。1周前，患者再次咳嗽，咳白粘痰，不易咳出，活动后气喘，眼睑部、双下肢浮肿，四肢乏力，偶感胸闷、头晕，无发热、咯血，夜间可平卧休息，于当地诊所诊治，予“感冒药”治疗，效果不佳，遂就诊于我科门诊，查血气PH7.244氧分压48.2mmHg，二氧化碳分压79.7mmHg，胸片示两肺纹理稍强，予阿奇霉素、氨茶碱治疗后，气喘、浮肿减轻，为求进一步诊治，遂入住我科。起病以来，患者精神、饮食、睡眠欠佳，大小便正常，体重无明显改变。': Int64Index([464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
      "            477, 478, 479],\n",
      "           dtype='int64'), '患者于10年前冬春开始出现咳嗽，咳痰，咳黄白色黏痰，每年持续3月以上，呈反复发作，近5年每于冬春季节在当地医院常规输液。近30天症状加重，咳嗽、咳少量白色黏痰，伴喘憋，不能下地活动，夜间不能平卧，伴有食欲减退，多次住我科治疗，诊断为“慢性阻塞性肺病急性发作期，肺气肿，肺感染，肺源性心脏病，心功能不全”给予对症治疗症状缓解出院。出院后不做呼吸机治疗（已自购呼吸机）。3天前上述症状再次加重，几乎不进食，少量咳嗽、咳白痰，为求进一步诊治，门诊以“慢性阻塞性肺病急性加重”收入院，患者发病以来无发热，睡眠欠佳，无胸痛，无夜间阵发性呼吸困难，无恶心、呕吐，无腹痛、腹泻，小便正常，双下肢无浮肿。\\n': Int64Index([136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "            149, 150, 151],\n",
      "           dtype='int64'), '患者于1个月前无明显诱因出现咳嗽，呈干咳，时轻时重，伴胸闷、气短，活动后加重，自行口服抗感冒药后症状未缓解。近1周咳嗽症状加重，就诊于我院急诊，化验血常规示中性粒细胞比值增高，社区门诊输液（具体用药不详）3天，症状无改善。昨日出现咳黄色痰液，今为系统诊治收入院，患者病程中，无发热，无胸痛、咯血，无头晕，无夜间阵发性呼吸困难，双下肢无凹陷性水肿。精神一般，食欲、睡眠可，大小便如常。\\n': Int64Index([88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102,\n",
      "            103],\n",
      "           dtype='int64'), '患者于1天前在工地自行摔倒在地，出现头痛、头晕，头痛呈持续性，阵发性加重，伴恶心，未呕吐，无昏迷，无肢体感觉及活动障碍，无二便失禁，家属急送至商都当地医院行头颅CT检查，回报蛛网膜下腔出血，转往乌兰察布中心医院，未予治疗，后家属为进一步诊治，急转至我院急诊，急诊行头血管CTA检查（2018-5-20我院）：1.右侧大脑中动脉M1段动脉瘤（大小约7mm×5mm）2.双侧颈内动脉颅内段多发钙化斑块并多发局限性狭窄；3.双侧颈内动脉岩骨段管腔细；4.脑动脉硬化并多发局限性狭窄5.右侧大脑前动脉A1段、A2段管腔节段性纤细。急诊以“动脉瘤”收住我科。患者自发病以来，精神差，未进饮食，二便如常。\\n': Int64Index([350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
      "            363, 364, 365],\n",
      "           dtype='int64'), '患者于1月前无明显诱因出现气短，活动后为著，无咳嗽、咳痰，无发热，就诊于土左旗医院，诊断为“心功能衰竭、胸腔积液、重度贫血”（未见资料），给予治疗（具体不详）后症状缓解出院，4天前气短症状加重，伴阵发性胸前区疼痛，持续10-30分钟，今为求进一步诊治就诊于我院。病程中，患者无头晕、头痛，二便正常，精神、饮食、睡眠欠佳，体重减轻。\\n': Int64Index([864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876,\n",
      "            877, 878, 879],\n",
      "           dtype='int64'), '患者于2012年4月在外院行喉癌切除术后出现胸闷、气促，位于双侧胸前区，持续时间约1分钟至数十分钟不等，活动后加重，卧床休息缓解，无胸痛、心悸，无发热、盗汗，无头晕、头痛，未正规诊治。2年前开始，无明显诱因下出现咳嗽、咳痰，咳白色泡沫痰，量中，伴胸闷、气促，性质与伴随症状大致同前，无咯血，无恶心、呕吐，入住我科，予对症支持治疗，行胸部CT考虑右肺癌可能，由于喉癌切除术后无法配合支气管镜检查。此后7次于我科给予CIK细胞输注治疗、营养支持、维持电解质平衡等治疗后好转出院，于2014-4-29行肺肿瘤氩氦刀冷冻消融术+穿刺活检术，病理结果示低分化鳞状细胞癌。患者2014-9-11入院复查CT未见肿瘤复发。2月前开始，患者自诉气促较前稍明显，近期偶有咳嗽，少许白痰，无发热，无胸痛，饮水无呛咳，为求进一步诊治，入住我科，病程中，食欲尚可，大小便正常，近日体重无下降。': Int64Index([960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972,\n",
      "            973, 974, 975],\n",
      "           dtype='int64'), '患者于20年前出现咳嗽，咳痰，咳白色粘液痰，活动后明显，在家自行口服化痰药（具体药名及剂量不详），可稍缓解，2个月前出现呼吸困难，不能平卧，伴有咯血，呈鲜红色，于2018年3月6日症状加重，就诊于内蒙市医院住院治疗，给予抗炎、止血对症治疗后咯血好转，仍有咳嗽、咳痰，呼吸困难无明显好转，近日患者症状于当地社区医院进行治疗（具体不详），输注白蛋白，今日患者症状加重呼“120”急诊送入我院，急诊给予补液，抗炎治疗，症状未见好转，于4月11日12时30分以“肺源性心脏病”转入我科，病程中患者精神状态欠佳，饮食、睡眠差，周身乏力，胸闷、气短、呼吸困难，不能平卧，咳嗽，咳痰，咳白色粘液痰，无恶心、呕吐，上腹痛，无腹胀、腹泻，大便正常，小便减少。\\n': Int64Index([587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599,\n",
      "            600, 601, 602],\n",
      "           dtype='int64'), '患者于20年前始反复出现咳嗽、咳白色稀痰，多于受凉或感冒后加重，多次在当地医院门诊就诊，诊断为“支气管炎”，予抗炎祛痰治疗后，症状能缓解，但易复发。每月皆有发作。1月前患者受寒后，再次咳嗽、咳淡黄色痰，咳嗽频繁，后逐渐感左侧季肋部隐痛，咳嗽时疼痛加重，无放射痛，曾在小区诊所予输液治疗，咳嗽有缓解。但不能消失，1天前始自觉爬楼时有气促。患者至我院门诊就诊，摄胸部CT提示左肺感染、慢性支气管炎，为进一步治疗，收住入院。发病来，无明显畏寒寒战高热，无长期低热、盗汗及咯血，无咳粉红色泡沫痰，无夜间阵发性呼吸困难，无脚肿脚痛，无反酸嗳气，近1月消瘦2斤，大小便正常。睡眠、纳食欠佳。': Int64Index([896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908,\n",
      "            909, 910, 911],\n",
      "           dtype='int64'), '患者于2年前始因”闻烟味”出现胸憋、气短，活动后加重，未系统治疗，长期不规律口服肺宝三效片，去痛片，患者诉口服药物后自觉症状好转，2个月前患者因“饮食不当”出现咳嗽不止，无痰，气短加重，就诊于乌兰察布市恩和医院，住院治疗10天，口服中药治疗（具体量名不详），症状有所缓解，5天前患者气短加重，夜间不能平卧，就诊于乌兰察布市中心医院，住院治疗4天，给予静点头孢（具体剂量不详），其他治疗不明，症状有所缓解，近2日夜间可平卧，今为系统诊治收入院，患者病程中无四肢浮肿，无有头晕，无头痛，无胸痛，无发热，无咯血及痰中带血，无呕吐、腹痛，精神、食欲一般，睡眠差，大小便如常。\\n': Int64Index([635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647,\n",
      "            648, 649, 650],\n",
      "           dtype='int64'), '患者于2年前无明显诱因出现反复咳嗽、咳痰，咳少许白粘痰，易咳出，以冬春季节及天气转冷为著，每年持续3个月以上，曾多次就医我院，经系统诊治考虑“慢性阻塞性肺疾病、肺部阴影性质待查”予以抗感染、化痰、平喘对症，症状缓解。5天前患者无明显诱因上述症状加重，出现活动后气短、胸闷、喘息，轻度活动及剧烈咳嗽后即可出现气短、喘息症状，曾就诊于我院中医科，给予中药治疗（具体药物、剂量不详）后，效果欠佳，胸闷、气短明显，不能平卧，为求进一步诊治入住我科。发病以来，无不明原因体重下降，无盗汗、乏力，无头晕、头痛，无腹胀、腹痛、腹泻，无尿频、尿急、尿痛，无皮疹及四肢骨关节异常，精神、饮食可，睡眠可，二便正常。\\n': Int64Index([56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], dtype='int64'), '患者于3天前无明显诱因出现呼吸困难，症状逐渐加重，活动后明显，无明显咳嗽、咳痰、胸痛等症状，夜间可平卧；未正规诊疗，今晨活动后气短明显加重，就诊我院急诊科，胸片示左肺上野及右肺下野结节影，右肺下野心缘旁片状高密度阴影，炎症可能，心影增大；予利尿、对症等治疗，病情有所缓解，今为求进一步诊治入我院。自患病以来，无头晕、头痛，无乏力、盗汗，无恶心、呕吐，精神、睡眠、饮食欠佳，大小便正常。\\n': Int64Index([286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "            299, 300, 301],\n",
      "           dtype='int64'), '患者于3年前出现间断咳嗽,以干咳为主,未予重视；3月前咳嗽加重，咳少量白粘痰，不易咳出，自服中药、止咳药，咳嗽症状有所缓解；4天前体检行胸部CT检查示：右肺上叶球形结节影，内可见空洞；为明确诊断，今日上午行支气管镜检查，镜下见右肺上叶有脓性分泌物；检查过程中患者出现氧饱和度下降，最低75%，听诊：双肺呼吸音弱，双肺可闻及干鸣音；考虑气道痉挛，立即给予甲强龙入小壶，苯海拉明肌注；同时给予局部吸入沙丁氨醇气雾剂，简易呼吸器辅助呼吸，氧饱和度渐上升；血压最低85/50mmHg,给予低分子右旋糖酐补液、对症治疗；之后患者出现头痛，恶心、呕吐，给予胃复安肌注；急查心电图未见明显异常；后收住院，心电监护示：心率95次/分，窦性心律，律齐，脉氧饱和度99%（鼻导管吸氧），呼吸20次/分，血压110/70mmHg。\\n': Int64Index([571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583,\n",
      "            584, 585, 586],\n",
      "           dtype='int64'), '患者于3年前无明显诱因出现肛内脱出肿物，每于大便时，便后肿物能自行还纳，偶有便血，每于大便后，血色鲜红，每次约2-3滴，自行用痔疮膏后病情得以控制。3年来上述症状反复发作，昨日上述症状突然加重，肿物不能还纳，嵌顿于肛门口，大便干结，排出费力，家属给予开塞露纳肛效果差，同时伴有少量便血，血色鲜红。今日患者求治于我科。患者入院症见：肛门部疼痛不适，腹胀，胸闷。患者自发病以来无发热，无呕吐，无明显消瘦，无语言及意识障碍，精神饮食可，小便正常。\\n': Int64Index([555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "            568, 569, 570],\n",
      "           dtype='int64'), '患者于4年前无明显诱因出现咳嗽、咳痰，痰呈白色泡沫状，量少，伴活动后气短，无发热，无痰中带血，每逢冬春季节及寒冷季节明显，每次发作持续2周余，活动耐力逐渐下降，半年前曾于我院诊断“慢性阻塞性肺病”住院治疗，出院后一直服用“倍他乐克、红霉素”（常规量），每天吸氧3-5小时。9天前因“着凉”后再次出现咳嗽，咳少量白色粘痰，气短，伴夜间发热，无大量黄浓痰，无痰中带血，无夜间阵发性呼吸困难，无头痛及晕厥，自测体温最高39℃，自服“莫西沙星”，症状无明显好转，今日为进一步诊治来我院门诊，门诊以“慢阻肺急性加重期”收入院。患者自发病以来无胸闷、心悸，无胸痛、咯血，无头痛、头晕，偶有恶心，无呕吐，无腹痛、腹泻，无双下肢浮肿，精神差，食欲欠佳，大便、小便正常，自觉体重稍减轻。\\n': Int64Index([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "            133, 134, 135],\n",
      "           dtype='int64'), '患者于4年前无明显诱因出现慢性咳嗽、咳痰，痰呈白色，每到春冬季节加重，曾于我院因肺气肿、肺部感染多次住院治疗好转出院。3天前患者无明显诱因出现心悸，无胸痛、胸闷、气短，就诊于塞罕区医院静脉输液“舒血宁、奥美拉唑”等药物，心悸症状好转，1天前，患者因着凉后出现发热，体温最高达38.4摄氏度，伴咳嗽、咳痰，痰为黄色粘痰，不易咳出，遂就诊于我院急诊科，以肺部感染收入我科，患者自发病以来无恶心、呕吐，无痰中带血，无咯血、胸痛，精神一般，饮食差，二便正常。\\n': Int64Index([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], dtype='int64'), '患者于4月余前无明显诱因出现咳嗽、咳痰，咳白色粘痰或白色泡沫样痰，常以受凉、感冒为诱因，持续时间较长，开始病情较轻，不用药也可缓解，以后病情逐渐加重，并出现喘息、气急，基本不影响日常活动，1周前上述症状加重，喘息、气急较重，活动耐力明显下降，咳嗽、咳痰重，量多易咳出，痰中无血丝、无异味，于家中自行口服止咳药物（具体用药不详，无其他治疗），疗效欠佳。为了进一步诊治入我院，患者发病以来无发热及胸痛，无头晕头痛，无声音嘶哑及吞咽困难，无腹痛腹胀，无明显的消瘦及乏力，精神饮食尚可，二便正常，近期体重无明显变化。\\n': Int64Index([224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "            237, 238, 239],\n",
      "           dtype='int64'), '患者于5天前出现咳嗽，咳黄痰，发热，最高体温为38.6℃，伴畏寒、寒颤、气喘，无咯血，无胸闷、气促。至北大医院就诊，予口服“头孢类、利巴韦林”等抗感染对症治疗后，症状有所好转。昨夜再次出现发热、咳嗽、气喘症状，至我院急诊就诊，查血液常规分析白细胞计数20.87X10^9/L，中性粒细胞比值93.3%，hsCRP279.56mg/L；胸部CT与2014-10-4胸部CT进行比较，1.左肺上叶前段结节较前增大，考虑肺癌可能；慢支、肺气肿；两肺下叶、左肺上叶下舌段广泛间质性感染；双侧胸腔积液较前吸收；心包积液同前；食管下段增厚同前。予“头孢”治疗后有好转。现为进一步诊治入住我科。患者起病以来精神、食欲、睡眠一般，大便稀，小便如常，体重无明显下降。': Int64Index([432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
      "            445, 446, 447],\n",
      "           dtype='int64'), '患者于5天前因劳累后出现咳嗽咳痰，发热，最高体温达40℃，无寒战，有痰不易咳出，夜间咳嗽加重伴出汗，活动及剧烈咳嗽后出现轻度气短，自行口服布洛芬等治疗（具体剂量不详），体温可降至正常，但病情反复。就诊于社区门诊，给予静滴头孢、喘定、氨溴索治疗3天（具体剂量不详），体温恢复正常，但仍有咳嗽、咳痰，咳少量黄痰。后就诊于我院门诊，血常规示：白细胞8.57*10^9/L，中性粒细胞比值80.20%↑，淋巴细胞比值10.90%↓，C反应蛋白100.580mg/L↑。胸部CT示：右肺炎症，请治疗后复查，2.脂肪肝。今为进一步诊疗，收入我科。病程中，患者无明显头晕、头痛，无心前区疼痛，无腹痛、腹泻，剧烈咳嗽时可出现干呕，精神睡眠差，饮食一般，大小便正常。\\n': Int64Index([959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971,\n",
      "            972, 973, 974],\n",
      "           dtype='int64'), '患者于5天前摔倒后出现头晕，伴恶心、呕吐，呕吐物为胃内容物，伴视物模糊，不伴有视物旋转，无耳鸣，无头痛，无肢体无力及行走不稳，就诊于当地医院，予以静脉输液对症治疗（具体药名及用量不详）4天，症状未见好转。今为系统诊治入我院，门诊以“头晕原因待查”收住院，病程中，患者无饮食呛咳，无抽搐及意识障碍，无语言障碍。自发病以来，精神状态可，二便可控，睡眠饮食如常。\\n': Int64Index([720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
      "            733, 734, 735],\n",
      "           dtype='int64'), '患者于5天前摔倒后出现胸闷、呼吸困难，伴有腰痛，惧怕呼吸，不敢咳嗽，有痰不易咳出，伴有右侧肢体活动受限加重。随后在当地医院行CT检查示：右侧脑软化多发脑缺血样变肺部感染慢性支气管炎肺动脉高压双侧胸腔积液心包积液左侧髋关节骨折术后。各项化验异常结果示：D-二聚体10.0，肌酸脱氢酶759，谷草转氨酶364。心电图示：Ⅰ度房室传导阻滞完全右束支传导阻滞ST-T端异常状态。检查后未在当地医院治疗，今早入我科门诊就诊，门诊以“肺部感染、Ⅰ型呼吸衰竭慢性支气管炎急性发作高血压3级脑出血后遗症左侧肢体偏瘫肺动脉高压双侧胸腔积液心包积液左侧髋关节骨折术后左侧股骨头骨折不除外”收住院。发病以来：神志模糊，食欲减退，急性病容，小便失禁，大便尚可。\\n': Int64Index([699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
      "            712, 713, 714],\n",
      "           dtype='int64'), '患者于5年余前无确切诱因逐渐出现咳嗽，咳白色泡沫痰，并伴气短，短距离活动后出现喘息。气短，一直未系统诊疗，于私人渠道购进成分不明药品，口服约1年，症状稍有缓解，1天前患者上述症状加重，并伴意识模糊，问话不能正确对答，急入我院，病症中患者食欲一般，无明显发热畏寒，咳痰加重，咳痰量增多，气短加重，间断腹胀、下肢浮肿，自服利尿药（具体成分及剂量不详）可缓解，尿便可。\\n': Int64Index([523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535,\n",
      "            536, 537, 538],\n",
      "           dtype='int64'), '患者于6天前感冒后出现咳嗽、咳痰症状，痰量少，不易咳出，患者自诉有发热症状，未测体温，不伴气短、胸痛、咯血等症状，自行口服头孢类药物（具体药物及剂量不详），症状未见明显缓解，今日就诊于当地医院，行胸部X线提示右肺下叶可见斑片状密度增高影，为求进一步诊治就诊于我科门诊，门诊以“肺炎”收住我科，患者自发病以来，精神食欲睡眠可，大小便正常，无体重减轻。\\n': Int64Index([603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
      "            616, 617, 618],\n",
      "           dtype='int64'), '患者于6年余前无明显诱因反复出现心悸，偶伴头晕、乏力，无胸闷、胸痛，持续数分钟至数十分钟不等，休息或口服药物（具体不详）症状可消退,曾到当地医院就诊，诊断为心房颤动，未规律服药就诊，1年前于我科住院治疗，诊断为1.冠心病稳定型心绞痛心功能II级（NYHA分级）心律失常心房颤动频发室性早搏腔隙性脑梗塞高血压病2级很高危组，行心脏彩超主动脉硬化、主动脉瓣退行性变并轻度反流，二尖瓣后叶瓣环钙化并少量反流，三尖瓣轻度反流，肺动脉压轻度升高（32mmHg），弥漫性室壁运动异常，LVEF53%。入院后予抗血小板、抗凝、调脂、控制血压心率、减轻心脏负荷及对症支持治疗，于2014-10-10行冠脉造影示冠脉血管粗大，血流缓慢，LM管腔未见明显狭窄，LAD中段弥漫性狭窄约60-70%，远端血流TIMI2级，LCX未见明显狭窄，RCA近段、中段瘤样扩张，管壁不整，远端血流TIMI2-3级。出院后规律服药治疗。1天前患者无明显诱因出现气促，伴嗜睡、咳痰，黄白色痰，无大汗淋漓，无胸痛、放射痛、心悸、气促，无恶心、呕吐、腹痛，至我院门诊就诊，门诊拟“气促查因”收住我科。患者起病来精神、睡眠尚可，食欲欠佳，大小便正常，体重无明显改变。': Int64Index([656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668,\n",
      "            669, 670, 671],\n",
      "           dtype='int64'), '患者于7年前无明显诱因出现咳嗽、咳痰，咳少量白色黏痰，不易咳出，抽烟后咳嗽咳痰症状加重，未给予重视，10天前咳嗽、咳痰症状加重，期间又一次痰中带血丝，伴有右侧胸痛，呈闷痛，间歇性疼痛，深呼吸及活动时无关，无发热，无消瘦及乏力，无声音嘶哑及吞咽困难，无心悸及心前区不适，未进行诊治。今为进一步诊治遂来我院我科就诊，以“胸痛待查”收入院，病程中无头晕头痛，无恶心呕吐，无腹痛腹泻，精神状态可，睡眠可，饮食及二便未见异常，无双下肢浮肿，近期体重无明显变化。\\n': Int64Index([667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679,\n",
      "            680, 681, 682],\n",
      "           dtype='int64'), '患者于8年出现咳嗽、咳痰、气喘，于当地医院行肺功能检查明确诊断为慢性阻塞性肺疾病(具体程度不详)，予抗感染、抗炎、解痉、平喘治疗后好转。此后上述症状反复发作，多次入院治疗，诊断为慢性阻塞性肺疾病、肺源性心脏病，予相关治疗后暂好转，3年前开始长期规律吸氧治疗，未规律进行吸入剂治疗。7天前因“跌倒至左肱骨颈骨折”卧床，后再次出现气喘、咳嗽，咳较多黄色脓痰，不易咳出，就诊于宝安区中医院骨科，予祛痰、解痉治疗，上述症状无缓解，精神较差，为进一步诊治收入院。此次起病以来，患者精神较差，嗜睡，食欲较差，大小便正常，体重无明显下降。': Int64Index([160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
      "            173, 174, 175],\n",
      "           dtype='int64'), '患者于8月前无明显诱因出现咳嗽、咳痰，咳嗽以干咳为主，无畏寒、发热，无胸闷、气促，无午后潮热、盗汗，无腹痛、腹胀，无尿频、尿急、尿痛，无头痛、头晕。被家属送至当地医院就诊，行胸部CT提示左侧前纵隔77X122mm实质性占位病变；慢性支气管炎，轻度肺气肿并右下肺炎性感染。增强CT提示左侧前纵隔实质性占位病变考虑淋巴瘤胸腺瘤；轻度支气管炎、轻度肺气肿并右下肺炎性感染。后于我院胸外科住院诊治并行左侧前纵隔实质性占位病变根治术手术治疗，病理提示（左前纵隔）病变为B2型胸腺瘤，术后足疗程放疗，病情好转出院。10余天前患者无明显诱因出现发热，体温最高为39.4℃，夜间发热为主，于当地医院住院治疗，行胸部CT示右肺及左肺舌段炎性病变；左侧前纵隔胸腺瘤切除术后；左下局部胸膜炎；慢性支气管炎、肺气肿。予头孢哌酮他唑巴坦、莫西沙星抗感染、止咳、化痰等对症治疗后，仍反复高热，复查胸部CT见双肺炎症较前进展。现为进一步诊治来我院就诊，门诊以“发热查因肺部感染”收入我科。患者近期，精神、睡眠、胃纳一般，大小便如常，体重无明显减轻。': Int64Index([832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "            845, 846, 847],\n",
      "           dtype='int64'), '患者于入院1周前无明显诱因出现发热，最高体温达39.6℃，伴有大汗淋漓，自行口服“安瑞克”体温下降，后再次发热，就诊于社区门诊，给予静滴“头孢噻肟、病毒唑”（具体剂量不详）1天后退热，共用药4天。后外出北京，停止静滴改为口服“头孢克肟胶囊”（2粒日/2次）1天后，再次发热，就诊于首都医科大学宣武医院，行胸片示：左肺感染。给予“莫西沙星”（具体剂量不详）静滴1次，诉未见明显缓解。今为求进一步诊治，就诊我院，门诊以“社区获得性肺炎”收住院。患者自发病以来，伴有流涕，偶有咳嗽、咳痰，有头痛、乏力，无心慌、气短，无恶心、呕吐，无腹痛、腹泻，精神、饮食一般，睡眠可，二便如常，体重未见明显变化。\\n': Int64Index([160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
      "            173, 174, 175],\n",
      "           dtype='int64'), '患者于入院前1月无明显诱因出现双下肢无力，走路不稳，伴有双下肢水肿，呈凹陷性，无意识障碍及抽搐发作，无言语含糊，无头晕、头痛，无恶心呕吐，无视物模糊及视物旋转，无吞咽困难及饮水呛咳，未予诊治。症状持续不缓解，今为进一步明确诊治来我院门诊就诊，以“双下肢无力原因待查”收入院。病程中患者无发热，无胸闷、气短，眼睑及双手浮肿，精神睡眠可，饮食如常，大便正常，小便较多。\\n': Int64Index([470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
      "            483, 484, 485],\n",
      "           dtype='int64'), '患者于十余年前“感冒”劳累后出现气短、胸闷，经口服药物可缓解，呈间断发作，时好时坏，未重视。此次于入院前7天受凉“感冒”后出现胸闷、气短伴咳嗽、咳痰，痰呈黄色脓痰，痰中无血丝，活动后气短明显，夜间尚可平卧，无夜间阵发性呼吸困难，有发烧（自测体温39℃），无明显嗓子疼，无流鼻涕，有头痛、头晕，有晕厥、黑朦，赴当地诊所以“感冒”诊治，给予“头孢，左氧氟沙星抗炎，使用喘定1天，雾化2次，今日改用阿奇霉素，止咳，化痰等对症治疗”后体温下降，胸闷、气短，呼吸困难、咳嗽、咳痰、黄痰未见好转。故今日来我院门诊进一步诊治以“肺气肿”收入院。自患病以来患者无恶心、呕吐，无腹痛、腹胀，无尿频、尿急、排尿困难。精神、饮食尚可，二便正常，体重未见明显减轻。\\n': Int64Index([880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892,\n",
      "            893, 894, 895],\n",
      "           dtype='int64'), '患者于半月前无明显诱因出现咳嗽、咳痰，痰量少，白色粘稠痰，不易咳出，伴有胸憋，平卧后咳嗽加重，自行口服克拉霉素和氨溴索稍好转，3天前就诊我院门诊，肺CT检查，结果示：右肺上叶尖后段多发钙化，考虑结核硬结，双肺多发树芽征，考虑细支气管炎，右肺及右侧叶间裂微结节，较前变化不明显，建议隔期复查，双肺多发炎性索条伴右肺中叶及左肺上叶舌段炎性肺不张，双侧胸膜增厚，左心室增大，肺动脉主干增宽，今为进一步治疗收入我科，患病以来，精神及进食尚可，无脓臭痰，无发热，无盗汗、乏力，无胸痛，大小便正常。\\n': Int64Index([943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955,\n",
      "            956, 957, 958],\n",
      "           dtype='int64'), '患者今天上午8时许无明显诱因下出现气促、呼吸困难，肢体乏力，摔倒在地。开始时神志清楚，诉头晕、乏力，随后逐渐出现意识障碍，呼之不应，伴小便失禁，无发热，无肢体抽搐，无喷射状呕吐。家属将其送至我院急诊，CT检查提示“1.左侧大脑半球硬膜下慢性血肿，较前有所吸收减少；左侧大脑实质受压，中线结构轻度右偏较前减轻；2.右侧基底节区、右侧额顶叶深部及小脑半球小缺血灶或腔梗、老年脑改变，等同前相仿。请结合临床，建议治疗后复查；3、拟慢支、肺气肿伴两肺散在多发感染，两肺渗出灶较前增多；两肺散在多发结节大致同前，建议随访观察；4、左上肺毁损，左上纵隔气管向左侧移位，两肺多发陈旧性病灶伴胸膜增厚，所见同前相仿”，血气分析提示呼吸衰竭。嘱麻醉科医师气管插管后收入我科住院。近几天患者精神、食欲正常，睡眠欠佳，大便正常，体重无明显改变。': Int64Index([800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812,\n",
      "            813, 814, 815],\n",
      "           dtype='int64'), '患者半年前无明显诱因出现咳嗽、咳痰、气短，痰为白色粘痰，每日晨起气短，伴哮鸣音，休息2-3h后可好转，日间可正常活动，间断口服止咳药（具体量名不详），效不佳，10天前，无明显诱因上述症状加重，活动后气短明显，可自行穿衣、上厕所，口服养阴清肺丸（1丸/次，每日2次）治疗，效不佳，昨日患者气短进一步加重，卧床，不能活动，病程中伴乏力，体温未测，无头晕、头痛，无胸痛，无恶心、呕吐，伴腹痛，无腹泻，精神差，食欲差，大小便正常，体重无明显减轻。\\n': Int64Index([382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "            395, 396, 397],\n",
      "           dtype='int64'), '患者半月前因着凉感冒出现咳嗽、咳痰、气喘，咳白色浓痰，伴轻微呼吸困难，无发热，无咯血，无胸闷、胸痛，无恶心、呕吐，无心悸，就诊于我院急诊，摄胸片提示“双肺感染”，予阿奇霉素、头孢呋辛、桉拧蒎等药物治疗，症状较前好转。现为进一步诊治以“肺炎”收入我科。起病以来，精神、睡眠、饮食较差，小便正常，大便少，体重未见明显异常。': Int64Index([176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,\n",
      "            189, 190, 191],\n",
      "           dtype='int64'), '患者患者10年前开始，每于天气转凉或气候变化易出现咳嗽，咳少量白痰，无气促，无呼吸困难，每年发病大于3个月，曾多次于医院门诊或住院治疗，诊断为“慢性阻塞性肺疾病”，予抗感染、止咳化痰、解痉平喘等治疗后好转。长期吸入“信必可”，并长期家庭氧疗，平素上楼、上坡无气喘。9天前患者受凉后出现咳嗽、咳痰、发热，最高体温38.5℃，无畏寒、寒战，咳黄色脓痰，量较多，于附近社康输液治疗4天，未再出现发热，但咳嗽、咳痰仍未见明显改善，1月5日就诊我科门诊，给予“雾化、阿奇霉素静滴及莫西沙星口服”等对症处理，症状改善不明显，无胸闷、气喘，食欲欠佳，为求进一步诊治，入住我科，病程中，无咯血，无胸痛，无心慌，大小便正常，体重近期无下降。': Int64Index([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], dtype='int64'), '患者无明显诱因间断寒战、发热1周，体温最高达39℃，伴活动气急、咳嗽，干咳为主，就诊于呼市第一医院，摄胸片见右下肺淡片影，给予输液（具体用药不详）6天症状缓解，停药1天后再次发热，体温仍达39℃，自服抗感冒药“感康”缓解，今为进一步明确诊治入院。患者发病来饮食睡眠可，大便干燥，尿频，轻度尿痛，无腹痛、腹泻，无胸痛、盗汗及夜间阵发性呼吸困难。\\n': Int64Index([302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n",
      "            315, 316, 317],\n",
      "           dtype='int64'), '患者缘于10余年前开始反复出现咳嗽，咳白粘痰，伴活动后气促，常可自行闻及喘鸣音，受凉感冒、天气变化后易发，曾在我院诊断\"慢性支气管炎、肺气肿\"，予抗感染、平喘、止咳化痰等治疗后症状改善，但反复，曾短暂吸入舒利迭治疗。3月前再次出现咳嗽、咳白色泡沫痰，伴气促，我科住院治疗，诊断为\"慢性阻塞性肺疾病急性加重期、肺部感染\"，予莫西沙星抗感染、化痰、平喘等治疗好转后出院，出院后未规律服药。5天前咳嗽、咳痰较前加重，咳白色泡沫样黏痰，伴气喘，平卧后气喘加重，我院门诊予\"阿奇霉素、克拉霉素、氨茶碱、孟鲁司特、复方甲氧那明、噻托溴铵\"治疗，症状无明显好转，遂于今日于我科住院治疗。患者本次加重以来，无发热，无盗汗、乏力，无胸闷、胸痛、咯血，无咳粉红色泡沫痰，无恶心、呕吐，无腹痛、腹泻。患者起病以来精神、食欲、睡眠一般，二便正常，体重无明显下降。': Int64Index([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], dtype='int64'), '患者自10余年前无明显诱因开始反复发作咳嗽、气喘，咳白色泡沫痰，受凉、感冒后易发作，未系统规律诊治。2年余前出现活动后气促，休息后可缓解，无咯血、盗汗、发热、胸痛、心悸等不适。曾在我院诊断为“慢性阻塞性肺疾病急性加重期，支气管扩张”，并痰培养出速生长分枝杆菌。1年余前患者因上述症状再次发作来我科住院治疗，出院诊断“支气管扩张并感染、慢性阻塞性肺疾病急性加重期、非结核分枝杆菌肺病可能、陈旧性肺结核、左甲状腺结节伴钙化性质待定、冠心病陈旧性心肌梗死PTCA+STENT术后、高血压病（3级极高危组）、高血压性心脏病、甲状腺功能减低、痛风性关节炎、陈旧性脑梗死”，出院后仍有反复受凉后咳嗽、咳痰，长期门诊及社康就诊。4天前患者受凉后再次出现咳嗽、咳痰、活动后气促，休息后可稍缓解，现为进一步诊治收入我科。近来患者精神、食欲、睡眠尚可，大小便正常，体重无明显减轻。': Int64Index([288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
      "            301, 302, 303],\n",
      "           dtype='int64'), '患者自4月前开始无明显诱因出现咳嗽、咳痰，为少量白痰，伴活动后气促、胸闷，平躺时气促无明显加重，无粉红色泡沫痰，无畏寒、发热、盗汗、恶心、呕吐，无反酸、嗳气，无腹痛、腹胀等不适。曾在光明新区中心医院住院治疗，予以利尿、抗心衰、稳定血压治疗出院后患者咳嗽、咳痰、气促较前缓解。出院后复查胸部CT示1、考虑左肺上叶III型肺结核，双侧胸腔积液及心包积液；2、左心房、室腔扩大，主动脉、冠状动脉粥样硬化。出院后仍诉有咳痰、咳痰，咳白痰，量中，2月前为求进一步诊治曾到我科住院治疗，诊断“慢性充血性心力衰竭；冠心病PCI术后心功能Ⅱ级；左上肺陈旧性肺结核；双侧胸腔积液；高血压病3级极高危组；2型糖尿病；糖尿病肾病；低钾血症；双侧颈动脉斑块形成；右肾囊肿；腹主动脉斑块形成；前列腺增生症伴前列腺结石；睡眠呼吸暂停低通气综合征；梅毒待排”，予利尿等对症治疗后好转出院。4天前患者再次出现气促、伴胸闷，活动后出现，休息后可缓解，夜间可平卧。伴少许咳嗽，咳白色黏痰，量不多。现为进一步诊治来我院门诊就诊，拟“肺炎”收入我科。患者病程中多饮、睡眠可，大小便正常，近期体重、体力无明显改变。': Int64Index([560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
      "            573, 574, 575],\n",
      "           dtype='int64'), '患者自述6年前开始出现反复咳嗽咳痰，未予治疗，4年前出现气短，活动后加重。于今年1月份出现双下肢水肿，进行性加重。为缓解症状，自行去乡卫生所诊治，服用呋塞米、螺内酯、氨茶碱、丹参滴丸（剂量不详）后症状稍有缓解。近20天咳嗽、气短加重，休息仍不能缓解，偶有白色黏状痰，咳痰费力，双下肢水肿加重，腰骶部出现水肿上至剑突下。为进一步诊治，今收住我科。病程中，头晕，头胀，无头痛，无视物障碍，无恶心呕吐，偶有心慌，无心前区疼痛。乏力，腹胀、食欲下降，睡眠差，伴夜间阵发性呼吸困难，大小便同前，体重较之前增加7Kg。\\n': Int64Index([683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695,\n",
      "            696, 697, 698],\n",
      "           dtype='int64'), '患者近5年来常于春、秋季节间断出现咳嗽、咳痰，伴胸憋、气短，予抗感染、化痰、舒张气道等治疗症状可有改善，病情呈进行性加重，曾于当地医院诊断“慢性阻塞性肺病慢性肺源性心脏病”。1月前患者受凉后上述症状再次加重，咳黄色黏痰，量多，无痰臭，无痰中带血，自觉发热（测体温37摄氏度），并感恶心、腹胀，遂就诊卓资县医院，予“青霉素类、头孢类”抗生素静点（共用药15天），间断利尿，症状稍有好转，现为更好治疗收入我院，该患自发病以来饮食差、睡眠尚可，无头痛、头晕，无返酸、烧心，小便如常，近3日未排大便，双下肢无明显浮肿。\\n': Int64Index([911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923,\n",
      "            924, 925, 926],\n",
      "           dtype='int64'), '该患者9天前因感冒后出现咳嗽、咳痰。咳黄色粘痰，量少，不易咳出，痰中无血丝、无异味。伴有发热，体温在37.5-38.0ng/ml℃之间。无消瘦及乏力，无声音嘶哑及吞咽困难，无明显的呼吸困难。于社区门诊静脉用药3天（具体药剂不详），病情未见缓解，为了进一步诊治入我科，发病以来精神差，进食量尚可，二便正常。\\n': Int64Index([176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188,\n",
      "            189, 190, 191],\n",
      "           dtype='int64')}\n"
     ]
    }
   ],
   "source": [
    "df_groupByIPNO = df_sourceData_withFullFeature.groupby('SOURCEDATA')\n",
    "print(df_groupByIPNO.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['经常咳嗽_稳定期', '双下肢水肿_加重期', '经常胸闷_稳定期', '经常活动后气促_稳定期', '经常咳痰_稳定期', '咳嗽_加重期', '咳痰_加重期', '胸闷_加重期', '喘息_加重期', '气促_加重期', '咯血_加重期', '发热_加重期', '胸痛_加重期', '心悸_加重期', '夜间阵发性呼吸困难_加重期', '经常喘息_稳定期']\n"
     ]
    }
   ],
   "source": [
    "list_NODENAME = df_sourceData_withFullFeature[['NODENAME']].drop_duplicates()\n",
    "list_NODENAME = list(list_NODENAME['NODENAME'])\n",
    "print(list_NODENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['有', '无', '未提及']\n"
     ]
    }
   ],
   "source": [
    "list_NODEVALUE = df_sourceData_withFullFeature[['NODEVALUE']].drop_duplicates()\n",
    "list_NODEVALUE = list(list_NODEVALUE['NODEVALUE'])\n",
    "temp = list_NODEVALUE[1]\n",
    "list_NODEVALUE[1] = list_NODEVALUE[2]\n",
    "list_NODEVALUE[2] = temp\n",
    "print(list_NODEVALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelByGroup(group):\n",
    "    label = [0]*(len(list_NODENAME)*len(list_NODEVALUE))\n",
    "    for index, row in group.iterrows():\n",
    "        name = row['NODENAME']\n",
    "        nameIndex = list_NODENAME.index(name)\n",
    "        value = row['NODEVALUE']\n",
    "        valueIndex = list_NODEVALUE.index(value)\n",
    "        labelIndex = len(list_NODEVALUE)*nameIndex+valueIndex\n",
    "        label[labelIndex] = 1\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2天前，患者受凉感冒后出现咳嗽、咳痰，痰液粘稠，不易咳出，无咯血、痰中带血，无发热，无潮热、盗汗、消瘦，无恶心、反酸、烧心，无鼻后滴流感，无气短、胸闷、呼吸困难，无心悸、胸闷、气促，无夜间阵发性呼吸困难，自服药物未见好转。今日来我院门诊肺部CT示1、右侧第6-10肋骨骨折。2、两肺上叶肺气肿。3、右侧少量胸腔积液。4、主动脉及两侧冠状动脉硬化。收入我科治疗，起病以来，精神、睡眠、饮食可，大小便未见明显异常，体重无明显改变。。起病以来，患者睡眠、食欲稍差，大便正常。患者约1周前肋骨骨折。', '4年前，患者受凉后出现咳嗽、咳痰，活动时气喘、气短不适，休息后稍好转，我科住院诊断COPD，经治疗好转。后多于受凉感冒，天气变化时上述症状再发。病程中无明显活动受限，无双下肢水肿，无夜间阵发性呼吸困难。10天前受凉后上述症状再发，咳嗽，咳黄绿色粘痰，伴胸痛，咳嗽、活动时加重，无咯血、痰中带血，无心悸、胸闷，无发热，活动时感气短不适。院外治疗未见好转，具体用药不详。为求进一步诊治收入。', '半月前，患者受凉感冒后出现咳嗽、咳痰，痰液较少，易咳出，伴活动时气短、胸闷，无咯血、痰中带血，无发热，无潮热、盗汗、消瘦，无恶心、反酸、烧心，无鼻后滴流感，无气短、胸闷、呼吸困难，无心悸、气促，无夜间阵发性呼吸困难，自服药物未见好转。今日来我院门诊胸片示右下肺感染，收入我科治疗，起病以来，精神、睡眠、饮食可，大小便未见明显异常，体重无明显改变。']\n",
      "[[0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1], [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "list_NodeText = []\n",
    "matrix_label = []\n",
    "for name,group in df_groupByIPNO:\n",
    "    list_NodeText.append(name)\n",
    "    label = getLabelByGroup(group)\n",
    "    matrix_label.append(label)\n",
    "    \n",
    "\n",
    "print(list_NodeText[:3])\n",
    "print(matrix_label[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient(ip='localhost') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "768\n",
      "[[ 0.8453089  -0.39730355 -0.34256735 ...  0.55657053 -0.35914582\n",
      "   0.3399743 ]\n",
      " [ 0.7569292  -0.237311   -0.19121414 ...  0.26455134 -0.17406131\n",
      "   0.23887676]\n",
      " [ 0.53377724 -0.28528413 -0.3709756  ...  0.5838953  -0.38493901\n",
      "   0.4552007 ]\n",
      " [ 0.49889338 -0.18010922  0.05094082 ...  0.30012956 -0.31746316\n",
      "   0.35076818]\n",
      " [ 0.5720918  -0.15788887 -0.07993508 ...  0.27482608  0.14874916\n",
      "   0.3781162 ]]\n"
     ]
    }
   ],
   "source": [
    "# list_vecOfNodeText = bc.encode(list_NodeText)\n",
    "\n",
    "# print(len(list_vecOfNodeText))\n",
    "# print(len(list_vecOfNodeText[0]))\n",
    "# print(list_vecOfNodeText[:5])\n",
    "\n",
    "# import pickle\n",
    "# file = open('list_vecOfNodeText.pkl','wb')\n",
    "# pickle.dump(list_vecOfNodeText, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "768\n",
      "[[ 0.8453089  -0.39730355 -0.34256735 ...  0.55657053 -0.35914582\n",
      "   0.3399743 ]\n",
      " [ 0.7569292  -0.237311   -0.19121414 ...  0.26455134 -0.17406131\n",
      "   0.23887676]\n",
      " [ 0.53377724 -0.28528413 -0.3709756  ...  0.5838953  -0.38493901\n",
      "   0.4552007 ]\n",
      " [ 0.49889338 -0.18010922  0.05094082 ...  0.30012956 -0.31746316\n",
      "   0.35076818]\n",
      " [ 0.5720918  -0.15788887 -0.07993508 ...  0.27482608  0.14874916\n",
      "   0.3781162 ]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('list_vecOfNodeText.pkl','rb') as file:\n",
    "    list_vecOfNodeText = pickle.load(file)\n",
    "    \n",
    "print(len(list_vecOfNodeText))\n",
    "print(len(list_vecOfNodeText[0]))\n",
    "print(list_vecOfNodeText[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 48)                3120      \n",
      "=================================================================\n",
      "Total params: 241,136\n",
      "Trainable params: 241,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=len(list_vecOfNodeText[0])))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=len(list_NODENAME)*len(list_NODEVALUE), activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 25 samples\n",
      "Epoch 1/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6505 - val_acc: 0.6000\n",
      "Epoch 2/10000\n",
      "96/96 [==============================] - 0s 194us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6744 - val_acc: 0.6000\n",
      "Epoch 3/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6870 - val_acc: 0.6000\n",
      "Epoch 4/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6946 - val_acc: 0.6000\n",
      "Epoch 5/10000\n",
      "96/96 [==============================] - 0s 357us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7080 - val_acc: 0.6000\n",
      "Epoch 6/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6513 - val_acc: 0.6000\n",
      "Epoch 7/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6758 - val_acc: 0.6000\n",
      "Epoch 8/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6915 - val_acc: 0.6000\n",
      "Epoch 9/10000\n",
      "96/96 [==============================] - 0s 174us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7153 - val_acc: 0.6000\n",
      "Epoch 10/10000\n",
      "96/96 [==============================] - 0s 428us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7342 - val_acc: 0.6000\n",
      "Epoch 11/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7459 - val_acc: 0.6000\n",
      "Epoch 12/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7502 - val_acc: 0.6000\n",
      "Epoch 13/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7534 - val_acc: 0.6000\n",
      "Epoch 14/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6751 - val_acc: 0.6000\n",
      "Epoch 15/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6925 - val_acc: 0.6000\n",
      "Epoch 16/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7009 - val_acc: 0.6000\n",
      "Epoch 17/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7199 - val_acc: 0.6000\n",
      "Epoch 18/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7233 - val_acc: 0.6000\n",
      "Epoch 19/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7359 - val_acc: 0.6000\n",
      "Epoch 20/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7454 - val_acc: 0.6000\n",
      "Epoch 21/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7538 - val_acc: 0.6000\n",
      "Epoch 22/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7616 - val_acc: 0.6000\n",
      "Epoch 23/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6893 - val_acc: 0.6000\n",
      "Epoch 24/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7032 - val_acc: 0.6000\n",
      "Epoch 25/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7176 - val_acc: 0.6000\n",
      "Epoch 26/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7364 - val_acc: 0.6000\n",
      "Epoch 27/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7449 - val_acc: 0.6000\n",
      "Epoch 28/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7439 - val_acc: 0.6000\n",
      "Epoch 29/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7478 - val_acc: 0.6000\n",
      "Epoch 30/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7629 - val_acc: 0.6000\n",
      "Epoch 31/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7729 - val_acc: 0.6000\n",
      "Epoch 32/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7749 - val_acc: 0.6000\n",
      "Epoch 33/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6624 - val_acc: 0.6000\n",
      "Epoch 34/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6815 - val_acc: 0.6000\n",
      "Epoch 35/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7088 - val_acc: 0.6000\n",
      "Epoch 36/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7254 - val_acc: 0.6000\n",
      "Epoch 37/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7401 - val_acc: 0.6000\n",
      "Epoch 38/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7492 - val_acc: 0.6000\n",
      "Epoch 39/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7008 - val_acc: 0.6000\n",
      "Epoch 40/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7141 - val_acc: 0.6000\n",
      "Epoch 41/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7382 - val_acc: 0.6000\n",
      "Epoch 42/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7534 - val_acc: 0.6000\n",
      "Epoch 43/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7248 - val_acc: 0.6000\n",
      "Epoch 44/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7324 - val_acc: 0.6000\n",
      "Epoch 45/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7441 - val_acc: 0.6000\n",
      "Epoch 46/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7617 - val_acc: 0.6000\n",
      "Epoch 47/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7711 - val_acc: 0.6000\n",
      "Epoch 48/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7736 - val_acc: 0.6000\n",
      "Epoch 49/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7092 - val_acc: 0.6000\n",
      "Epoch 50/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6823 - val_acc: 0.6000\n",
      "Epoch 51/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6970 - val_acc: 0.6000\n",
      "Epoch 52/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7169 - val_acc: 0.6000\n",
      "Epoch 53/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7260 - val_acc: 0.6000\n",
      "Epoch 54/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7429 - val_acc: 0.6000\n",
      "Epoch 55/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7567 - val_acc: 0.6000\n",
      "Epoch 56/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7700 - val_acc: 0.6000\n",
      "Epoch 57/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7805 - val_acc: 0.6000\n",
      "Epoch 58/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7918 - val_acc: 0.6000\n",
      "Epoch 59/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7945 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8050 - val_acc: 0.6000\n",
      "Epoch 61/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8013 - val_acc: 0.6000\n",
      "Epoch 62/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8056 - val_acc: 0.6000\n",
      "Epoch 63/10000\n",
      "96/96 [==============================] - 0s 304us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8084 - val_acc: 0.6000\n",
      "Epoch 64/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8116 - val_acc: 0.6000\n",
      "Epoch 65/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7684 - val_acc: 0.6000\n",
      "Epoch 66/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7089 - val_acc: 0.6000\n",
      "Epoch 67/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7326 - val_acc: 0.6000\n",
      "Epoch 68/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7501 - val_acc: 0.6000\n",
      "Epoch 69/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7663 - val_acc: 0.6000\n",
      "Epoch 70/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7753 - val_acc: 0.6000\n",
      "Epoch 71/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7870 - val_acc: 0.6000\n",
      "Epoch 72/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7836 - val_acc: 0.6000\n",
      "Epoch 73/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7385 - val_acc: 0.6000\n",
      "Epoch 74/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7632 - val_acc: 0.6000\n",
      "Epoch 75/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7779 - val_acc: 0.6000\n",
      "Epoch 76/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7204 - val_acc: 0.6000\n",
      "Epoch 77/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7355 - val_acc: 0.6000\n",
      "Epoch 78/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7525 - val_acc: 0.6000\n",
      "Epoch 79/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.6848 - val_acc: 0.6000\n",
      "Epoch 80/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7107 - val_acc: 0.6000\n",
      "Epoch 81/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7255 - val_acc: 0.6000\n",
      "Epoch 82/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7430 - val_acc: 0.6000\n",
      "Epoch 83/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7572 - val_acc: 0.6000\n",
      "Epoch 84/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7696 - val_acc: 0.6000\n",
      "Epoch 85/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7887 - val_acc: 0.6000\n",
      "Epoch 86/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7921 - val_acc: 0.6000\n",
      "Epoch 87/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8056 - val_acc: 0.6000\n",
      "Epoch 88/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8137 - val_acc: 0.6000\n",
      "Epoch 89/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8132 - val_acc: 0.6000\n",
      "Epoch 90/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7776 - val_acc: 0.6000\n",
      "Epoch 91/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7910 - val_acc: 0.6000\n",
      "Epoch 92/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7927 - val_acc: 0.6000\n",
      "Epoch 93/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8003 - val_acc: 0.6000\n",
      "Epoch 94/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8049 - val_acc: 0.6000\n",
      "Epoch 95/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8168 - val_acc: 0.6000\n",
      "Epoch 96/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8226 - val_acc: 0.6000\n",
      "Epoch 97/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8322 - val_acc: 0.6000\n",
      "Epoch 98/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8417 - val_acc: 0.6000\n",
      "Epoch 99/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8484 - val_acc: 0.6000\n",
      "Epoch 100/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8454 - val_acc: 0.6000\n",
      "Epoch 101/10000\n",
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7744 - val_acc: 0.6000\n",
      "Epoch 102/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7931 - val_acc: 0.6000\n",
      "Epoch 103/10000\n",
      "96/96 [==============================] - 0s 191us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8035 - val_acc: 0.6000\n",
      "Epoch 104/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8101 - val_acc: 0.6000\n",
      "Epoch 105/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8237 - val_acc: 0.6000\n",
      "Epoch 106/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8310 - val_acc: 0.6000\n",
      "Epoch 107/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7863 - val_acc: 0.6000\n",
      "Epoch 108/10000\n",
      "96/96 [==============================] - 0s 195us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7937 - val_acc: 0.6000\n",
      "Epoch 109/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8026 - val_acc: 0.6000\n",
      "Epoch 110/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8191 - val_acc: 0.6000\n",
      "Epoch 111/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8220 - val_acc: 0.6000\n",
      "Epoch 112/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7614 - val_acc: 0.6000\n",
      "Epoch 113/10000\n",
      "96/96 [==============================] - 0s 205us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7777 - val_acc: 0.6000\n",
      "Epoch 114/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7989 - val_acc: 0.6000\n",
      "Epoch 115/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7699 - val_acc: 0.6000\n",
      "Epoch 116/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7833 - val_acc: 0.6000\n",
      "Epoch 117/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7921 - val_acc: 0.6000\n",
      "Epoch 118/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8031 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8204 - val_acc: 0.6000\n",
      "Epoch 120/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8295 - val_acc: 0.6000\n",
      "Epoch 121/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8407 - val_acc: 0.6000\n",
      "Epoch 122/10000\n",
      "96/96 [==============================] - 0s 198us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8431 - val_acc: 0.6000\n",
      "Epoch 123/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8420 - val_acc: 0.6000\n",
      "Epoch 124/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8421 - val_acc: 0.6000\n",
      "Epoch 125/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7793 - val_acc: 0.6000\n",
      "Epoch 126/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7885 - val_acc: 0.6000\n",
      "Epoch 127/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7985 - val_acc: 0.6000\n",
      "Epoch 128/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8164 - val_acc: 0.6000\n",
      "Epoch 129/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7815 - val_acc: 0.6000\n",
      "Epoch 130/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7838 - val_acc: 0.6000\n",
      "Epoch 131/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8026 - val_acc: 0.6000\n",
      "Epoch 132/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8121 - val_acc: 0.6000\n",
      "Epoch 133/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8257 - val_acc: 0.6000\n",
      "Epoch 134/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8263 - val_acc: 0.6000\n",
      "Epoch 135/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8408 - val_acc: 0.6000\n",
      "Epoch 136/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8452 - val_acc: 0.6000\n",
      "Epoch 137/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7908 - val_acc: 0.6000\n",
      "Epoch 138/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8062 - val_acc: 0.6000\n",
      "Epoch 139/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8238 - val_acc: 0.6000\n",
      "Epoch 140/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8382 - val_acc: 0.6000\n",
      "Epoch 141/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8401 - val_acc: 0.6000\n",
      "Epoch 142/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8477 - val_acc: 0.6000\n",
      "Epoch 143/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8595 - val_acc: 0.6000\n",
      "Epoch 144/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8302 - val_acc: 0.6000\n",
      "Epoch 145/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8394 - val_acc: 0.6000\n",
      "Epoch 146/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8408 - val_acc: 0.6000\n",
      "Epoch 147/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8483 - val_acc: 0.6000\n",
      "Epoch 148/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8541 - val_acc: 0.6000\n",
      "Epoch 149/10000\n",
      "96/96 [==============================] - 0s 305us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8671 - val_acc: 0.6000\n",
      "Epoch 150/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8763 - val_acc: 0.6000\n",
      "Epoch 151/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8774 - val_acc: 0.6000\n",
      "Epoch 152/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7357 - val_acc: 0.6000\n",
      "Epoch 153/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7667 - val_acc: 0.6000\n",
      "Epoch 154/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7879 - val_acc: 0.6000\n",
      "Epoch 155/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8065 - val_acc: 0.6000\n",
      "Epoch 156/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8230 - val_acc: 0.6000\n",
      "Epoch 157/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8429 - val_acc: 0.6000\n",
      "Epoch 158/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8519 - val_acc: 0.6000\n",
      "Epoch 159/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8555 - val_acc: 0.6000\n",
      "Epoch 160/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8600 - val_acc: 0.6000\n",
      "Epoch 161/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8756 - val_acc: 0.6000\n",
      "Epoch 162/10000\n",
      "96/96 [==============================] - 0s 196us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8827 - val_acc: 0.6000\n",
      "Epoch 163/10000\n",
      "96/96 [==============================] - 0s 196us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8844 - val_acc: 0.6000\n",
      "Epoch 164/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8212 - val_acc: 0.6000\n",
      "Epoch 165/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8369 - val_acc: 0.6000\n",
      "Epoch 166/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8515 - val_acc: 0.6000\n",
      "Epoch 167/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8537 - val_acc: 0.6000\n",
      "Epoch 168/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8690 - val_acc: 0.6000\n",
      "Epoch 169/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8699 - val_acc: 0.6000\n",
      "Epoch 170/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8206 - val_acc: 0.6000\n",
      "Epoch 171/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8373 - val_acc: 0.6000\n",
      "Epoch 172/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8543 - val_acc: 0.6000\n",
      "Epoch 173/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8652 - val_acc: 0.6000\n",
      "Epoch 174/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8753 - val_acc: 0.6000\n",
      "Epoch 175/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8826 - val_acc: 0.6000\n",
      "Epoch 176/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8922 - val_acc: 0.6000\n",
      "Epoch 177/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8578 - val_acc: 0.6000\n",
      "Epoch 178/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8036 - val_acc: 0.6000\n",
      "Epoch 179/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8199 - val_acc: 0.6000\n",
      "Epoch 180/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8307 - val_acc: 0.6000\n",
      "Epoch 181/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8486 - val_acc: 0.6000\n",
      "Epoch 182/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8554 - val_acc: 0.6000\n",
      "Epoch 183/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8664 - val_acc: 0.6000\n",
      "Epoch 184/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8712 - val_acc: 0.6000\n",
      "Epoch 185/10000\n",
      "96/96 [==============================] - 0s 303us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.7945 - val_acc: 0.6000\n",
      "Epoch 186/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8144 - val_acc: 0.6000\n",
      "Epoch 187/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8296 - val_acc: 0.6000\n",
      "Epoch 188/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8455 - val_acc: 0.6000\n",
      "Epoch 189/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8620 - val_acc: 0.6000\n",
      "Epoch 190/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8654 - val_acc: 0.6000\n",
      "Epoch 191/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8775 - val_acc: 0.6000\n",
      "Epoch 192/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8833 - val_acc: 0.6000\n",
      "Epoch 193/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8953 - val_acc: 0.6000\n",
      "Epoch 194/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8516 - val_acc: 0.6000\n",
      "Epoch 195/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8428 - val_acc: 0.6000\n",
      "Epoch 196/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8132 - val_acc: 0.6000\n",
      "Epoch 197/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8280 - val_acc: 0.6000\n",
      "Epoch 198/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8518 - val_acc: 0.6000\n",
      "Epoch 199/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8689 - val_acc: 0.6000\n",
      "Epoch 200/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8831 - val_acc: 0.6000\n",
      "Epoch 201/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8924 - val_acc: 0.6000\n",
      "Epoch 202/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9044 - val_acc: 0.6000\n",
      "Epoch 203/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9045 - val_acc: 0.6000\n",
      "Epoch 204/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9151 - val_acc: 0.6000\n",
      "Epoch 205/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9193 - val_acc: 0.6000\n",
      "Epoch 206/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9239 - val_acc: 0.6000\n",
      "Epoch 207/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9296 - val_acc: 0.6000\n",
      "Epoch 208/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9346 - val_acc: 0.6000\n",
      "Epoch 209/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9417 - val_acc: 0.6000\n",
      "Epoch 210/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9058 - val_acc: 0.6000\n",
      "Epoch 211/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9159 - val_acc: 0.6000\n",
      "Epoch 212/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9230 - val_acc: 0.6000\n",
      "Epoch 213/10000\n",
      "96/96 [==============================] - 0s 294us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9246 - val_acc: 0.6000\n",
      "Epoch 214/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9247 - val_acc: 0.6000\n",
      "Epoch 215/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9313 - val_acc: 0.6000\n",
      "Epoch 216/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8671 - val_acc: 0.6000\n",
      "Epoch 217/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8688 - val_acc: 0.6000\n",
      "Epoch 218/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8307 - val_acc: 0.6000\n",
      "Epoch 219/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8527 - val_acc: 0.6000\n",
      "Epoch 220/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8029 - val_acc: 0.6000\n",
      "Epoch 221/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8208 - val_acc: 0.6000\n",
      "Epoch 222/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8428 - val_acc: 0.6000\n",
      "Epoch 223/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8607 - val_acc: 0.6000\n",
      "Epoch 224/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8772 - val_acc: 0.6000\n",
      "Epoch 225/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8842 - val_acc: 0.6000\n",
      "Epoch 226/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8914 - val_acc: 0.6000\n",
      "Epoch 227/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9082 - val_acc: 0.6000\n",
      "Epoch 228/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9113 - val_acc: 0.6000\n",
      "Epoch 229/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9253 - val_acc: 0.6000\n",
      "Epoch 230/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9323 - val_acc: 0.6000\n",
      "Epoch 231/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9435 - val_acc: 0.6000\n",
      "Epoch 232/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9413 - val_acc: 0.6000\n",
      "Epoch 233/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9483 - val_acc: 0.6000\n",
      "Epoch 234/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9526 - val_acc: 0.6000\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9187 - val_acc: 0.6000\n",
      "Epoch 236/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9191 - val_acc: 0.6000\n",
      "Epoch 237/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9231 - val_acc: 0.6000\n",
      "Epoch 238/10000\n",
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9345 - val_acc: 0.6000\n",
      "Epoch 239/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9457 - val_acc: 0.6000\n",
      "Epoch 240/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9529 - val_acc: 0.6000\n",
      "Epoch 241/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9602 - val_acc: 0.6000\n",
      "Epoch 242/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9673 - val_acc: 0.6000\n",
      "Epoch 243/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9617 - val_acc: 0.6000\n",
      "Epoch 244/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9682 - val_acc: 0.6000\n",
      "Epoch 245/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8964 - val_acc: 0.6000\n",
      "Epoch 246/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8969 - val_acc: 0.6000\n",
      "Epoch 247/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9065 - val_acc: 0.6000\n",
      "Epoch 248/10000\n",
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9159 - val_acc: 0.6000\n",
      "Epoch 249/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9315 - val_acc: 0.6000\n",
      "Epoch 250/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9440 - val_acc: 0.6000\n",
      "Epoch 251/10000\n",
      "96/96 [==============================] - 0s 304us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9510 - val_acc: 0.6000\n",
      "Epoch 252/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9595 - val_acc: 0.6000\n",
      "Epoch 253/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9663 - val_acc: 0.6000\n",
      "Epoch 254/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9730 - val_acc: 0.6000\n",
      "Epoch 255/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9753 - val_acc: 0.6000\n",
      "Epoch 256/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9818 - val_acc: 0.6000\n",
      "Epoch 257/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9356 - val_acc: 0.6000\n",
      "Epoch 258/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9281 - val_acc: 0.6000\n",
      "Epoch 259/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9343 - val_acc: 0.6000\n",
      "Epoch 260/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8824 - val_acc: 0.6000\n",
      "Epoch 261/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8998 - val_acc: 0.6000\n",
      "Epoch 262/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9188 - val_acc: 0.6000\n",
      "Epoch 263/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9341 - val_acc: 0.6000\n",
      "Epoch 264/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9385 - val_acc: 0.6000\n",
      "Epoch 265/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9502 - val_acc: 0.6000\n",
      "Epoch 266/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9580 - val_acc: 0.6000\n",
      "Epoch 267/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9684 - val_acc: 0.6000\n",
      "Epoch 268/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9107 - val_acc: 0.6000\n",
      "Epoch 269/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9213 - val_acc: 0.6000\n",
      "Epoch 270/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8926 - val_acc: 0.6000\n",
      "Epoch 271/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8362 - val_acc: 0.6000\n",
      "Epoch 272/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8541 - val_acc: 0.6000\n",
      "Epoch 273/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8651 - val_acc: 0.6000\n",
      "Epoch 274/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8859 - val_acc: 0.6000\n",
      "Epoch 275/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8950 - val_acc: 0.6000\n",
      "Epoch 276/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9060 - val_acc: 0.6000\n",
      "Epoch 277/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9232 - val_acc: 0.6000\n",
      "Epoch 278/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8604 - val_acc: 0.6000\n",
      "Epoch 279/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8773 - val_acc: 0.6000\n",
      "Epoch 280/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.8908 - val_acc: 0.6000\n",
      "Epoch 281/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9064 - val_acc: 0.6000\n",
      "Epoch 282/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9170 - val_acc: 0.6000\n",
      "Epoch 283/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9328 - val_acc: 0.6000\n",
      "Epoch 284/10000\n",
      "96/96 [==============================] - 0s 297us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9435 - val_acc: 0.6000\n",
      "Epoch 285/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9521 - val_acc: 0.6000\n",
      "Epoch 286/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9605 - val_acc: 0.6000\n",
      "Epoch 287/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9707 - val_acc: 0.6000\n",
      "Epoch 288/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9714 - val_acc: 0.6000\n",
      "Epoch 289/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9791 - val_acc: 0.6000\n",
      "Epoch 290/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9868 - val_acc: 0.6000\n",
      "Epoch 291/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9845 - val_acc: 0.6000\n",
      "Epoch 292/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9876 - val_acc: 0.6000\n",
      "Epoch 293/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9933 - val_acc: 0.6000\n",
      "Epoch 294/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9229 - val_acc: 0.6000\n",
      "Epoch 295/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9357 - val_acc: 0.6000\n",
      "Epoch 296/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9442 - val_acc: 0.6000\n",
      "Epoch 297/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9556 - val_acc: 0.6000\n",
      "Epoch 298/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9684 - val_acc: 0.6000\n",
      "Epoch 299/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9751 - val_acc: 0.6000\n",
      "Epoch 300/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9791 - val_acc: 0.6000\n",
      "Epoch 301/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9812 - val_acc: 0.6000\n",
      "Epoch 302/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9266 - val_acc: 0.6000\n",
      "Epoch 303/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9433 - val_acc: 0.6000\n",
      "Epoch 304/10000\n",
      "96/96 [==============================] - 0s 187us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9512 - val_acc: 0.6000\n",
      "Epoch 305/10000\n",
      "96/96 [==============================] - 0s 201us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9589 - val_acc: 0.6000\n",
      "Epoch 306/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9670 - val_acc: 0.6000\n",
      "Epoch 307/10000\n",
      "96/96 [==============================] - 0s 163us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9740 - val_acc: 0.6000\n",
      "Epoch 308/10000\n",
      "96/96 [==============================] - 0s 201us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9431 - val_acc: 0.6000\n",
      "Epoch 309/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9561 - val_acc: 0.6000\n",
      "Epoch 310/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9644 - val_acc: 0.6000\n",
      "Epoch 311/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9734 - val_acc: 0.6000\n",
      "Epoch 312/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9802 - val_acc: 0.6000\n",
      "Epoch 313/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9855 - val_acc: 0.6000\n",
      "Epoch 314/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9890 - val_acc: 0.6000\n",
      "Epoch 315/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9942 - val_acc: 0.6000\n",
      "Epoch 316/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9997 - val_acc: 0.6000\n",
      "Epoch 317/10000\n",
      "96/96 [==============================] - 0s 342us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9316 - val_acc: 0.6000\n",
      "Epoch 318/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9499 - val_acc: 0.6000\n",
      "Epoch 319/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9648 - val_acc: 0.6000\n",
      "Epoch 320/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9758 - val_acc: 0.6000\n",
      "Epoch 321/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9867 - val_acc: 0.6000\n",
      "Epoch 322/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9874 - val_acc: 0.6000\n",
      "Epoch 323/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9916 - val_acc: 0.6000\n",
      "Epoch 324/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0007 - val_acc: 0.6000\n",
      "Epoch 325/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0067 - val_acc: 0.6000\n",
      "Epoch 326/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0161 - val_acc: 0.6000\n",
      "Epoch 327/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0181 - val_acc: 0.6000\n",
      "Epoch 328/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9546 - val_acc: 0.6000\n",
      "Epoch 329/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9642 - val_acc: 0.6000\n",
      "Epoch 330/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9723 - val_acc: 0.6000\n",
      "Epoch 331/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9843 - val_acc: 0.6000\n",
      "Epoch 332/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9911 - val_acc: 0.6000\n",
      "Epoch 333/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9426 - val_acc: 0.6000\n",
      "Epoch 334/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9630 - val_acc: 0.6000\n",
      "Epoch 335/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9792 - val_acc: 0.6000\n",
      "Epoch 336/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9893 - val_acc: 0.6000\n",
      "Epoch 337/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9982 - val_acc: 0.6000\n",
      "Epoch 338/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9696 - val_acc: 0.6000\n",
      "Epoch 339/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9802 - val_acc: 0.6000\n",
      "Epoch 340/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9867 - val_acc: 0.6000\n",
      "Epoch 341/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9974 - val_acc: 0.6000\n",
      "Epoch 342/10000\n",
      "96/96 [==============================] - 0s 192us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0096 - val_acc: 0.6000\n",
      "Epoch 343/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0178 - val_acc: 0.6000\n",
      "Epoch 344/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0258 - val_acc: 0.6000\n",
      "Epoch 345/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9501 - val_acc: 0.6000\n",
      "Epoch 346/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9616 - val_acc: 0.6000\n",
      "Epoch 347/10000\n",
      "96/96 [==============================] - 0s 191us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9752 - val_acc: 0.6000\n",
      "Epoch 348/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9894 - val_acc: 0.6000\n",
      "Epoch 349/10000\n",
      "96/96 [==============================] - 0s 182us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9962 - val_acc: 0.6000\n",
      "Epoch 350/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0032 - val_acc: 0.6000\n",
      "Epoch 351/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 197us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0124 - val_acc: 0.6000\n",
      "Epoch 352/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0131 - val_acc: 0.6000\n",
      "Epoch 353/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0190 - val_acc: 0.6000\n",
      "Epoch 354/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0251 - val_acc: 0.6000\n",
      "Epoch 355/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9838 - val_acc: 0.6000\n",
      "Epoch 356/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9754 - val_acc: 0.6000\n",
      "Epoch 357/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9883 - val_acc: 0.6000\n",
      "Epoch 358/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9929 - val_acc: 0.6000\n",
      "Epoch 359/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0033 - val_acc: 0.6000\n",
      "Epoch 360/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0099 - val_acc: 0.6000\n",
      "Epoch 361/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0196 - val_acc: 0.6000\n",
      "Epoch 362/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0278 - val_acc: 0.6000\n",
      "Epoch 363/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0300 - val_acc: 0.6000\n",
      "Epoch 364/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9876 - val_acc: 0.6000\n",
      "Epoch 365/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9964 - val_acc: 0.6000\n",
      "Epoch 366/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0054 - val_acc: 0.6000\n",
      "Epoch 367/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0152 - val_acc: 0.6000\n",
      "Epoch 368/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0248 - val_acc: 0.6000\n",
      "Epoch 369/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0384 - val_acc: 0.6000\n",
      "Epoch 370/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0445 - val_acc: 0.6000\n",
      "Epoch 371/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0538 - val_acc: 0.6000\n",
      "Epoch 372/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9916 - val_acc: 0.6000\n",
      "Epoch 373/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0040 - val_acc: 0.6000\n",
      "Epoch 374/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0133 - val_acc: 0.6000\n",
      "Epoch 375/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0188 - val_acc: 0.6000\n",
      "Epoch 376/10000\n",
      "96/96 [==============================] - 0s 195us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9901 - val_acc: 0.6000\n",
      "Epoch 377/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0009 - val_acc: 0.6000\n",
      "Epoch 378/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0100 - val_acc: 0.6000\n",
      "Epoch 379/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0185 - val_acc: 0.6000\n",
      "Epoch 380/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0259 - val_acc: 0.6000\n",
      "Epoch 381/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9630 - val_acc: 0.6000\n",
      "Epoch 382/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9771 - val_acc: 0.6000\n",
      "Epoch 383/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9875 - val_acc: 0.6000\n",
      "Epoch 384/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0002 - val_acc: 0.6000\n",
      "Epoch 385/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0097 - val_acc: 0.6000\n",
      "Epoch 386/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0167 - val_acc: 0.6000\n",
      "Epoch 387/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0265 - val_acc: 0.6000\n",
      "Epoch 388/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0334 - val_acc: 0.6000\n",
      "Epoch 389/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0352 - val_acc: 0.6000\n",
      "Epoch 390/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9777 - val_acc: 0.6000\n",
      "Epoch 391/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9897 - val_acc: 0.6000\n",
      "Epoch 392/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0041 - val_acc: 0.6000\n",
      "Epoch 393/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0169 - val_acc: 0.6000\n",
      "Epoch 394/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0285 - val_acc: 0.6000\n",
      "Epoch 395/10000\n",
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0395 - val_acc: 0.6000\n",
      "Epoch 396/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0481 - val_acc: 0.6000\n",
      "Epoch 397/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0549 - val_acc: 0.6000\n",
      "Epoch 398/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0615 - val_acc: 0.6000\n",
      "Epoch 399/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0564 - val_acc: 0.6000\n",
      "Epoch 400/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0623 - val_acc: 0.6000\n",
      "Epoch 401/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0733 - val_acc: 0.6000\n",
      "Epoch 402/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0045 - val_acc: 0.6000\n",
      "Epoch 403/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0167 - val_acc: 0.6000\n",
      "Epoch 404/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0302 - val_acc: 0.6000\n",
      "Epoch 405/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0420 - val_acc: 0.6000\n",
      "Epoch 406/10000\n",
      "96/96 [==============================] - 0s 191us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0497 - val_acc: 0.6000\n",
      "Epoch 407/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0528 - val_acc: 0.6000\n",
      "Epoch 408/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0565 - val_acc: 0.6000\n",
      "Epoch 409/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0177 - val_acc: 0.6000\n",
      "Epoch 410/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0254 - val_acc: 0.6000\n",
      "Epoch 411/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0364 - val_acc: 0.6000\n",
      "Epoch 412/10000\n",
      "96/96 [==============================] - 0s 186us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0481 - val_acc: 0.6000\n",
      "Epoch 413/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0548 - val_acc: 0.6000\n",
      "Epoch 414/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0611 - val_acc: 0.6000\n",
      "Epoch 415/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0651 - val_acc: 0.6000\n",
      "Epoch 416/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0698 - val_acc: 0.6000\n",
      "Epoch 417/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0771 - val_acc: 0.6000\n",
      "Epoch 418/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0808 - val_acc: 0.6000\n",
      "Epoch 419/10000\n",
      "96/96 [==============================] - 0s 296us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0877 - val_acc: 0.6000\n",
      "Epoch 420/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0909 - val_acc: 0.6000\n",
      "Epoch 421/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0894 - val_acc: 0.6000\n",
      "Epoch 422/10000\n",
      "96/96 [==============================] - 0s 296us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0876 - val_acc: 0.6000\n",
      "Epoch 423/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0951 - val_acc: 0.6000\n",
      "Epoch 424/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0371 - val_acc: 0.6000\n",
      "Epoch 425/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0458 - val_acc: 0.6000\n",
      "Epoch 426/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9864 - val_acc: 0.6000\n",
      "Epoch 427/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0026 - val_acc: 0.6000\n",
      "Epoch 428/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0164 - val_acc: 0.6000\n",
      "Epoch 429/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9933 - val_acc: 0.6000\n",
      "Epoch 430/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0094 - val_acc: 0.6000\n",
      "Epoch 431/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0222 - val_acc: 0.6000\n",
      "Epoch 432/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0259 - val_acc: 0.6000\n",
      "Epoch 433/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0383 - val_acc: 0.6000\n",
      "Epoch 434/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0433 - val_acc: 0.6000\n",
      "Epoch 435/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0534 - val_acc: 0.6000\n",
      "Epoch 436/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0586 - val_acc: 0.6000\n",
      "Epoch 437/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0653 - val_acc: 0.6000\n",
      "Epoch 438/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0035 - val_acc: 0.6000\n",
      "Epoch 439/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0179 - val_acc: 0.6000\n",
      "Epoch 440/10000\n",
      "96/96 [==============================] - 0s 183us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9570 - val_acc: 0.6000\n",
      "Epoch 441/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9683 - val_acc: 0.6000\n",
      "Epoch 442/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 117.9862 - val_acc: 0.6000\n",
      "Epoch 443/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0011 - val_acc: 0.6000\n",
      "Epoch 444/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0132 - val_acc: 0.6000\n",
      "Epoch 445/10000\n",
      "96/96 [==============================] - 0s 306us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0298 - val_acc: 0.6000\n",
      "Epoch 446/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0393 - val_acc: 0.6000\n",
      "Epoch 447/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0521 - val_acc: 0.6000\n",
      "Epoch 448/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0619 - val_acc: 0.6000\n",
      "Epoch 449/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0706 - val_acc: 0.6000\n",
      "Epoch 450/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0775 - val_acc: 0.6000\n",
      "Epoch 451/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0364 - val_acc: 0.6000\n",
      "Epoch 452/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0317 - val_acc: 0.6000\n",
      "Epoch 453/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0441 - val_acc: 0.6000\n",
      "Epoch 454/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0516 - val_acc: 0.6000\n",
      "Epoch 455/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0580 - val_acc: 0.6000\n",
      "Epoch 456/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0701 - val_acc: 0.6000\n",
      "Epoch 457/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0797 - val_acc: 0.6000\n",
      "Epoch 458/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0849 - val_acc: 0.6000\n",
      "Epoch 459/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0926 - val_acc: 0.6000\n",
      "Epoch 460/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0337 - val_acc: 0.6000\n",
      "Epoch 461/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0446 - val_acc: 0.6000\n",
      "Epoch 462/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0556 - val_acc: 0.6000\n",
      "Epoch 463/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0614 - val_acc: 0.6000\n",
      "Epoch 464/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0690 - val_acc: 0.6000\n",
      "Epoch 465/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0805 - val_acc: 0.6000\n",
      "Epoch 466/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0134 - val_acc: 0.6000\n",
      "Epoch 467/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0264 - val_acc: 0.6000\n",
      "Epoch 468/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0223 - val_acc: 0.6000\n",
      "Epoch 469/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0367 - val_acc: 0.6000\n",
      "Epoch 470/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0444 - val_acc: 0.6000\n",
      "Epoch 471/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0589 - val_acc: 0.6000\n",
      "Epoch 472/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0703 - val_acc: 0.6000\n",
      "Epoch 473/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0823 - val_acc: 0.6000\n",
      "Epoch 474/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0890 - val_acc: 0.6000\n",
      "Epoch 475/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0903 - val_acc: 0.6000\n",
      "Epoch 476/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0987 - val_acc: 0.6000\n",
      "Epoch 477/10000\n",
      "96/96 [==============================] - 0s 302us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0706 - val_acc: 0.6000\n",
      "Epoch 478/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0765 - val_acc: 0.6000\n",
      "Epoch 479/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0847 - val_acc: 0.6000\n",
      "Epoch 480/10000\n",
      "96/96 [==============================] - 0s 326us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0928 - val_acc: 0.6000\n",
      "Epoch 481/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0929 - val_acc: 0.6000\n",
      "Epoch 482/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0949 - val_acc: 0.6000\n",
      "Epoch 483/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0978 - val_acc: 0.6000\n",
      "Epoch 484/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0288 - val_acc: 0.6000\n",
      "Epoch 485/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0331 - val_acc: 0.6000\n",
      "Epoch 486/10000\n",
      "96/96 [==============================] - 0s 329us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0514 - val_acc: 0.6000\n",
      "Epoch 487/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0600 - val_acc: 0.6000\n",
      "Epoch 488/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0691 - val_acc: 0.6000\n",
      "Epoch 489/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0745 - val_acc: 0.6000\n",
      "Epoch 490/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0811 - val_acc: 0.6000\n",
      "Epoch 491/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0930 - val_acc: 0.6000\n",
      "Epoch 492/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1008 - val_acc: 0.6000\n",
      "Epoch 493/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1081 - val_acc: 0.6000\n",
      "Epoch 494/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1141 - val_acc: 0.6000\n",
      "Epoch 495/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1196 - val_acc: 0.6000\n",
      "Epoch 496/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1192 - val_acc: 0.6000\n",
      "Epoch 497/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1238 - val_acc: 0.6000\n",
      "Epoch 498/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1251 - val_acc: 0.6000\n",
      "Epoch 499/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0724 - val_acc: 0.6000\n",
      "Epoch 500/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0860 - val_acc: 0.6000\n",
      "Epoch 501/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0955 - val_acc: 0.6000\n",
      "Epoch 502/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1071 - val_acc: 0.6000\n",
      "Epoch 503/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1131 - val_acc: 0.6000\n",
      "Epoch 504/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1214 - val_acc: 0.6000\n",
      "Epoch 505/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1239 - val_acc: 0.6000\n",
      "Epoch 506/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1251 - val_acc: 0.6000\n",
      "Epoch 507/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1300 - val_acc: 0.6000\n",
      "Epoch 508/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1357 - val_acc: 0.6000\n",
      "Epoch 509/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1347 - val_acc: 0.6000\n",
      "Epoch 510/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1017 - val_acc: 0.6000\n",
      "Epoch 511/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1095 - val_acc: 0.6000\n",
      "Epoch 512/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1132 - val_acc: 0.6000\n",
      "Epoch 513/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1218 - val_acc: 0.6000\n",
      "Epoch 514/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1289 - val_acc: 0.6000\n",
      "Epoch 515/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1297 - val_acc: 0.6000\n",
      "Epoch 516/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1358 - val_acc: 0.6000\n",
      "Epoch 517/10000\n",
      "96/96 [==============================] - 0s 205us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0668 - val_acc: 0.6000\n",
      "Epoch 518/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0754 - val_acc: 0.6000\n",
      "Epoch 519/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0872 - val_acc: 0.6000\n",
      "Epoch 520/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0916 - val_acc: 0.6000\n",
      "Epoch 521/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0951 - val_acc: 0.6000\n",
      "Epoch 522/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1008 - val_acc: 0.6000\n",
      "Epoch 523/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1067 - val_acc: 0.6000\n",
      "Epoch 524/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1159 - val_acc: 0.6000\n",
      "Epoch 525/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1253 - val_acc: 0.6000\n",
      "Epoch 526/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1301 - val_acc: 0.6000\n",
      "Epoch 527/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1393 - val_acc: 0.6000\n",
      "Epoch 528/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0798 - val_acc: 0.6000\n",
      "Epoch 529/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0934 - val_acc: 0.6000\n",
      "Epoch 530/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1011 - val_acc: 0.6000\n",
      "Epoch 531/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1106 - val_acc: 0.6000\n",
      "Epoch 532/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1200 - val_acc: 0.6000\n",
      "Epoch 533/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1257 - val_acc: 0.6000\n",
      "Epoch 534/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1322 - val_acc: 0.6000\n",
      "Epoch 535/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1396 - val_acc: 0.6000\n",
      "Epoch 536/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1428 - val_acc: 0.6000\n",
      "Epoch 537/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1466 - val_acc: 0.6000\n",
      "Epoch 538/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0491 - val_acc: 0.6000\n",
      "Epoch 539/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0701 - val_acc: 0.6000\n",
      "Epoch 540/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0893 - val_acc: 0.6000\n",
      "Epoch 541/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1048 - val_acc: 0.6000\n",
      "Epoch 542/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1124 - val_acc: 0.6000\n",
      "Epoch 543/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1188 - val_acc: 0.6000\n",
      "Epoch 544/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1253 - val_acc: 0.6000\n",
      "Epoch 545/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1303 - val_acc: 0.6000\n",
      "Epoch 546/10000\n",
      "96/96 [==============================] - 0s 309us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1344 - val_acc: 0.6000\n",
      "Epoch 547/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0787 - val_acc: 0.6000\n",
      "Epoch 548/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0915 - val_acc: 0.6000\n",
      "Epoch 549/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1067 - val_acc: 0.6000\n",
      "Epoch 550/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1149 - val_acc: 0.6000\n",
      "Epoch 551/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0118 - val_acc: 0.6000\n",
      "Epoch 552/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0270 - val_acc: 0.6000\n",
      "Epoch 553/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0442 - val_acc: 0.6000\n",
      "Epoch 554/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0581 - val_acc: 0.6000\n",
      "Epoch 555/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0665 - val_acc: 0.6000\n",
      "Epoch 556/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0759 - val_acc: 0.6000\n",
      "Epoch 557/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0898 - val_acc: 0.6000\n",
      "Epoch 558/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1023 - val_acc: 0.6000\n",
      "Epoch 559/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0619 - val_acc: 0.6000\n",
      "Epoch 560/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0580 - val_acc: 0.6000\n",
      "Epoch 561/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0691 - val_acc: 0.6000\n",
      "Epoch 562/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0860 - val_acc: 0.6000\n",
      "Epoch 563/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0992 - val_acc: 0.6000\n",
      "Epoch 564/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1118 - val_acc: 0.6000\n",
      "Epoch 565/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1213 - val_acc: 0.6000\n",
      "Epoch 566/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1299 - val_acc: 0.6000\n",
      "Epoch 567/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1305 - val_acc: 0.6000\n",
      "Epoch 568/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1384 - val_acc: 0.6000\n",
      "Epoch 569/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1447 - val_acc: 0.6000\n",
      "Epoch 570/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1474 - val_acc: 0.6000\n",
      "Epoch 571/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1523 - val_acc: 0.6000\n",
      "Epoch 572/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1554 - val_acc: 0.6000\n",
      "Epoch 573/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1035 - val_acc: 0.6000\n",
      "Epoch 574/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1147 - val_acc: 0.6000\n",
      "Epoch 575/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1212 - val_acc: 0.6000\n",
      "Epoch 576/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1281 - val_acc: 0.6000\n",
      "Epoch 577/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1358 - val_acc: 0.6000\n",
      "Epoch 578/10000\n",
      "96/96 [==============================] - 0s 331us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1460 - val_acc: 0.6000\n",
      "Epoch 579/10000\n",
      "96/96 [==============================] - 0s 188us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0813 - val_acc: 0.6000\n",
      "Epoch 580/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0962 - val_acc: 0.6000\n",
      "Epoch 581/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1076 - val_acc: 0.6000\n",
      "Epoch 582/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1126 - val_acc: 0.6000\n",
      "Epoch 583/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1238 - val_acc: 0.6000\n",
      "Epoch 584/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1288 - val_acc: 0.6000\n",
      "Epoch 585/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1347 - val_acc: 0.6000\n",
      "Epoch 586/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1381 - val_acc: 0.6000\n",
      "Epoch 587/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1478 - val_acc: 0.6000\n",
      "Epoch 588/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1513 - val_acc: 0.6000\n",
      "Epoch 589/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1522 - val_acc: 0.6000\n",
      "Epoch 590/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1221 - val_acc: 0.6000\n",
      "Epoch 591/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1272 - val_acc: 0.6000\n",
      "Epoch 592/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1370 - val_acc: 0.6000\n",
      "Epoch 593/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1417 - val_acc: 0.6000\n",
      "Epoch 594/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1496 - val_acc: 0.6000\n",
      "Epoch 595/10000\n",
      "96/96 [==============================] - 0s 310us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1564 - val_acc: 0.6000\n",
      "Epoch 596/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0970 - val_acc: 0.6000\n",
      "Epoch 597/10000\n",
      "96/96 [==============================] - 0s 324us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1083 - val_acc: 0.6000\n",
      "Epoch 598/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1211 - val_acc: 0.6000\n",
      "Epoch 599/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1300 - val_acc: 0.6000\n",
      "Epoch 600/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1395 - val_acc: 0.6000\n",
      "Epoch 601/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1425 - val_acc: 0.6000\n",
      "Epoch 602/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1491 - val_acc: 0.6000\n",
      "Epoch 603/10000\n",
      "96/96 [==============================] - 0s 294us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1515 - val_acc: 0.6000\n",
      "Epoch 604/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1596 - val_acc: 0.6000\n",
      "Epoch 605/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0985 - val_acc: 0.6000\n",
      "Epoch 606/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1062 - val_acc: 0.6000\n",
      "Epoch 607/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1200 - val_acc: 0.6000\n",
      "Epoch 608/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1316 - val_acc: 0.6000\n",
      "Epoch 609/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1367 - val_acc: 0.6000\n",
      "Epoch 610/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0681 - val_acc: 0.6000\n",
      "Epoch 611/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0823 - val_acc: 0.6000\n",
      "Epoch 612/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0961 - val_acc: 0.6000\n",
      "Epoch 613/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1048 - val_acc: 0.6000\n",
      "Epoch 614/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1131 - val_acc: 0.6000\n",
      "Epoch 615/10000\n",
      "96/96 [==============================] - 0s 187us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1241 - val_acc: 0.6000\n",
      "Epoch 616/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1301 - val_acc: 0.6000\n",
      "Epoch 617/10000\n",
      "96/96 [==============================] - 0s 178us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1419 - val_acc: 0.6000\n",
      "Epoch 618/10000\n",
      "96/96 [==============================] - 0s 176us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1500 - val_acc: 0.6000\n",
      "Epoch 619/10000\n",
      "96/96 [==============================] - 0s 197us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1540 - val_acc: 0.6000\n",
      "Epoch 620/10000\n",
      "96/96 [==============================] - 0s 176us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1559 - val_acc: 0.6000\n",
      "Epoch 621/10000\n",
      "96/96 [==============================] - 0s 181us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1626 - val_acc: 0.6000\n",
      "Epoch 622/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1671 - val_acc: 0.6000\n",
      "Epoch 623/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1721 - val_acc: 0.6000\n",
      "Epoch 624/10000\n",
      "96/96 [==============================] - 0s 191us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1776 - val_acc: 0.6000\n",
      "Epoch 625/10000\n",
      "96/96 [==============================] - 0s 185us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1776 - val_acc: 0.6000\n",
      "Epoch 626/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1040 - val_acc: 0.6000\n",
      "Epoch 627/10000\n",
      "96/96 [==============================] - 0s 189us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1138 - val_acc: 0.6000\n",
      "Epoch 628/10000\n",
      "96/96 [==============================] - 0s 175us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1279 - val_acc: 0.6000\n",
      "Epoch 629/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1356 - val_acc: 0.6000\n",
      "Epoch 630/10000\n",
      "96/96 [==============================] - 0s 171us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1435 - val_acc: 0.6000\n",
      "Epoch 631/10000\n",
      "96/96 [==============================] - 0s 170us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1509 - val_acc: 0.6000\n",
      "Epoch 632/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1616 - val_acc: 0.6000\n",
      "Epoch 633/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1659 - val_acc: 0.6000\n",
      "Epoch 634/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1733 - val_acc: 0.6000\n",
      "Epoch 635/10000\n",
      "96/96 [==============================] - 0s 297us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1265 - val_acc: 0.6000\n",
      "Epoch 636/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1373 - val_acc: 0.6000\n",
      "Epoch 637/10000\n",
      "96/96 [==============================] - 0s 180us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1469 - val_acc: 0.6000\n",
      "Epoch 638/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1564 - val_acc: 0.6000\n",
      "Epoch 639/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1656 - val_acc: 0.6000\n",
      "Epoch 640/10000\n",
      "96/96 [==============================] - 0s 323us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1687 - val_acc: 0.6000\n",
      "Epoch 641/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1719 - val_acc: 0.6000\n",
      "Epoch 642/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1321 - val_acc: 0.6000\n",
      "Epoch 643/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1258 - val_acc: 0.6000\n",
      "Epoch 644/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1412 - val_acc: 0.6000\n",
      "Epoch 645/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1483 - val_acc: 0.6000\n",
      "Epoch 646/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1560 - val_acc: 0.6000\n",
      "Epoch 647/10000\n",
      "96/96 [==============================] - 0s 334us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1628 - val_acc: 0.6000\n",
      "Epoch 648/10000\n",
      "96/96 [==============================] - 0s 346us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1682 - val_acc: 0.6000\n",
      "Epoch 649/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1756 - val_acc: 0.6000\n",
      "Epoch 650/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1841 - val_acc: 0.6000\n",
      "Epoch 651/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1887 - val_acc: 0.6000\n",
      "Epoch 652/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1945 - val_acc: 0.6000\n",
      "Epoch 653/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1999 - val_acc: 0.6000\n",
      "Epoch 654/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2003 - val_acc: 0.6000\n",
      "Epoch 655/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1691 - val_acc: 0.6000\n",
      "Epoch 656/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1037 - val_acc: 0.6000\n",
      "Epoch 657/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1143 - val_acc: 0.6000\n",
      "Epoch 658/10000\n",
      "96/96 [==============================] - 0s 336us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1275 - val_acc: 0.6000\n",
      "Epoch 659/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1341 - val_acc: 0.6000\n",
      "Epoch 660/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1442 - val_acc: 0.6000\n",
      "Epoch 661/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1521 - val_acc: 0.6000\n",
      "Epoch 662/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1000 - val_acc: 0.6000\n",
      "Epoch 663/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1155 - val_acc: 0.6000\n",
      "Epoch 664/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1260 - val_acc: 0.6000\n",
      "Epoch 665/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1405 - val_acc: 0.6000\n",
      "Epoch 666/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0759 - val_acc: 0.6000\n",
      "Epoch 667/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.0936 - val_acc: 0.6000\n",
      "Epoch 668/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1071 - val_acc: 0.6000\n",
      "Epoch 669/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1165 - val_acc: 0.6000\n",
      "Epoch 670/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1313 - val_acc: 0.6000\n",
      "Epoch 671/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1436 - val_acc: 0.6000\n",
      "Epoch 672/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1536 - val_acc: 0.6000\n",
      "Epoch 673/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1592 - val_acc: 0.6000\n",
      "Epoch 674/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1699 - val_acc: 0.6000\n",
      "Epoch 675/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1774 - val_acc: 0.6000\n",
      "Epoch 676/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1844 - val_acc: 0.6000\n",
      "Epoch 677/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1222 - val_acc: 0.6000\n",
      "Epoch 678/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1288 - val_acc: 0.6000\n",
      "Epoch 679/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1413 - val_acc: 0.6000\n",
      "Epoch 680/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1516 - val_acc: 0.6000\n",
      "Epoch 681/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1598 - val_acc: 0.6000\n",
      "Epoch 682/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1688 - val_acc: 0.6000\n",
      "Epoch 683/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1698 - val_acc: 0.6000\n",
      "Epoch 684/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1729 - val_acc: 0.6000\n",
      "Epoch 685/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1814 - val_acc: 0.6000\n",
      "Epoch 686/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1877 - val_acc: 0.6000\n",
      "Epoch 687/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1895 - val_acc: 0.6000\n",
      "Epoch 688/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1971 - val_acc: 0.6000\n",
      "Epoch 689/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2010 - val_acc: 0.6000\n",
      "Epoch 690/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2021 - val_acc: 0.6000\n",
      "Epoch 691/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1669 - val_acc: 0.6000\n",
      "Epoch 692/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1695 - val_acc: 0.6000\n",
      "Epoch 693/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1725 - val_acc: 0.6000\n",
      "Epoch 694/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1831 - val_acc: 0.6000\n",
      "Epoch 695/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1913 - val_acc: 0.6000\n",
      "Epoch 696/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1979 - val_acc: 0.6000\n",
      "Epoch 697/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2025 - val_acc: 0.6000\n",
      "Epoch 698/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1328 - val_acc: 0.6000\n",
      "Epoch 699/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1406 - val_acc: 0.6000\n",
      "Epoch 700/10000\n",
      "96/96 [==============================] - 0s 195us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1460 - val_acc: 0.6000\n",
      "Epoch 701/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1557 - val_acc: 0.6000\n",
      "Epoch 702/10000\n",
      "96/96 [==============================] - 0s 188us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1647 - val_acc: 0.6000\n",
      "Epoch 703/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1716 - val_acc: 0.6000\n",
      "Epoch 704/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1817 - val_acc: 0.6000\n",
      "Epoch 705/10000\n",
      "96/96 [==============================] - 0s 324us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1868 - val_acc: 0.6000\n",
      "Epoch 706/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1320 - val_acc: 0.6000\n",
      "Epoch 707/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1463 - val_acc: 0.6000\n",
      "Epoch 708/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1614 - val_acc: 0.6000\n",
      "Epoch 709/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1720 - val_acc: 0.6000\n",
      "Epoch 710/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1819 - val_acc: 0.6000\n",
      "Epoch 711/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1906 - val_acc: 0.6000\n",
      "Epoch 712/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1996 - val_acc: 0.6000\n",
      "Epoch 713/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2077 - val_acc: 0.6000\n",
      "Epoch 714/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2144 - val_acc: 0.6000\n",
      "Epoch 715/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2143 - val_acc: 0.6000\n",
      "Epoch 716/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2223 - val_acc: 0.6000\n",
      "Epoch 717/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2259 - val_acc: 0.6000\n",
      "Epoch 718/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2253 - val_acc: 0.6000\n",
      "Epoch 719/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2274 - val_acc: 0.6000\n",
      "Epoch 720/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2315 - val_acc: 0.6000\n",
      "Epoch 721/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2351 - val_acc: 0.6000\n",
      "Epoch 722/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1353 - val_acc: 0.6000\n",
      "Epoch 723/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1562 - val_acc: 0.6000\n",
      "Epoch 724/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1730 - val_acc: 0.6000\n",
      "Epoch 725/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1874 - val_acc: 0.6000\n",
      "Epoch 726/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2000 - val_acc: 0.6000\n",
      "Epoch 727/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2046 - val_acc: 0.6000\n",
      "Epoch 728/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2102 - val_acc: 0.6000\n",
      "Epoch 729/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2193 - val_acc: 0.6000\n",
      "Epoch 730/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1127 - val_acc: 0.6000\n",
      "Epoch 731/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1245 - val_acc: 0.6000\n",
      "Epoch 732/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1341 - val_acc: 0.6000\n",
      "Epoch 733/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1457 - val_acc: 0.6000\n",
      "Epoch 734/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1604 - val_acc: 0.6000\n",
      "Epoch 735/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1700 - val_acc: 0.6000\n",
      "Epoch 736/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1809 - val_acc: 0.6000\n",
      "Epoch 737/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1861 - val_acc: 0.6000\n",
      "Epoch 738/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1977 - val_acc: 0.6000\n",
      "Epoch 739/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2036 - val_acc: 0.6000\n",
      "Epoch 740/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2091 - val_acc: 0.6000\n",
      "Epoch 741/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2123 - val_acc: 0.6000\n",
      "Epoch 742/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2182 - val_acc: 0.6000\n",
      "Epoch 743/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2204 - val_acc: 0.6000\n",
      "Epoch 744/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2283 - val_acc: 0.6000\n",
      "Epoch 745/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2336 - val_acc: 0.6000\n",
      "Epoch 746/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2388 - val_acc: 0.6000\n",
      "Epoch 747/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2379 - val_acc: 0.6000\n",
      "Epoch 748/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2427 - val_acc: 0.6000\n",
      "Epoch 749/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1703 - val_acc: 0.6000\n",
      "Epoch 750/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1784 - val_acc: 0.6000\n",
      "Epoch 751/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1750 - val_acc: 0.6000\n",
      "Epoch 752/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1185 - val_acc: 0.6000\n",
      "Epoch 753/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1385 - val_acc: 0.6000\n",
      "Epoch 754/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1533 - val_acc: 0.6000\n",
      "Epoch 755/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1634 - val_acc: 0.6000\n",
      "Epoch 756/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1775 - val_acc: 0.6000\n",
      "Epoch 757/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1890 - val_acc: 0.6000\n",
      "Epoch 758/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2005 - val_acc: 0.6000\n",
      "Epoch 759/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1634 - val_acc: 0.6000\n",
      "Epoch 760/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1734 - val_acc: 0.6000\n",
      "Epoch 761/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1866 - val_acc: 0.6000\n",
      "Epoch 762/10000\n",
      "96/96 [==============================] - 0s 303us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1311 - val_acc: 0.6000\n",
      "Epoch 763/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1417 - val_acc: 0.6000\n",
      "Epoch 764/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1539 - val_acc: 0.6000\n",
      "Epoch 765/10000\n",
      "96/96 [==============================] - 0s 307us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1683 - val_acc: 0.6000\n",
      "Epoch 766/10000\n",
      "96/96 [==============================] - 0s 295us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1805 - val_acc: 0.6000\n",
      "Epoch 767/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1908 - val_acc: 0.6000\n",
      "Epoch 768/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1997 - val_acc: 0.6000\n",
      "Epoch 769/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2047 - val_acc: 0.6000\n",
      "Epoch 770/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2135 - val_acc: 0.6000\n",
      "Epoch 771/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2165 - val_acc: 0.6000\n",
      "Epoch 772/10000\n",
      "96/96 [==============================] - 0s 303us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2213 - val_acc: 0.6000\n",
      "Epoch 773/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2258 - val_acc: 0.6000\n",
      "Epoch 774/10000\n",
      "96/96 [==============================] - 0s 302us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2316 - val_acc: 0.6000\n",
      "Epoch 775/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2371 - val_acc: 0.6000\n",
      "Epoch 776/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2416 - val_acc: 0.6000\n",
      "Epoch 777/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2462 - val_acc: 0.6000\n",
      "Epoch 778/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1321 - val_acc: 0.6000\n",
      "Epoch 779/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1419 - val_acc: 0.6000\n",
      "Epoch 780/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1499 - val_acc: 0.6000\n",
      "Epoch 781/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1628 - val_acc: 0.6000\n",
      "Epoch 782/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1700 - val_acc: 0.6000\n",
      "Epoch 783/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1795 - val_acc: 0.6000\n",
      "Epoch 784/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1851 - val_acc: 0.6000\n",
      "Epoch 785/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1911 - val_acc: 0.6000\n",
      "Epoch 786/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2016 - val_acc: 0.6000\n",
      "Epoch 787/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2027 - val_acc: 0.6000\n",
      "Epoch 788/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2128 - val_acc: 0.6000\n",
      "Epoch 789/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2199 - val_acc: 0.6000\n",
      "Epoch 790/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2261 - val_acc: 0.6000\n",
      "Epoch 791/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2348 - val_acc: 0.6000\n",
      "Epoch 792/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2372 - val_acc: 0.6000\n",
      "Epoch 793/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2430 - val_acc: 0.6000\n",
      "Epoch 794/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2458 - val_acc: 0.6000\n",
      "Epoch 795/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1899 - val_acc: 0.6000\n",
      "Epoch 796/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1995 - val_acc: 0.6000\n",
      "Epoch 797/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2127 - val_acc: 0.6000\n",
      "Epoch 798/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2233 - val_acc: 0.6000\n",
      "Epoch 799/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2271 - val_acc: 0.6000\n",
      "Epoch 800/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2367 - val_acc: 0.6000\n",
      "Epoch 801/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2404 - val_acc: 0.6000\n",
      "Epoch 802/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2484 - val_acc: 0.6000\n",
      "Epoch 803/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2510 - val_acc: 0.6000\n",
      "Epoch 804/10000\n",
      "96/96 [==============================] - 0s 191us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2552 - val_acc: 0.6000\n",
      "Epoch 805/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2619 - val_acc: 0.6000\n",
      "Epoch 806/10000\n",
      "96/96 [==============================] - 0s 184us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2640 - val_acc: 0.6000\n",
      "Epoch 807/10000\n",
      "96/96 [==============================] - 0s 175us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2668 - val_acc: 0.6000\n",
      "Epoch 808/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2696 - val_acc: 0.6000\n",
      "Epoch 809/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2721 - val_acc: 0.6000\n",
      "Epoch 810/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2749 - val_acc: 0.6000\n",
      "Epoch 811/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2754 - val_acc: 0.6000\n",
      "Epoch 812/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1994 - val_acc: 0.6000\n",
      "Epoch 813/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2055 - val_acc: 0.6000\n",
      "Epoch 814/10000\n",
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2113 - val_acc: 0.6000\n",
      "Epoch 815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2209 - val_acc: 0.6000\n",
      "Epoch 816/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2238 - val_acc: 0.6000\n",
      "Epoch 817/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2277 - val_acc: 0.6000\n",
      "Epoch 818/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2378 - val_acc: 0.6000\n",
      "Epoch 819/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2461 - val_acc: 0.6000\n",
      "Epoch 820/10000\n",
      "96/96 [==============================] - 0s 296us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2532 - val_acc: 0.6000\n",
      "Epoch 821/10000\n",
      "96/96 [==============================] - 0s 316us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2581 - val_acc: 0.6000\n",
      "Epoch 822/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2594 - val_acc: 0.6000\n",
      "Epoch 823/10000\n",
      "96/96 [==============================] - 0s 305us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2657 - val_acc: 0.6000\n",
      "Epoch 824/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2698 - val_acc: 0.6000\n",
      "Epoch 825/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2364 - val_acc: 0.6000\n",
      "Epoch 826/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1719 - val_acc: 0.6000\n",
      "Epoch 827/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1833 - val_acc: 0.6000\n",
      "Epoch 828/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1946 - val_acc: 0.6000\n",
      "Epoch 829/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2008 - val_acc: 0.6000\n",
      "Epoch 830/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2065 - val_acc: 0.6000\n",
      "Epoch 831/10000\n",
      "96/96 [==============================] - 0s 315us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2178 - val_acc: 0.6000\n",
      "Epoch 832/10000\n",
      "96/96 [==============================] - 0s 323us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2240 - val_acc: 0.6000\n",
      "Epoch 833/10000\n",
      "96/96 [==============================] - ETA: 0s - loss: 44.3614 - acc: 0.84 - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2283 - val_acc: 0.6000\n",
      "Epoch 834/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2279 - val_acc: 0.6000\n",
      "Epoch 835/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2347 - val_acc: 0.6000\n",
      "Epoch 836/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1784 - val_acc: 0.6000\n",
      "Epoch 837/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1918 - val_acc: 0.6000\n",
      "Epoch 838/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1435 - val_acc: 0.6000\n",
      "Epoch 839/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1610 - val_acc: 0.6000\n",
      "Epoch 840/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1732 - val_acc: 0.6000\n",
      "Epoch 841/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1896 - val_acc: 0.6000\n",
      "Epoch 842/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2026 - val_acc: 0.6000\n",
      "Epoch 843/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2120 - val_acc: 0.6000\n",
      "Epoch 844/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2251 - val_acc: 0.6000\n",
      "Epoch 845/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2340 - val_acc: 0.6000\n",
      "Epoch 846/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2402 - val_acc: 0.6000\n",
      "Epoch 847/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2492 - val_acc: 0.6000\n",
      "Epoch 848/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2527 - val_acc: 0.6000\n",
      "Epoch 849/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2562 - val_acc: 0.6000\n",
      "Epoch 850/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2600 - val_acc: 0.6000\n",
      "Epoch 851/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1928 - val_acc: 0.6000\n",
      "Epoch 852/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2038 - val_acc: 0.6000\n",
      "Epoch 853/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2143 - val_acc: 0.6000\n",
      "Epoch 854/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2195 - val_acc: 0.6000\n",
      "Epoch 855/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2291 - val_acc: 0.6000\n",
      "Epoch 856/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2342 - val_acc: 0.6000\n",
      "Epoch 857/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2371 - val_acc: 0.6000\n",
      "Epoch 858/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2444 - val_acc: 0.6000\n",
      "Epoch 859/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2507 - val_acc: 0.6000\n",
      "Epoch 860/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2583 - val_acc: 0.6000\n",
      "Epoch 861/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2608 - val_acc: 0.6000\n",
      "Epoch 862/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2656 - val_acc: 0.6000\n",
      "Epoch 863/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2676 - val_acc: 0.6000\n",
      "Epoch 864/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2730 - val_acc: 0.6000\n",
      "Epoch 865/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2735 - val_acc: 0.6000\n",
      "Epoch 866/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2399 - val_acc: 0.6000\n",
      "Epoch 867/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2453 - val_acc: 0.6000\n",
      "Epoch 868/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2499 - val_acc: 0.6000\n",
      "Epoch 869/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2587 - val_acc: 0.6000\n",
      "Epoch 870/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2651 - val_acc: 0.6000\n",
      "Epoch 871/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2682 - val_acc: 0.6000\n",
      "Epoch 872/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2719 - val_acc: 0.6000\n",
      "Epoch 873/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2743 - val_acc: 0.6000\n",
      "Epoch 874/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2792 - val_acc: 0.6000\n",
      "Epoch 875/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2821 - val_acc: 0.6000\n",
      "Epoch 876/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2869 - val_acc: 0.6000\n",
      "Epoch 877/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2880 - val_acc: 0.6000\n",
      "Epoch 878/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2931 - val_acc: 0.6000\n",
      "Epoch 879/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2930 - val_acc: 0.6000\n",
      "Epoch 880/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2948 - val_acc: 0.6000\n",
      "Epoch 881/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2939 - val_acc: 0.6000\n",
      "Epoch 882/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2956 - val_acc: 0.6000\n",
      "Epoch 883/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1684 - val_acc: 0.6000\n",
      "Epoch 884/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1845 - val_acc: 0.6000\n",
      "Epoch 885/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2007 - val_acc: 0.6000\n",
      "Epoch 886/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2119 - val_acc: 0.6000\n",
      "Epoch 887/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2237 - val_acc: 0.6000\n",
      "Epoch 888/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2342 - val_acc: 0.6000\n",
      "Epoch 889/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2489 - val_acc: 0.6000\n",
      "Epoch 890/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2563 - val_acc: 0.6000\n",
      "Epoch 891/10000\n",
      "96/96 [==============================] - 0s 334us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1699 - val_acc: 0.6000\n",
      "Epoch 892/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1892 - val_acc: 0.6000\n",
      "Epoch 893/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2090 - val_acc: 0.6000\n",
      "Epoch 894/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2265 - val_acc: 0.6000\n",
      "Epoch 895/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2386 - val_acc: 0.6000\n",
      "Epoch 896/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2516 - val_acc: 0.6000\n",
      "Epoch 897/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2614 - val_acc: 0.6000\n",
      "Epoch 898/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2677 - val_acc: 0.6000\n",
      "Epoch 899/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2743 - val_acc: 0.6000\n",
      "Epoch 900/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2795 - val_acc: 0.6000\n",
      "Epoch 901/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2869 - val_acc: 0.6000\n",
      "Epoch 902/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2905 - val_acc: 0.6000\n",
      "Epoch 903/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2940 - val_acc: 0.6000\n",
      "Epoch 904/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2486 - val_acc: 0.6000\n",
      "Epoch 905/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1657 - val_acc: 0.6000\n",
      "Epoch 906/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1811 - val_acc: 0.6000\n",
      "Epoch 907/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1985 - val_acc: 0.6000\n",
      "Epoch 908/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2136 - val_acc: 0.6000\n",
      "Epoch 909/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2272 - val_acc: 0.6000\n",
      "Epoch 910/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2375 - val_acc: 0.6000\n",
      "Epoch 911/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2446 - val_acc: 0.6000\n",
      "Epoch 912/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2540 - val_acc: 0.6000\n",
      "Epoch 913/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2621 - val_acc: 0.6000\n",
      "Epoch 914/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2683 - val_acc: 0.6000\n",
      "Epoch 915/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2705 - val_acc: 0.6000\n",
      "Epoch 916/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2787 - val_acc: 0.6000\n",
      "Epoch 917/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2842 - val_acc: 0.6000\n",
      "Epoch 918/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2229 - val_acc: 0.6000\n",
      "Epoch 919/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2370 - val_acc: 0.6000\n",
      "Epoch 920/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.1846 - val_acc: 0.6000\n",
      "Epoch 921/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2013 - val_acc: 0.6000\n",
      "Epoch 922/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2159 - val_acc: 0.6000\n",
      "Epoch 923/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2291 - val_acc: 0.6000\n",
      "Epoch 924/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2425 - val_acc: 0.6000\n",
      "Epoch 925/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2523 - val_acc: 0.6000\n",
      "Epoch 926/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2625 - val_acc: 0.6000\n",
      "Epoch 927/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2704 - val_acc: 0.6000\n",
      "Epoch 928/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2749 - val_acc: 0.6000\n",
      "Epoch 929/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2826 - val_acc: 0.6000\n",
      "Epoch 930/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2898 - val_acc: 0.6000\n",
      "Epoch 931/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2951 - val_acc: 0.6000\n",
      "Epoch 932/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2990 - val_acc: 0.6000\n",
      "Epoch 933/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3045 - val_acc: 0.6000\n",
      "Epoch 934/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2659 - val_acc: 0.6000\n",
      "Epoch 935/10000\n",
      "96/96 [==============================] - 0s 304us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2753 - val_acc: 0.6000\n",
      "Epoch 936/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2830 - val_acc: 0.6000\n",
      "Epoch 937/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2907 - val_acc: 0.6000\n",
      "Epoch 938/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2962 - val_acc: 0.6000\n",
      "Epoch 939/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3000 - val_acc: 0.6000\n",
      "Epoch 940/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3038 - val_acc: 0.6000\n",
      "Epoch 941/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2315 - val_acc: 0.6000\n",
      "Epoch 942/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2376 - val_acc: 0.6000\n",
      "Epoch 943/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2475 - val_acc: 0.6000\n",
      "Epoch 944/10000\n",
      "96/96 [==============================] - 0s 309us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2581 - val_acc: 0.6000\n",
      "Epoch 945/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2640 - val_acc: 0.6000\n",
      "Epoch 946/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2723 - val_acc: 0.6000\n",
      "Epoch 947/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2757 - val_acc: 0.6000\n",
      "Epoch 948/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2820 - val_acc: 0.6000\n",
      "Epoch 949/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2890 - val_acc: 0.6000\n",
      "Epoch 950/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2942 - val_acc: 0.6000\n",
      "Epoch 951/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2996 - val_acc: 0.6000\n",
      "Epoch 952/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3002 - val_acc: 0.6000\n",
      "Epoch 953/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3012 - val_acc: 0.6000\n",
      "Epoch 954/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3053 - val_acc: 0.6000\n",
      "Epoch 955/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3110 - val_acc: 0.6000\n",
      "Epoch 956/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3119 - val_acc: 0.6000\n",
      "Epoch 957/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3128 - val_acc: 0.6000\n",
      "Epoch 958/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3170 - val_acc: 0.6000\n",
      "Epoch 959/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2577 - val_acc: 0.6000\n",
      "Epoch 960/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2691 - val_acc: 0.6000\n",
      "Epoch 961/10000\n",
      "96/96 [==============================] - 0s 321us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2775 - val_acc: 0.6000\n",
      "Epoch 962/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2870 - val_acc: 0.6000\n",
      "Epoch 963/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2929 - val_acc: 0.6000\n",
      "Epoch 964/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3020 - val_acc: 0.6000\n",
      "Epoch 965/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3108 - val_acc: 0.6000\n",
      "Epoch 966/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3156 - val_acc: 0.6000\n",
      "Epoch 967/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3222 - val_acc: 0.6000\n",
      "Epoch 968/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3290 - val_acc: 0.6000\n",
      "Epoch 969/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3346 - val_acc: 0.6000\n",
      "Epoch 970/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3414 - val_acc: 0.6000\n",
      "Epoch 971/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3431 - val_acc: 0.6000\n",
      "Epoch 972/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3464 - val_acc: 0.6000\n",
      "Epoch 973/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2743 - val_acc: 0.6000\n",
      "Epoch 974/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2783 - val_acc: 0.6000\n",
      "Epoch 975/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2853 - val_acc: 0.6000\n",
      "Epoch 976/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2911 - val_acc: 0.6000\n",
      "Epoch 977/10000\n",
      "96/96 [==============================] - 0s 185us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2993 - val_acc: 0.6000\n",
      "Epoch 978/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3029 - val_acc: 0.6000\n",
      "Epoch 979/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3096 - val_acc: 0.6000\n",
      "Epoch 980/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3154 - val_acc: 0.6000\n",
      "Epoch 981/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3173 - val_acc: 0.6000\n",
      "Epoch 982/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3219 - val_acc: 0.6000\n",
      "Epoch 983/10000\n",
      "96/96 [==============================] - 0s 312us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3225 - val_acc: 0.6000\n",
      "Epoch 984/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2879 - val_acc: 0.6000\n",
      "Epoch 985/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2938 - val_acc: 0.6000\n",
      "Epoch 986/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2989 - val_acc: 0.6000\n",
      "Epoch 987/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3076 - val_acc: 0.6000\n",
      "Epoch 988/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3100 - val_acc: 0.6000\n",
      "Epoch 989/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3143 - val_acc: 0.6000\n",
      "Epoch 990/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3214 - val_acc: 0.6000\n",
      "Epoch 991/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3269 - val_acc: 0.6000\n",
      "Epoch 992/10000\n",
      "96/96 [==============================] - 0s 337us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3306 - val_acc: 0.6000\n",
      "Epoch 993/10000\n",
      "96/96 [==============================] - 0s 296us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3347 - val_acc: 0.6000\n",
      "Epoch 994/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3340 - val_acc: 0.6000\n",
      "Epoch 995/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3368 - val_acc: 0.6000\n",
      "Epoch 996/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3418 - val_acc: 0.6000\n",
      "Epoch 997/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3453 - val_acc: 0.6000\n",
      "Epoch 998/10000\n",
      "96/96 [==============================] - 0s 359us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3448 - val_acc: 0.6000\n",
      "Epoch 999/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3487 - val_acc: 0.6000\n",
      "Epoch 1000/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3515 - val_acc: 0.6000\n",
      "Epoch 1001/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3507 - val_acc: 0.6000\n",
      "Epoch 1002/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3550 - val_acc: 0.6000\n",
      "Epoch 1003/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3582 - val_acc: 0.6000\n",
      "Epoch 1004/10000\n",
      "96/96 [==============================] - 0s 319us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3598 - val_acc: 0.6000\n",
      "Epoch 1005/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2976 - val_acc: 0.6000\n",
      "Epoch 1006/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3023 - val_acc: 0.6000\n",
      "Epoch 1007/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3122 - val_acc: 0.6000\n",
      "Epoch 1008/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3204 - val_acc: 0.6000\n",
      "Epoch 1009/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3288 - val_acc: 0.6000\n",
      "Epoch 1010/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3303 - val_acc: 0.6000\n",
      "Epoch 1011/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3389 - val_acc: 0.6000\n",
      "Epoch 1012/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2659 - val_acc: 0.6000\n",
      "Epoch 1013/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2760 - val_acc: 0.6000\n",
      "Epoch 1014/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2862 - val_acc: 0.6000\n",
      "Epoch 1015/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2949 - val_acc: 0.6000\n",
      "Epoch 1016/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3065 - val_acc: 0.6000\n",
      "Epoch 1017/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3149 - val_acc: 0.6000\n",
      "Epoch 1018/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3204 - val_acc: 0.6000\n",
      "Epoch 1019/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3285 - val_acc: 0.6000\n",
      "Epoch 1020/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3360 - val_acc: 0.6000\n",
      "Epoch 1021/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3423 - val_acc: 0.6000\n",
      "Epoch 1022/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3459 - val_acc: 0.6000\n",
      "Epoch 1023/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3494 - val_acc: 0.6000\n",
      "Epoch 1024/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3510 - val_acc: 0.6000\n",
      "Epoch 1025/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3517 - val_acc: 0.6000\n",
      "Epoch 1026/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3584 - val_acc: 0.6000\n",
      "Epoch 1027/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3202 - val_acc: 0.6000\n",
      "Epoch 1028/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2602 - val_acc: 0.6000\n",
      "Epoch 1029/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2684 - val_acc: 0.6000\n",
      "Epoch 1030/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2770 - val_acc: 0.6000\n",
      "Epoch 1031/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2870 - val_acc: 0.6000\n",
      "Epoch 1032/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2976 - val_acc: 0.6000\n",
      "Epoch 1033/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3059 - val_acc: 0.6000\n",
      "Epoch 1034/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2439 - val_acc: 0.6000\n",
      "Epoch 1035/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2569 - val_acc: 0.6000\n",
      "Epoch 1036/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2648 - val_acc: 0.6000\n",
      "Epoch 1037/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2724 - val_acc: 0.6000\n",
      "Epoch 1038/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2826 - val_acc: 0.6000\n",
      "Epoch 1039/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2896 - val_acc: 0.6000\n",
      "Epoch 1040/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2961 - val_acc: 0.6000\n",
      "Epoch 1041/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3058 - val_acc: 0.6000\n",
      "Epoch 1042/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3130 - val_acc: 0.6000\n",
      "Epoch 1043/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2228 - val_acc: 0.6000\n",
      "Epoch 1044/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2432 - val_acc: 0.6000\n",
      "Epoch 1045/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2592 - val_acc: 0.6000\n",
      "Epoch 1046/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2736 - val_acc: 0.6000\n",
      "Epoch 1047/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2843 - val_acc: 0.6000\n",
      "Epoch 1048/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2953 - val_acc: 0.6000\n",
      "Epoch 1049/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3060 - val_acc: 0.6000\n",
      "Epoch 1050/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3148 - val_acc: 0.6000\n",
      "Epoch 1051/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3231 - val_acc: 0.6000\n",
      "Epoch 1052/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3262 - val_acc: 0.6000\n",
      "Epoch 1053/10000\n",
      "96/96 [==============================] - 0s 294us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3285 - val_acc: 0.6000\n",
      "Epoch 1054/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2616 - val_acc: 0.6000\n",
      "Epoch 1055/10000\n",
      "96/96 [==============================] - 0s 297us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2744 - val_acc: 0.6000\n",
      "Epoch 1056/10000\n",
      "96/96 [==============================] - 0s 311us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2825 - val_acc: 0.6000\n",
      "Epoch 1057/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2946 - val_acc: 0.6000\n",
      "Epoch 1058/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3050 - val_acc: 0.6000\n",
      "Epoch 1059/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3122 - val_acc: 0.6000\n",
      "Epoch 1060/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3212 - val_acc: 0.6000\n",
      "Epoch 1061/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3250 - val_acc: 0.6000\n",
      "Epoch 1062/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3315 - val_acc: 0.6000\n",
      "Epoch 1063/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3343 - val_acc: 0.6000\n",
      "Epoch 1064/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3412 - val_acc: 0.6000\n",
      "Epoch 1065/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3488 - val_acc: 0.6000\n",
      "Epoch 1066/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3557 - val_acc: 0.6000\n",
      "Epoch 1067/10000\n",
      "96/96 [==============================] - 0s 302us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2972 - val_acc: 0.6000\n",
      "Epoch 1068/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3093 - val_acc: 0.6000\n",
      "Epoch 1069/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3205 - val_acc: 0.6000\n",
      "Epoch 1070/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3287 - val_acc: 0.6000\n",
      "Epoch 1071/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3365 - val_acc: 0.6000\n",
      "Epoch 1072/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3450 - val_acc: 0.6000\n",
      "Epoch 1073/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3496 - val_acc: 0.6000\n",
      "Epoch 1074/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3584 - val_acc: 0.6000\n",
      "Epoch 1075/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2901 - val_acc: 0.6000\n",
      "Epoch 1076/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3020 - val_acc: 0.6000\n",
      "Epoch 1077/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3101 - val_acc: 0.6000\n",
      "Epoch 1078/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3185 - val_acc: 0.6000\n",
      "Epoch 1079/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3259 - val_acc: 0.6000\n",
      "Epoch 1080/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3324 - val_acc: 0.6000\n",
      "Epoch 1081/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3356 - val_acc: 0.6000\n",
      "Epoch 1082/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3393 - val_acc: 0.6000\n",
      "Epoch 1083/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3475 - val_acc: 0.6000\n",
      "Epoch 1084/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3497 - val_acc: 0.6000\n",
      "Epoch 1085/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3531 - val_acc: 0.6000\n",
      "Epoch 1086/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3576 - val_acc: 0.6000\n",
      "Epoch 1087/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3144 - val_acc: 0.6000\n",
      "Epoch 1088/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3075 - val_acc: 0.6000\n",
      "Epoch 1089/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3187 - val_acc: 0.6000\n",
      "Epoch 1090/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3254 - val_acc: 0.6000\n",
      "Epoch 1091/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3312 - val_acc: 0.6000\n",
      "Epoch 1092/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3365 - val_acc: 0.6000\n",
      "Epoch 1093/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3435 - val_acc: 0.6000\n",
      "Epoch 1094/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3509 - val_acc: 0.6000\n",
      "Epoch 1095/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3548 - val_acc: 0.6000\n",
      "Epoch 1096/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3577 - val_acc: 0.6000\n",
      "Epoch 1097/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3586 - val_acc: 0.6000\n",
      "Epoch 1098/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3612 - val_acc: 0.6000\n",
      "Epoch 1099/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3651 - val_acc: 0.6000\n",
      "Epoch 1100/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3687 - val_acc: 0.6000\n",
      "Epoch 1101/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3706 - val_acc: 0.6000\n",
      "Epoch 1102/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3381 - val_acc: 0.6000\n",
      "Epoch 1103/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3429 - val_acc: 0.6000\n",
      "Epoch 1104/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3492 - val_acc: 0.6000\n",
      "Epoch 1105/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3557 - val_acc: 0.6000\n",
      "Epoch 1106/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3608 - val_acc: 0.6000\n",
      "Epoch 1107/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3655 - val_acc: 0.6000\n",
      "Epoch 1108/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3696 - val_acc: 0.6000\n",
      "Epoch 1109/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3697 - val_acc: 0.6000\n",
      "Epoch 1110/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3703 - val_acc: 0.6000\n",
      "Epoch 1111/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3719 - val_acc: 0.6000\n",
      "Epoch 1112/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3126 - val_acc: 0.6000\n",
      "Epoch 1113/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3238 - val_acc: 0.6000\n",
      "Epoch 1114/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3343 - val_acc: 0.6000\n",
      "Epoch 1115/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3403 - val_acc: 0.6000\n",
      "Epoch 1116/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3492 - val_acc: 0.6000\n",
      "Epoch 1117/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3541 - val_acc: 0.6000\n",
      "Epoch 1118/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2848 - val_acc: 0.6000\n",
      "Epoch 1119/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2963 - val_acc: 0.6000\n",
      "Epoch 1120/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3086 - val_acc: 0.6000\n",
      "Epoch 1121/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3185 - val_acc: 0.6000\n",
      "Epoch 1122/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3291 - val_acc: 0.6000\n",
      "Epoch 1123/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3394 - val_acc: 0.6000\n",
      "Epoch 1124/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3484 - val_acc: 0.6000\n",
      "Epoch 1125/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3540 - val_acc: 0.6000\n",
      "Epoch 1126/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3591 - val_acc: 0.6000\n",
      "Epoch 1127/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3659 - val_acc: 0.6000\n",
      "Epoch 1128/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3710 - val_acc: 0.6000\n",
      "Epoch 1129/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3758 - val_acc: 0.6000\n",
      "Epoch 1130/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3783 - val_acc: 0.6000\n",
      "Epoch 1131/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3832 - val_acc: 0.6000\n",
      "Epoch 1132/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3841 - val_acc: 0.6000\n",
      "Epoch 1133/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3868 - val_acc: 0.6000\n",
      "Epoch 1134/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3908 - val_acc: 0.6000\n",
      "Epoch 1135/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3958 - val_acc: 0.6000\n",
      "Epoch 1136/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3955 - val_acc: 0.6000\n",
      "Epoch 1137/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3992 - val_acc: 0.6000\n",
      "Epoch 1138/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4029 - val_acc: 0.6000\n",
      "Epoch 1139/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4037 - val_acc: 0.6000\n",
      "Epoch 1140/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4033 - val_acc: 0.6000\n",
      "Epoch 1141/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4066 - val_acc: 0.6000\n",
      "Epoch 1142/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3410 - val_acc: 0.6000\n",
      "Epoch 1143/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3483 - val_acc: 0.6000\n",
      "Epoch 1144/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3562 - val_acc: 0.6000\n",
      "Epoch 1145/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2663 - val_acc: 0.6000\n",
      "Epoch 1146/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.2834 - val_acc: 0.6000\n",
      "Epoch 1147/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3003 - val_acc: 0.6000\n",
      "Epoch 1148/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3137 - val_acc: 0.6000\n",
      "Epoch 1149/10000\n",
      "96/96 [==============================] - 0s 185us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3236 - val_acc: 0.6000\n",
      "Epoch 1150/10000\n",
      "96/96 [==============================] - 0s 179us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3363 - val_acc: 0.6000\n",
      "Epoch 1151/10000\n",
      "96/96 [==============================] - 0s 165us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3446 - val_acc: 0.6000\n",
      "Epoch 1152/10000\n",
      "96/96 [==============================] - 0s 312us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3512 - val_acc: 0.6000\n",
      "Epoch 1153/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3202 - val_acc: 0.6000\n",
      "Epoch 1154/10000\n",
      "96/96 [==============================] - 0s 411us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3293 - val_acc: 0.6000\n",
      "Epoch 1155/10000\n",
      "96/96 [==============================] - 0s 357us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3395 - val_acc: 0.6000\n",
      "Epoch 1156/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3480 - val_acc: 0.6000\n",
      "Epoch 1157/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3536 - val_acc: 0.6000\n",
      "Epoch 1158/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3606 - val_acc: 0.6000\n",
      "Epoch 1159/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3675 - val_acc: 0.6000\n",
      "Epoch 1160/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3709 - val_acc: 0.6000\n",
      "Epoch 1161/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3742 - val_acc: 0.6000\n",
      "Epoch 1162/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3030 - val_acc: 0.6000\n",
      "Epoch 1163/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3149 - val_acc: 0.6000\n",
      "Epoch 1164/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3259 - val_acc: 0.6000\n",
      "Epoch 1165/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3377 - val_acc: 0.6000\n",
      "Epoch 1166/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3460 - val_acc: 0.6000\n",
      "Epoch 1167/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3544 - val_acc: 0.6000\n",
      "Epoch 1168/10000\n",
      "96/96 [==============================] - 0s 314us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3583 - val_acc: 0.6000\n",
      "Epoch 1169/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3634 - val_acc: 0.6000\n",
      "Epoch 1170/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3672 - val_acc: 0.6000\n",
      "Epoch 1171/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3121 - val_acc: 0.6000\n",
      "Epoch 1172/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3222 - val_acc: 0.6000\n",
      "Epoch 1173/10000\n",
      "96/96 [==============================] - 0s 314us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3319 - val_acc: 0.6000\n",
      "Epoch 1174/10000\n",
      "96/96 [==============================] - 0s 357us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3408 - val_acc: 0.6000\n",
      "Epoch 1175/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3517 - val_acc: 0.6000\n",
      "Epoch 1176/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3579 - val_acc: 0.6000\n",
      "Epoch 1177/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3684 - val_acc: 0.6000\n",
      "Epoch 1178/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3734 - val_acc: 0.6000\n",
      "Epoch 1179/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3798 - val_acc: 0.6000\n",
      "Epoch 1180/10000\n",
      "96/96 [==============================] - 0s 183us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3856 - val_acc: 0.6000\n",
      "Epoch 1181/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3902 - val_acc: 0.6000\n",
      "Epoch 1182/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3954 - val_acc: 0.6000\n",
      "Epoch 1183/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3987 - val_acc: 0.6000\n",
      "Epoch 1184/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4047 - val_acc: 0.6000\n",
      "Epoch 1185/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4062 - val_acc: 0.6000\n",
      "Epoch 1186/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4098 - val_acc: 0.6000\n",
      "Epoch 1187/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4145 - val_acc: 0.6000\n",
      "Epoch 1188/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4159 - val_acc: 0.6000\n",
      "Epoch 1189/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4168 - val_acc: 0.6000\n",
      "Epoch 1190/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4170 - val_acc: 0.6000\n",
      "Epoch 1191/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4201 - val_acc: 0.6000\n",
      "Epoch 1192/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4235 - val_acc: 0.6000\n",
      "Epoch 1193/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4264 - val_acc: 0.6000\n",
      "Epoch 1194/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4294 - val_acc: 0.6000\n",
      "Epoch 1195/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4273 - val_acc: 0.6000\n",
      "Epoch 1196/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4266 - val_acc: 0.6000\n",
      "Epoch 1197/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3530 - val_acc: 0.6000\n",
      "Epoch 1198/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3595 - val_acc: 0.6000\n",
      "Epoch 1199/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3665 - val_acc: 0.6000\n",
      "Epoch 1200/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3685 - val_acc: 0.6000\n",
      "Epoch 1201/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3744 - val_acc: 0.6000\n",
      "Epoch 1202/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3829 - val_acc: 0.6000\n",
      "Epoch 1203/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3892 - val_acc: 0.6000\n",
      "Epoch 1204/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3956 - val_acc: 0.6000\n",
      "Epoch 1205/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4011 - val_acc: 0.6000\n",
      "Epoch 1206/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4065 - val_acc: 0.6000\n",
      "Epoch 1207/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4106 - val_acc: 0.6000\n",
      "Epoch 1208/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4131 - val_acc: 0.6000\n",
      "Epoch 1209/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3696 - val_acc: 0.6000\n",
      "Epoch 1210/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3755 - val_acc: 0.6000\n",
      "Epoch 1211/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3835 - val_acc: 0.6000\n",
      "Epoch 1212/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3898 - val_acc: 0.6000\n",
      "Epoch 1213/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3947 - val_acc: 0.6000\n",
      "Epoch 1214/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4035 - val_acc: 0.6000\n",
      "Epoch 1215/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4102 - val_acc: 0.6000\n",
      "Epoch 1216/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4152 - val_acc: 0.6000\n",
      "Epoch 1217/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4170 - val_acc: 0.6000\n",
      "Epoch 1218/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4183 - val_acc: 0.6000\n",
      "Epoch 1219/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4225 - val_acc: 0.6000\n",
      "Epoch 1220/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3847 - val_acc: 0.6000\n",
      "Epoch 1221/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3917 - val_acc: 0.6000\n",
      "Epoch 1222/10000\n",
      "96/96 [==============================] - 0s 306us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3967 - val_acc: 0.6000\n",
      "Epoch 1223/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3999 - val_acc: 0.6000\n",
      "Epoch 1224/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4035 - val_acc: 0.6000\n",
      "Epoch 1225/10000\n",
      "96/96 [==============================] - 0s 359us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4087 - val_acc: 0.6000\n",
      "Epoch 1226/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4139 - val_acc: 0.6000\n",
      "Epoch 1227/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4183 - val_acc: 0.6000\n",
      "Epoch 1228/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4229 - val_acc: 0.6000\n",
      "Epoch 1229/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4248 - val_acc: 0.6000\n",
      "Epoch 1230/10000\n",
      "96/96 [==============================] - 0s 303us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4256 - val_acc: 0.6000\n",
      "Epoch 1231/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4285 - val_acc: 0.6000\n",
      "Epoch 1232/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4282 - val_acc: 0.6000\n",
      "Epoch 1233/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4328 - val_acc: 0.6000\n",
      "Epoch 1234/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4331 - val_acc: 0.6000\n",
      "Epoch 1235/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4366 - val_acc: 0.6000\n",
      "Epoch 1236/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4378 - val_acc: 0.6000\n",
      "Epoch 1237/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4385 - val_acc: 0.6000\n",
      "Epoch 1238/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4413 - val_acc: 0.6000\n",
      "Epoch 1239/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4419 - val_acc: 0.6000\n",
      "Epoch 1240/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3226 - val_acc: 0.6000\n",
      "Epoch 1241/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3240 - val_acc: 0.6000\n",
      "Epoch 1242/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3366 - val_acc: 0.6000\n",
      "Epoch 1243/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3463 - val_acc: 0.6000\n",
      "Epoch 1244/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3592 - val_acc: 0.6000\n",
      "Epoch 1245/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3705 - val_acc: 0.6000\n",
      "Epoch 1246/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3770 - val_acc: 0.6000\n",
      "Epoch 1247/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3860 - val_acc: 0.6000\n",
      "Epoch 1248/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3906 - val_acc: 0.6000\n",
      "Epoch 1249/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3987 - val_acc: 0.6000\n",
      "Epoch 1250/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4032 - val_acc: 0.6000\n",
      "Epoch 1251/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4045 - val_acc: 0.6000\n",
      "Epoch 1252/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3106 - val_acc: 0.6000\n",
      "Epoch 1253/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3300 - val_acc: 0.6000\n",
      "Epoch 1254/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3480 - val_acc: 0.6000\n",
      "Epoch 1255/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3637 - val_acc: 0.6000\n",
      "Epoch 1256/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3761 - val_acc: 0.6000\n",
      "Epoch 1257/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3868 - val_acc: 0.6000\n",
      "Epoch 1258/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3352 - val_acc: 0.6000\n",
      "Epoch 1259/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3508 - val_acc: 0.6000\n",
      "Epoch 1260/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3639 - val_acc: 0.6000\n",
      "Epoch 1261/10000\n",
      "96/96 [==============================] - 0s 198us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3757 - val_acc: 0.6000\n",
      "Epoch 1262/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3862 - val_acc: 0.6000\n",
      "Epoch 1263/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3947 - val_acc: 0.6000\n",
      "Epoch 1264/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4023 - val_acc: 0.6000\n",
      "Epoch 1265/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4104 - val_acc: 0.6000\n",
      "Epoch 1266/10000\n",
      "96/96 [==============================] - 0s 310us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3408 - val_acc: 0.6000\n",
      "Epoch 1267/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3487 - val_acc: 0.6000\n",
      "Epoch 1268/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3583 - val_acc: 0.6000\n",
      "Epoch 1269/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3679 - val_acc: 0.6000\n",
      "Epoch 1270/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3744 - val_acc: 0.6000\n",
      "Epoch 1271/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3840 - val_acc: 0.6000\n",
      "Epoch 1272/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3886 - val_acc: 0.6000\n",
      "Epoch 1273/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3968 - val_acc: 0.6000\n",
      "Epoch 1274/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4048 - val_acc: 0.6000\n",
      "Epoch 1275/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4106 - val_acc: 0.6000\n",
      "Epoch 1276/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4163 - val_acc: 0.6000\n",
      "Epoch 1277/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4206 - val_acc: 0.6000\n",
      "Epoch 1278/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4250 - val_acc: 0.6000\n",
      "Epoch 1279/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 195us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4308 - val_acc: 0.6000\n",
      "Epoch 1280/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4352 - val_acc: 0.6000\n",
      "Epoch 1281/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4354 - val_acc: 0.6000\n",
      "Epoch 1282/10000\n",
      "96/96 [==============================] - 0s 194us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4363 - val_acc: 0.6000\n",
      "Epoch 1283/10000\n",
      "96/96 [==============================] - 0s 196us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4405 - val_acc: 0.6000\n",
      "Epoch 1284/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4016 - val_acc: 0.6000\n",
      "Epoch 1285/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3381 - val_acc: 0.6000\n",
      "Epoch 1286/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3473 - val_acc: 0.6000\n",
      "Epoch 1287/10000\n",
      "96/96 [==============================] - 0s 191us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3562 - val_acc: 0.6000\n",
      "Epoch 1288/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3665 - val_acc: 0.6000\n",
      "Epoch 1289/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3729 - val_acc: 0.6000\n",
      "Epoch 1290/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3805 - val_acc: 0.6000\n",
      "Epoch 1291/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3890 - val_acc: 0.6000\n",
      "Epoch 1292/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3938 - val_acc: 0.6000\n",
      "Epoch 1293/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4006 - val_acc: 0.6000\n",
      "Epoch 1294/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3413 - val_acc: 0.6000\n",
      "Epoch 1295/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3518 - val_acc: 0.6000\n",
      "Epoch 1296/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3616 - val_acc: 0.6000\n",
      "Epoch 1297/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3677 - val_acc: 0.6000\n",
      "Epoch 1298/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3764 - val_acc: 0.6000\n",
      "Epoch 1299/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3854 - val_acc: 0.6000\n",
      "Epoch 1300/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3925 - val_acc: 0.6000\n",
      "Epoch 1301/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3968 - val_acc: 0.6000\n",
      "Epoch 1302/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3281 - val_acc: 0.6000\n",
      "Epoch 1303/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3392 - val_acc: 0.6000\n",
      "Epoch 1304/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3492 - val_acc: 0.6000\n",
      "Epoch 1305/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3576 - val_acc: 0.6000\n",
      "Epoch 1306/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3679 - val_acc: 0.6000\n",
      "Epoch 1307/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3786 - val_acc: 0.6000\n",
      "Epoch 1308/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3867 - val_acc: 0.6000\n",
      "Epoch 1309/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3933 - val_acc: 0.6000\n",
      "Epoch 1310/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3988 - val_acc: 0.6000\n",
      "Epoch 1311/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4057 - val_acc: 0.6000\n",
      "Epoch 1312/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4093 - val_acc: 0.6000\n",
      "Epoch 1313/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3521 - val_acc: 0.6000\n",
      "Epoch 1314/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3632 - val_acc: 0.6000\n",
      "Epoch 1315/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3753 - val_acc: 0.6000\n",
      "Epoch 1316/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3850 - val_acc: 0.6000\n",
      "Epoch 1317/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3911 - val_acc: 0.6000\n",
      "Epoch 1318/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4011 - val_acc: 0.6000\n",
      "Epoch 1319/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4086 - val_acc: 0.6000\n",
      "Epoch 1320/10000\n",
      "96/96 [==============================] - 0s 201us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4149 - val_acc: 0.6000\n",
      "Epoch 1321/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4225 - val_acc: 0.6000\n",
      "Epoch 1322/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4253 - val_acc: 0.6000\n",
      "Epoch 1323/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4303 - val_acc: 0.6000\n",
      "Epoch 1324/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4347 - val_acc: 0.6000\n",
      "Epoch 1325/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4361 - val_acc: 0.6000\n",
      "Epoch 1326/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4413 - val_acc: 0.6000\n",
      "Epoch 1327/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4426 - val_acc: 0.6000\n",
      "Epoch 1328/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4455 - val_acc: 0.6000\n",
      "Epoch 1329/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4472 - val_acc: 0.6000\n",
      "Epoch 1330/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4512 - val_acc: 0.6000\n",
      "Epoch 1331/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4561 - val_acc: 0.6000\n",
      "Epoch 1332/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4585 - val_acc: 0.6000\n",
      "Epoch 1333/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4610 - val_acc: 0.6000\n",
      "Epoch 1334/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4629 - val_acc: 0.6000\n",
      "Epoch 1335/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4656 - val_acc: 0.6000\n",
      "Epoch 1336/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4273 - val_acc: 0.6000\n",
      "Epoch 1337/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4303 - val_acc: 0.6000\n",
      "Epoch 1338/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4316 - val_acc: 0.6000\n",
      "Epoch 1339/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4343 - val_acc: 0.6000\n",
      "Epoch 1340/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4394 - val_acc: 0.6000\n",
      "Epoch 1341/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4422 - val_acc: 0.6000\n",
      "Epoch 1342/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4432 - val_acc: 0.6000\n",
      "Epoch 1343/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4473 - val_acc: 0.6000\n",
      "Epoch 1344/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4530 - val_acc: 0.6000\n",
      "Epoch 1345/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4564 - val_acc: 0.6000\n",
      "Epoch 1346/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4573 - val_acc: 0.6000\n",
      "Epoch 1347/10000\n",
      "96/96 [==============================] - 0s 316us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3817 - val_acc: 0.6000\n",
      "Epoch 1348/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3891 - val_acc: 0.6000\n",
      "Epoch 1349/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3978 - val_acc: 0.6000\n",
      "Epoch 1350/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4052 - val_acc: 0.6000\n",
      "Epoch 1351/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4158 - val_acc: 0.6000\n",
      "Epoch 1352/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4238 - val_acc: 0.6000\n",
      "Epoch 1353/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4309 - val_acc: 0.6000\n",
      "Epoch 1354/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4368 - val_acc: 0.6000\n",
      "Epoch 1355/10000\n",
      "96/96 [==============================] - 0s 306us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4393 - val_acc: 0.6000\n",
      "Epoch 1356/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4449 - val_acc: 0.6000\n",
      "Epoch 1357/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4495 - val_acc: 0.6000\n",
      "Epoch 1358/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4526 - val_acc: 0.6000\n",
      "Epoch 1359/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4564 - val_acc: 0.6000\n",
      "Epoch 1360/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4596 - val_acc: 0.6000\n",
      "Epoch 1361/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4599 - val_acc: 0.6000\n",
      "Epoch 1362/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4615 - val_acc: 0.6000\n",
      "Epoch 1363/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4655 - val_acc: 0.6000\n",
      "Epoch 1364/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4655 - val_acc: 0.6000\n",
      "Epoch 1365/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4672 - val_acc: 0.6000\n",
      "Epoch 1366/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4714 - val_acc: 0.6000\n",
      "Epoch 1367/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4113 - val_acc: 0.6000\n",
      "Epoch 1368/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4210 - val_acc: 0.6000\n",
      "Epoch 1369/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4290 - val_acc: 0.6000\n",
      "Epoch 1370/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4368 - val_acc: 0.6000\n",
      "Epoch 1371/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4438 - val_acc: 0.6000\n",
      "Epoch 1372/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4506 - val_acc: 0.6000\n",
      "Epoch 1373/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4572 - val_acc: 0.6000\n",
      "Epoch 1374/10000\n",
      "96/96 [==============================] - 0s 198us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4619 - val_acc: 0.6000\n",
      "Epoch 1375/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4654 - val_acc: 0.6000\n",
      "Epoch 1376/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4682 - val_acc: 0.6000\n",
      "Epoch 1377/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4706 - val_acc: 0.6000\n",
      "Epoch 1378/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4739 - val_acc: 0.6000\n",
      "Epoch 1379/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4743 - val_acc: 0.6000\n",
      "Epoch 1380/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4789 - val_acc: 0.6000\n",
      "Epoch 1381/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4833 - val_acc: 0.6000\n",
      "Epoch 1382/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4842 - val_acc: 0.6000\n",
      "Epoch 1383/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4862 - val_acc: 0.6000\n",
      "Epoch 1384/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4883 - val_acc: 0.6000\n",
      "Epoch 1385/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4875 - val_acc: 0.6000\n",
      "Epoch 1386/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4900 - val_acc: 0.6000\n",
      "Epoch 1387/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4897 - val_acc: 0.6000\n",
      "Epoch 1388/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4141 - val_acc: 0.6000\n",
      "Epoch 1389/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4231 - val_acc: 0.6000\n",
      "Epoch 1390/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4283 - val_acc: 0.6000\n",
      "Epoch 1391/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4339 - val_acc: 0.6000\n",
      "Epoch 1392/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4396 - val_acc: 0.6000\n",
      "Epoch 1393/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4480 - val_acc: 0.6000\n",
      "Epoch 1394/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4531 - val_acc: 0.6000\n",
      "Epoch 1395/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4580 - val_acc: 0.6000\n",
      "Epoch 1396/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4609 - val_acc: 0.6000\n",
      "Epoch 1397/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4671 - val_acc: 0.6000\n",
      "Epoch 1398/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4724 - val_acc: 0.6000\n",
      "Epoch 1399/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4273 - val_acc: 0.6000\n",
      "Epoch 1400/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4174 - val_acc: 0.6000\n",
      "Epoch 1401/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4270 - val_acc: 0.6000\n",
      "Epoch 1402/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4341 - val_acc: 0.6000\n",
      "Epoch 1403/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4430 - val_acc: 0.6000\n",
      "Epoch 1404/10000\n",
      "96/96 [==============================] - 0s 305us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4481 - val_acc: 0.6000\n",
      "Epoch 1405/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4538 - val_acc: 0.6000\n",
      "Epoch 1406/10000\n",
      "96/96 [==============================] - 0s 362us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4578 - val_acc: 0.6000\n",
      "Epoch 1407/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4620 - val_acc: 0.6000\n",
      "Epoch 1408/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4666 - val_acc: 0.6000\n",
      "Epoch 1409/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3952 - val_acc: 0.6000\n",
      "Epoch 1410/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4037 - val_acc: 0.6000\n",
      "Epoch 1411/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4142 - val_acc: 0.6000\n",
      "Epoch 1412/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4222 - val_acc: 0.6000\n",
      "Epoch 1413/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4308 - val_acc: 0.6000\n",
      "Epoch 1414/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4385 - val_acc: 0.6000\n",
      "Epoch 1415/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4461 - val_acc: 0.6000\n",
      "Epoch 1416/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4529 - val_acc: 0.6000\n",
      "Epoch 1417/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4595 - val_acc: 0.6000\n",
      "Epoch 1418/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4649 - val_acc: 0.6000\n",
      "Epoch 1419/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4682 - val_acc: 0.6000\n",
      "Epoch 1420/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4718 - val_acc: 0.6000\n",
      "Epoch 1421/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4762 - val_acc: 0.6000\n",
      "Epoch 1422/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4141 - val_acc: 0.6000\n",
      "Epoch 1423/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4200 - val_acc: 0.6000\n",
      "Epoch 1424/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3682 - val_acc: 0.6000\n",
      "Epoch 1425/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3791 - val_acc: 0.6000\n",
      "Epoch 1426/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3914 - val_acc: 0.6000\n",
      "Epoch 1427/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4013 - val_acc: 0.6000\n",
      "Epoch 1428/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4132 - val_acc: 0.6000\n",
      "Epoch 1429/10000\n",
      "96/96 [==============================] - 0s 302us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4220 - val_acc: 0.6000\n",
      "Epoch 1430/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4305 - val_acc: 0.6000\n",
      "Epoch 1431/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4375 - val_acc: 0.6000\n",
      "Epoch 1432/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4425 - val_acc: 0.6000\n",
      "Epoch 1433/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4481 - val_acc: 0.6000\n",
      "Epoch 1434/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4562 - val_acc: 0.6000\n",
      "Epoch 1435/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4608 - val_acc: 0.6000\n",
      "Epoch 1436/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4291 - val_acc: 0.6000\n",
      "Epoch 1437/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4343 - val_acc: 0.6000\n",
      "Epoch 1438/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4408 - val_acc: 0.6000\n",
      "Epoch 1439/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4456 - val_acc: 0.6000\n",
      "Epoch 1440/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4524 - val_acc: 0.6000\n",
      "Epoch 1441/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4555 - val_acc: 0.6000\n",
      "Epoch 1442/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4620 - val_acc: 0.6000\n",
      "Epoch 1443/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4661 - val_acc: 0.6000\n",
      "Epoch 1444/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.3766 - val_acc: 0.6000\n",
      "Epoch 1445/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.3926 - val_acc: 0.6000\n",
      "Epoch 1446/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4071 - val_acc: 0.6000\n",
      "Epoch 1447/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4190 - val_acc: 0.6000\n",
      "Epoch 1448/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4304 - val_acc: 0.6000\n",
      "Epoch 1449/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4404 - val_acc: 0.6000\n",
      "Epoch 1450/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4492 - val_acc: 0.6000\n",
      "Epoch 1451/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4558 - val_acc: 0.6000\n",
      "Epoch 1452/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4605 - val_acc: 0.6000\n",
      "Epoch 1453/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4643 - val_acc: 0.6000\n",
      "Epoch 1454/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4683 - val_acc: 0.6000\n",
      "Epoch 1455/10000\n",
      "96/96 [==============================] - 0s 193us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4713 - val_acc: 0.6000\n",
      "Epoch 1456/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4768 - val_acc: 0.6000\n",
      "Epoch 1457/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4059 - val_acc: 0.6000\n",
      "Epoch 1458/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4144 - val_acc: 0.6000\n",
      "Epoch 1459/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4227 - val_acc: 0.6000\n",
      "Epoch 1460/10000\n",
      "96/96 [==============================] - 0s 326us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4312 - val_acc: 0.6000\n",
      "Epoch 1461/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4408 - val_acc: 0.6000\n",
      "Epoch 1462/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4474 - val_acc: 0.6000\n",
      "Epoch 1463/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4567 - val_acc: 0.6000\n",
      "Epoch 1464/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4632 - val_acc: 0.6000\n",
      "Epoch 1465/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4699 - val_acc: 0.6000\n",
      "Epoch 1466/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4722 - val_acc: 0.6000\n",
      "Epoch 1467/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4779 - val_acc: 0.6000\n",
      "Epoch 1468/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4818 - val_acc: 0.6000\n",
      "Epoch 1469/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4867 - val_acc: 0.6000\n",
      "Epoch 1470/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4876 - val_acc: 0.6000\n",
      "Epoch 1471/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4904 - val_acc: 0.6000\n",
      "Epoch 1472/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4926 - val_acc: 0.6000\n",
      "Epoch 1473/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4940 - val_acc: 0.6000\n",
      "Epoch 1474/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4961 - val_acc: 0.6000\n",
      "Epoch 1475/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4993 - val_acc: 0.6000\n",
      "Epoch 1476/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.5031 - val_acc: 0.6000\n",
      "Epoch 1477/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.5037 - val_acc: 0.6000\n",
      "Epoch 1478/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.5054 - val_acc: 0.6000\n",
      "Epoch 1479/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4477 - val_acc: 0.6000\n",
      "Epoch 1480/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4556 - val_acc: 0.6000\n",
      "Epoch 1481/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4644 - val_acc: 0.6000\n",
      "Epoch 1482/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4713 - val_acc: 0.6000\n",
      "Epoch 1483/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4776 - val_acc: 0.6000\n",
      "Epoch 1484/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4819 - val_acc: 0.6000\n",
      "Epoch 1485/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4892 - val_acc: 0.6000\n",
      "Epoch 1486/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4932 - val_acc: 0.6000\n",
      "Epoch 1487/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4987 - val_acc: 0.6000\n",
      "Epoch 1488/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5031 - val_acc: 0.6000\n",
      "Epoch 1489/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5058 - val_acc: 0.6000\n",
      "Epoch 1490/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5097 - val_acc: 0.6000\n",
      "Epoch 1491/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5099 - val_acc: 0.6000\n",
      "Epoch 1492/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5130 - val_acc: 0.6000\n",
      "Epoch 1493/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5154 - val_acc: 0.6000\n",
      "Epoch 1494/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4802 - val_acc: 0.6000\n",
      "Epoch 1495/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4162 - val_acc: 0.6000\n",
      "Epoch 1496/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4254 - val_acc: 0.6000\n",
      "Epoch 1497/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4331 - val_acc: 0.6000\n",
      "Epoch 1498/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4408 - val_acc: 0.6000\n",
      "Epoch 1499/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4483 - val_acc: 0.6000\n",
      "Epoch 1500/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4567 - val_acc: 0.6000\n",
      "Epoch 1501/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4605 - val_acc: 0.6000\n",
      "Epoch 1502/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4683 - val_acc: 0.6000\n",
      "Epoch 1503/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4718 - val_acc: 0.6000\n",
      "Epoch 1504/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4787 - val_acc: 0.6000\n",
      "Epoch 1505/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4812 - val_acc: 0.6000\n",
      "Epoch 1506/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4845 - val_acc: 0.6000\n",
      "Epoch 1507/10000\n",
      "96/96 [==============================] - 0s 303us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4876 - val_acc: 0.6000\n",
      "Epoch 1508/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4148 - val_acc: 0.6000\n",
      "Epoch 1509/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4223 - val_acc: 0.6000\n",
      "Epoch 1510/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4310 - val_acc: 0.6000\n",
      "Epoch 1511/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4399 - val_acc: 0.6000\n",
      "Epoch 1512/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4482 - val_acc: 0.6000\n",
      "Epoch 1513/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4553 - val_acc: 0.6000\n",
      "Epoch 1514/10000\n",
      "96/96 [==============================] - 0s 306us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4619 - val_acc: 0.6000\n",
      "Epoch 1515/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4702 - val_acc: 0.6000\n",
      "Epoch 1516/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4756 - val_acc: 0.6000\n",
      "Epoch 1517/10000\n",
      "96/96 [==============================] - 0s 417us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4815 - val_acc: 0.6000\n",
      "Epoch 1518/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4850 - val_acc: 0.6000\n",
      "Epoch 1519/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4905 - val_acc: 0.6000\n",
      "Epoch 1520/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4967 - val_acc: 0.6000\n",
      "Epoch 1521/10000\n",
      "96/96 [==============================] - 0s 307us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4986 - val_acc: 0.6000\n",
      "Epoch 1522/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5020 - val_acc: 0.6000\n",
      "Epoch 1523/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5070 - val_acc: 0.6000\n",
      "Epoch 1524/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5093 - val_acc: 0.6000\n",
      "Epoch 1525/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5118 - val_acc: 0.6000\n",
      "Epoch 1526/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5154 - val_acc: 0.6000\n",
      "Epoch 1527/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5156 - val_acc: 0.6000\n",
      "Epoch 1528/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5187 - val_acc: 0.6000\n",
      "Epoch 1529/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5212 - val_acc: 0.6000\n",
      "Epoch 1530/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5231 - val_acc: 0.6000\n",
      "Epoch 1531/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5226 - val_acc: 0.6000\n",
      "Epoch 1532/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5239 - val_acc: 0.6000\n",
      "Epoch 1533/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5277 - val_acc: 0.6000\n",
      "Epoch 1534/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4647 - val_acc: 0.6000\n",
      "Epoch 1535/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4717 - val_acc: 0.6000\n",
      "Epoch 1536/10000\n",
      "96/96 [==============================] - 0s 197us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4788 - val_acc: 0.6000\n",
      "Epoch 1537/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4842 - val_acc: 0.6000\n",
      "Epoch 1538/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4866 - val_acc: 0.6000\n",
      "Epoch 1539/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4914 - val_acc: 0.6000\n",
      "Epoch 1540/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4938 - val_acc: 0.6000\n",
      "Epoch 1541/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4378 - val_acc: 0.6000\n",
      "Epoch 1542/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4485 - val_acc: 0.6000\n",
      "Epoch 1543/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4576 - val_acc: 0.6000\n",
      "Epoch 1544/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4671 - val_acc: 0.6000\n",
      "Epoch 1545/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4735 - val_acc: 0.6000\n",
      "Epoch 1546/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4810 - val_acc: 0.6000\n",
      "Epoch 1547/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4874 - val_acc: 0.6000\n",
      "Epoch 1548/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4910 - val_acc: 0.6000\n",
      "Epoch 1549/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4976 - val_acc: 0.6000\n",
      "Epoch 1550/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4635 - val_acc: 0.6000\n",
      "Epoch 1551/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4698 - val_acc: 0.6000\n",
      "Epoch 1552/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4746 - val_acc: 0.6000\n",
      "Epoch 1553/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4821 - val_acc: 0.6000\n",
      "Epoch 1554/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4867 - val_acc: 0.6000\n",
      "Epoch 1555/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4909 - val_acc: 0.6000\n",
      "Epoch 1556/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4949 - val_acc: 0.6000\n",
      "Epoch 1557/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4989 - val_acc: 0.6000\n",
      "Epoch 1558/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5044 - val_acc: 0.6000\n",
      "Epoch 1559/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5069 - val_acc: 0.6000\n",
      "Epoch 1560/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4353 - val_acc: 0.6000\n",
      "Epoch 1561/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4431 - val_acc: 0.6000\n",
      "Epoch 1562/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4534 - val_acc: 0.6000\n",
      "Epoch 1563/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4620 - val_acc: 0.6000\n",
      "Epoch 1564/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4699 - val_acc: 0.6000\n",
      "Epoch 1565/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4791 - val_acc: 0.6000\n",
      "Epoch 1566/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4850 - val_acc: 0.6000\n",
      "Epoch 1567/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4914 - val_acc: 0.6000\n",
      "Epoch 1568/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4988 - val_acc: 0.6000\n",
      "Epoch 1569/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5021 - val_acc: 0.6000\n",
      "Epoch 1570/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5086 - val_acc: 0.6000\n",
      "Epoch 1571/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5137 - val_acc: 0.6000\n",
      "Epoch 1572/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5177 - val_acc: 0.6000\n",
      "Epoch 1573/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5189 - val_acc: 0.6000\n",
      "Epoch 1574/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5220 - val_acc: 0.6000\n",
      "Epoch 1575/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5243 - val_acc: 0.6000\n",
      "Epoch 1576/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5287 - val_acc: 0.6000\n",
      "Epoch 1577/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5308 - val_acc: 0.6000\n",
      "Epoch 1578/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5323 - val_acc: 0.6000\n",
      "Epoch 1579/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5332 - val_acc: 0.6000\n",
      "Epoch 1580/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5374 - val_acc: 0.6000\n",
      "Epoch 1581/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5376 - val_acc: 0.6000\n",
      "Epoch 1582/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5396 - val_acc: 0.6000\n",
      "Epoch 1583/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5417 - val_acc: 0.6000\n",
      "Epoch 1584/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5437 - val_acc: 0.6000\n",
      "Epoch 1585/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5470 - val_acc: 0.6000\n",
      "Epoch 1586/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5480 - val_acc: 0.6000\n",
      "Epoch 1587/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5472 - val_acc: 0.6000\n",
      "Epoch 1588/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5485 - val_acc: 0.6000\n",
      "Epoch 1589/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5502 - val_acc: 0.6000\n",
      "Epoch 1590/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4748 - val_acc: 0.6000\n",
      "Epoch 1591/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4811 - val_acc: 0.6000\n",
      "Epoch 1592/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4870 - val_acc: 0.6000\n",
      "Epoch 1593/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4941 - val_acc: 0.6000\n",
      "Epoch 1594/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4989 - val_acc: 0.6000\n",
      "Epoch 1595/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5060 - val_acc: 0.6000\n",
      "Epoch 1596/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5117 - val_acc: 0.6000\n",
      "Epoch 1597/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5170 - val_acc: 0.6000\n",
      "Epoch 1598/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5201 - val_acc: 0.6000\n",
      "Epoch 1599/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5241 - val_acc: 0.6000\n",
      "Epoch 1600/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5289 - val_acc: 0.6000\n",
      "Epoch 1601/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5319 - val_acc: 0.6000\n",
      "Epoch 1602/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5358 - val_acc: 0.6000\n",
      "Epoch 1603/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5396 - val_acc: 0.6000\n",
      "Epoch 1604/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5415 - val_acc: 0.6000\n",
      "Epoch 1605/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5432 - val_acc: 0.6000\n",
      "Epoch 1606/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5443 - val_acc: 0.6000\n",
      "Epoch 1607/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5473 - val_acc: 0.6000\n",
      "Epoch 1608/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4002 - val_acc: 0.6000\n",
      "Epoch 1609/10000\n",
      "96/96 [==============================] - 0s 190us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4193 - val_acc: 0.6000\n",
      "Epoch 1610/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4373 - val_acc: 0.6000\n",
      "Epoch 1611/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4529 - val_acc: 0.6000\n",
      "Epoch 1612/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4665 - val_acc: 0.6000\n",
      "Epoch 1613/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4786 - val_acc: 0.6000\n",
      "Epoch 1614/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4893 - val_acc: 0.6000\n",
      "Epoch 1615/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4974 - val_acc: 0.6000\n",
      "Epoch 1616/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5066 - val_acc: 0.6000\n",
      "Epoch 1617/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5129 - val_acc: 0.6000\n",
      "Epoch 1618/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5207 - val_acc: 0.6000\n",
      "Epoch 1619/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5255 - val_acc: 0.6000\n",
      "Epoch 1620/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5326 - val_acc: 0.6000\n",
      "Epoch 1621/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5359 - val_acc: 0.6000\n",
      "Epoch 1622/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5403 - val_acc: 0.6000\n",
      "Epoch 1623/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5460 - val_acc: 0.6000\n",
      "Epoch 1624/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5479 - val_acc: 0.6000\n",
      "Epoch 1625/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5504 - val_acc: 0.6000\n",
      "Epoch 1626/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5555 - val_acc: 0.6000\n",
      "Epoch 1627/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5593 - val_acc: 0.6000\n",
      "Epoch 1628/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5610 - val_acc: 0.6000\n",
      "Epoch 1629/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5633 - val_acc: 0.6000\n",
      "Epoch 1630/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5629 - val_acc: 0.6000\n",
      "Epoch 1631/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5641 - val_acc: 0.6000\n",
      "Epoch 1632/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5667 - val_acc: 0.6000\n",
      "Epoch 1633/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4900 - val_acc: 0.6000\n",
      "Epoch 1634/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4463 - val_acc: 0.6000\n",
      "Epoch 1635/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4399 - val_acc: 0.6000\n",
      "Epoch 1636/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4504 - val_acc: 0.6000\n",
      "Epoch 1637/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4593 - val_acc: 0.6000\n",
      "Epoch 1638/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4709 - val_acc: 0.6000\n",
      "Epoch 1639/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4810 - val_acc: 0.6000\n",
      "Epoch 1640/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4889 - val_acc: 0.6000\n",
      "Epoch 1641/10000\n",
      "96/96 [==============================] - 0s 310us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4941 - val_acc: 0.6000\n",
      "Epoch 1642/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5022 - val_acc: 0.6000\n",
      "Epoch 1643/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5105 - val_acc: 0.6000\n",
      "Epoch 1644/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5148 - val_acc: 0.6000\n",
      "Epoch 1645/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5210 - val_acc: 0.6000\n",
      "Epoch 1646/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5234 - val_acc: 0.6000\n",
      "Epoch 1647/10000\n",
      "96/96 [==============================] - 0s 311us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5285 - val_acc: 0.6000\n",
      "Epoch 1648/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4696 - val_acc: 0.6000\n",
      "Epoch 1649/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4804 - val_acc: 0.6000\n",
      "Epoch 1650/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4887 - val_acc: 0.6000\n",
      "Epoch 1651/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4955 - val_acc: 0.6000\n",
      "Epoch 1652/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5042 - val_acc: 0.6000\n",
      "Epoch 1653/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5131 - val_acc: 0.6000\n",
      "Epoch 1654/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5210 - val_acc: 0.6000\n",
      "Epoch 1655/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5251 - val_acc: 0.6000\n",
      "Epoch 1656/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4642 - val_acc: 0.6000\n",
      "Epoch 1657/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4728 - val_acc: 0.6000\n",
      "Epoch 1658/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4816 - val_acc: 0.6000\n",
      "Epoch 1659/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4897 - val_acc: 0.6000\n",
      "Epoch 1660/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4983 - val_acc: 0.6000\n",
      "Epoch 1661/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5066 - val_acc: 0.6000\n",
      "Epoch 1662/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5147 - val_acc: 0.6000\n",
      "Epoch 1663/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5200 - val_acc: 0.6000\n",
      "Epoch 1664/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4860 - val_acc: 0.6000\n",
      "Epoch 1665/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4903 - val_acc: 0.6000\n",
      "Epoch 1666/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4965 - val_acc: 0.6000\n",
      "Epoch 1667/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5040 - val_acc: 0.6000\n",
      "Epoch 1668/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5109 - val_acc: 0.6000\n",
      "Epoch 1669/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5158 - val_acc: 0.6000\n",
      "Epoch 1670/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5226 - val_acc: 0.6000\n",
      "Epoch 1671/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5267 - val_acc: 0.6000\n",
      "Epoch 1672/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5327 - val_acc: 0.6000\n",
      "Epoch 1673/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5371 - val_acc: 0.6000\n",
      "Epoch 1674/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5416 - val_acc: 0.6000\n",
      "Epoch 1675/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5461 - val_acc: 0.6000\n",
      "Epoch 1676/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5493 - val_acc: 0.6000\n",
      "Epoch 1677/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5528 - val_acc: 0.6000\n",
      "Epoch 1678/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5538 - val_acc: 0.6000\n",
      "Epoch 1679/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5546 - val_acc: 0.6000\n",
      "Epoch 1680/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4818 - val_acc: 0.6000\n",
      "Epoch 1681/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4891 - val_acc: 0.6000\n",
      "Epoch 1682/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4965 - val_acc: 0.6000\n",
      "Epoch 1683/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5026 - val_acc: 0.6000\n",
      "Epoch 1684/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5082 - val_acc: 0.6000\n",
      "Epoch 1685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5124 - val_acc: 0.6000\n",
      "Epoch 1686/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5187 - val_acc: 0.6000\n",
      "Epoch 1687/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5226 - val_acc: 0.6000\n",
      "Epoch 1688/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5263 - val_acc: 0.6000\n",
      "Epoch 1689/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5310 - val_acc: 0.6000\n",
      "Epoch 1690/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5347 - val_acc: 0.6000\n",
      "Epoch 1691/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5407 - val_acc: 0.6000\n",
      "Epoch 1692/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5446 - val_acc: 0.6000\n",
      "Epoch 1693/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5465 - val_acc: 0.6000\n",
      "Epoch 1694/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5484 - val_acc: 0.6000\n",
      "Epoch 1695/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5511 - val_acc: 0.6000\n",
      "Epoch 1696/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5526 - val_acc: 0.6000\n",
      "Epoch 1697/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5561 - val_acc: 0.6000\n",
      "Epoch 1698/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5570 - val_acc: 0.6000\n",
      "Epoch 1699/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5602 - val_acc: 0.6000\n",
      "Epoch 1700/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5643 - val_acc: 0.6000\n",
      "Epoch 1701/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5672 - val_acc: 0.6000\n",
      "Epoch 1702/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5679 - val_acc: 0.6000\n",
      "Epoch 1703/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5692 - val_acc: 0.6000\n",
      "Epoch 1704/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5702 - val_acc: 0.6000\n",
      "Epoch 1705/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5119 - val_acc: 0.6000\n",
      "Epoch 1706/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5187 - val_acc: 0.6000\n",
      "Epoch 1707/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5276 - val_acc: 0.6000\n",
      "Epoch 1708/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5341 - val_acc: 0.6000\n",
      "Epoch 1709/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5388 - val_acc: 0.6000\n",
      "Epoch 1710/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5430 - val_acc: 0.6000\n",
      "Epoch 1711/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5486 - val_acc: 0.6000\n",
      "Epoch 1712/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5560 - val_acc: 0.6000\n",
      "Epoch 1713/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5627 - val_acc: 0.6000\n",
      "Epoch 1714/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5673 - val_acc: 0.6000\n",
      "Epoch 1715/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5724 - val_acc: 0.6000\n",
      "Epoch 1716/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5781 - val_acc: 0.6000\n",
      "Epoch 1717/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5813 - val_acc: 0.6000\n",
      "Epoch 1718/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5862 - val_acc: 0.6000\n",
      "Epoch 1719/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5908 - val_acc: 0.6000\n",
      "Epoch 1720/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5926 - val_acc: 0.6000\n",
      "Epoch 1721/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5960 - val_acc: 0.6000\n",
      "Epoch 1722/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5985 - val_acc: 0.6000\n",
      "Epoch 1723/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6004 - val_acc: 0.6000\n",
      "Epoch 1724/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5606 - val_acc: 0.6000\n",
      "Epoch 1725/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4999 - val_acc: 0.6000\n",
      "Epoch 1726/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5070 - val_acc: 0.6000\n",
      "Epoch 1727/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5139 - val_acc: 0.6000\n",
      "Epoch 1728/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5198 - val_acc: 0.6000\n",
      "Epoch 1729/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5262 - val_acc: 0.6000\n",
      "Epoch 1730/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5315 - val_acc: 0.6000\n",
      "Epoch 1731/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5368 - val_acc: 0.6000\n",
      "Epoch 1732/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5432 - val_acc: 0.6000\n",
      "Epoch 1733/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5490 - val_acc: 0.6000\n",
      "Epoch 1734/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4581 - val_acc: 0.6000\n",
      "Epoch 1735/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4731 - val_acc: 0.6000\n",
      "Epoch 1736/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4850 - val_acc: 0.6000\n",
      "Epoch 1737/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4972 - val_acc: 0.6000\n",
      "Epoch 1738/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5073 - val_acc: 0.6000\n",
      "Epoch 1739/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5169 - val_acc: 0.6000\n",
      "Epoch 1740/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5261 - val_acc: 0.6000\n",
      "Epoch 1741/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5347 - val_acc: 0.6000\n",
      "Epoch 1742/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5421 - val_acc: 0.6000\n",
      "Epoch 1743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4722 - val_acc: 0.6000\n",
      "Epoch 1744/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4803 - val_acc: 0.6000\n",
      "Epoch 1745/10000\n",
      "96/96 [==============================] - 0s 205us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4892 - val_acc: 0.6000\n",
      "Epoch 1746/10000\n",
      "96/96 [==============================] - 0s 198us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4973 - val_acc: 0.6000\n",
      "Epoch 1747/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5063 - val_acc: 0.6000\n",
      "Epoch 1748/10000\n",
      "96/96 [==============================] - 0s 203us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5122 - val_acc: 0.6000\n",
      "Epoch 1749/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5205 - val_acc: 0.6000\n",
      "Epoch 1750/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5285 - val_acc: 0.6000\n",
      "Epoch 1751/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5335 - val_acc: 0.6000\n",
      "Epoch 1752/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5392 - val_acc: 0.6000\n",
      "Epoch 1753/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5447 - val_acc: 0.6000\n",
      "Epoch 1754/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5493 - val_acc: 0.6000\n",
      "Epoch 1755/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5515 - val_acc: 0.6000\n",
      "Epoch 1756/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5570 - val_acc: 0.6000\n",
      "Epoch 1757/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5608 - val_acc: 0.6000\n",
      "Epoch 1758/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5636 - val_acc: 0.6000\n",
      "Epoch 1759/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5678 - val_acc: 0.6000\n",
      "Epoch 1760/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5690 - val_acc: 0.6000\n",
      "Epoch 1761/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5711 - val_acc: 0.6000\n",
      "Epoch 1762/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5754 - val_acc: 0.6000\n",
      "Epoch 1763/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5745 - val_acc: 0.6000\n",
      "Epoch 1764/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5779 - val_acc: 0.6000\n",
      "Epoch 1765/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5840 - val_acc: 0.6000\n",
      "Epoch 1766/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5879 - val_acc: 0.6000\n",
      "Epoch 1767/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5918 - val_acc: 0.6000\n",
      "Epoch 1768/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5957 - val_acc: 0.6000\n",
      "Epoch 1769/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5980 - val_acc: 0.6000\n",
      "Epoch 1770/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5379 - val_acc: 0.6000\n",
      "Epoch 1771/10000\n",
      "96/96 [==============================] - 0s 198us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5452 - val_acc: 0.6000\n",
      "Epoch 1772/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5535 - val_acc: 0.6000\n",
      "Epoch 1773/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5590 - val_acc: 0.6000\n",
      "Epoch 1774/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5641 - val_acc: 0.6000\n",
      "Epoch 1775/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5696 - val_acc: 0.6000\n",
      "Epoch 1776/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5742 - val_acc: 0.6000\n",
      "Epoch 1777/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5782 - val_acc: 0.6000\n",
      "Epoch 1778/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5837 - val_acc: 0.6000\n",
      "Epoch 1779/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5884 - val_acc: 0.6000\n",
      "Epoch 1780/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5929 - val_acc: 0.6000\n",
      "Epoch 1781/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5961 - val_acc: 0.6000\n",
      "Epoch 1782/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5994 - val_acc: 0.6000\n",
      "Epoch 1783/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6017 - val_acc: 0.6000\n",
      "Epoch 1784/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5262 - val_acc: 0.6000\n",
      "Epoch 1785/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5346 - val_acc: 0.6000\n",
      "Epoch 1786/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5422 - val_acc: 0.6000\n",
      "Epoch 1787/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5486 - val_acc: 0.6000\n",
      "Epoch 1788/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5561 - val_acc: 0.6000\n",
      "Epoch 1789/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5627 - val_acc: 0.6000\n",
      "Epoch 1790/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5673 - val_acc: 0.6000\n",
      "Epoch 1791/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5713 - val_acc: 0.6000\n",
      "Epoch 1792/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5769 - val_acc: 0.6000\n",
      "Epoch 1793/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5812 - val_acc: 0.6000\n",
      "Epoch 1794/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5848 - val_acc: 0.6000\n",
      "Epoch 1795/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5871 - val_acc: 0.6000\n",
      "Epoch 1796/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5901 - val_acc: 0.6000\n",
      "Epoch 1797/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5943 - val_acc: 0.6000\n",
      "Epoch 1798/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5980 - val_acc: 0.6000\n",
      "Epoch 1799/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5985 - val_acc: 0.6000\n",
      "Epoch 1800/10000\n",
      "96/96 [==============================] - 0s 196us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5998 - val_acc: 0.6000\n",
      "Epoch 1801/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6029 - val_acc: 0.6000\n",
      "Epoch 1802/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6038 - val_acc: 0.6000\n",
      "Epoch 1803/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5389 - val_acc: 0.6000\n",
      "Epoch 1804/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5445 - val_acc: 0.6000\n",
      "Epoch 1805/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5507 - val_acc: 0.6000\n",
      "Epoch 1806/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5583 - val_acc: 0.6000\n",
      "Epoch 1807/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5648 - val_acc: 0.6000\n",
      "Epoch 1808/10000\n",
      "96/96 [==============================] - 0s 309us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5315 - val_acc: 0.6000\n",
      "Epoch 1809/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4873 - val_acc: 0.6000\n",
      "Epoch 1810/10000\n",
      "96/96 [==============================] - 0s 392us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4986 - val_acc: 0.6000\n",
      "Epoch 1811/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5067 - val_acc: 0.6000\n",
      "Epoch 1812/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5166 - val_acc: 0.6000\n",
      "Epoch 1813/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5251 - val_acc: 0.6000\n",
      "Epoch 1814/10000\n",
      "96/96 [==============================] - 0s 306us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5326 - val_acc: 0.6000\n",
      "Epoch 1815/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5395 - val_acc: 0.6000\n",
      "Epoch 1816/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5450 - val_acc: 0.6000\n",
      "Epoch 1817/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5522 - val_acc: 0.6000\n",
      "Epoch 1818/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5587 - val_acc: 0.6000\n",
      "Epoch 1819/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5640 - val_acc: 0.6000\n",
      "Epoch 1820/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4926 - val_acc: 0.6000\n",
      "Epoch 1821/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5026 - val_acc: 0.6000\n",
      "Epoch 1822/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5130 - val_acc: 0.6000\n",
      "Epoch 1823/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5218 - val_acc: 0.6000\n",
      "Epoch 1824/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5297 - val_acc: 0.6000\n",
      "Epoch 1825/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5359 - val_acc: 0.6000\n",
      "Epoch 1826/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5421 - val_acc: 0.6000\n",
      "Epoch 1827/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5476 - val_acc: 0.6000\n",
      "Epoch 1828/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5528 - val_acc: 0.6000\n",
      "Epoch 1829/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5580 - val_acc: 0.6000\n",
      "Epoch 1830/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5644 - val_acc: 0.6000\n",
      "Epoch 1831/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5704 - val_acc: 0.6000\n",
      "Epoch 1832/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5758 - val_acc: 0.6000\n",
      "Epoch 1833/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5803 - val_acc: 0.6000\n",
      "Epoch 1834/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5840 - val_acc: 0.6000\n",
      "Epoch 1835/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5879 - val_acc: 0.6000\n",
      "Epoch 1836/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5911 - val_acc: 0.6000\n",
      "Epoch 1837/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5939 - val_acc: 0.6000\n",
      "Epoch 1838/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5943 - val_acc: 0.6000\n",
      "Epoch 1839/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5963 - val_acc: 0.6000\n",
      "Epoch 1840/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5988 - val_acc: 0.6000\n",
      "Epoch 1841/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6010 - val_acc: 0.6000\n",
      "Epoch 1842/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6025 - val_acc: 0.6000\n",
      "Epoch 1843/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6051 - val_acc: 0.6000\n",
      "Epoch 1844/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6062 - val_acc: 0.6000\n",
      "Epoch 1845/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5477 - val_acc: 0.6000\n",
      "Epoch 1846/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5548 - val_acc: 0.6000\n",
      "Epoch 1847/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5616 - val_acc: 0.6000\n",
      "Epoch 1848/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5692 - val_acc: 0.6000\n",
      "Epoch 1849/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5765 - val_acc: 0.6000\n",
      "Epoch 1850/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5821 - val_acc: 0.6000\n",
      "Epoch 1851/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5875 - val_acc: 0.6000\n",
      "Epoch 1852/10000\n",
      "96/96 [==============================] - 0s 199us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5940 - val_acc: 0.6000\n",
      "Epoch 1853/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5973 - val_acc: 0.6000\n",
      "Epoch 1854/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6023 - val_acc: 0.6000\n",
      "Epoch 1855/10000\n",
      "96/96 [==============================] - 0s 196us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6058 - val_acc: 0.6000\n",
      "Epoch 1856/10000\n",
      "96/96 [==============================] - 0s 196us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6095 - val_acc: 0.6000\n",
      "Epoch 1857/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6138 - val_acc: 0.6000\n",
      "Epoch 1858/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6165 - val_acc: 0.6000\n",
      "Epoch 1859/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6173 - val_acc: 0.6000\n",
      "Epoch 1860/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6202 - val_acc: 0.6000\n",
      "Epoch 1861/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6228 - val_acc: 0.6000\n",
      "Epoch 1862/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6232 - val_acc: 0.6000\n",
      "Epoch 1863/10000\n",
      "96/96 [==============================] - 0s 347us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6254 - val_acc: 0.6000\n",
      "Epoch 1864/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6279 - val_acc: 0.6000\n",
      "Epoch 1865/10000\n",
      "96/96 [==============================] - 0s 319us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6308 - val_acc: 0.6000\n",
      "Epoch 1866/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6339 - val_acc: 0.6000\n",
      "Epoch 1867/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6347 - val_acc: 0.6000\n",
      "Epoch 1868/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6357 - val_acc: 0.6000\n",
      "Epoch 1869/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6367 - val_acc: 0.6000\n",
      "Epoch 1870/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5593 - val_acc: 0.6000\n",
      "Epoch 1871/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5659 - val_acc: 0.6000\n",
      "Epoch 1872/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5715 - val_acc: 0.6000\n",
      "Epoch 1873/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5782 - val_acc: 0.6000\n",
      "Epoch 1874/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5838 - val_acc: 0.6000\n",
      "Epoch 1875/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5904 - val_acc: 0.6000\n",
      "Epoch 1876/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5964 - val_acc: 0.6000\n",
      "Epoch 1877/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6003 - val_acc: 0.6000\n",
      "Epoch 1878/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6052 - val_acc: 0.6000\n",
      "Epoch 1879/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6083 - val_acc: 0.6000\n",
      "Epoch 1880/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6139 - val_acc: 0.6000\n",
      "Epoch 1881/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6181 - val_acc: 0.6000\n",
      "Epoch 1882/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6193 - val_acc: 0.6000\n",
      "Epoch 1883/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6213 - val_acc: 0.6000\n",
      "Epoch 1884/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6252 - val_acc: 0.6000\n",
      "Epoch 1885/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5884 - val_acc: 0.6000\n",
      "Epoch 1886/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5933 - val_acc: 0.6000\n",
      "Epoch 1887/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5970 - val_acc: 0.6000\n",
      "Epoch 1888/10000\n",
      "96/96 [==============================] - 0s 324us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6017 - val_acc: 0.6000\n",
      "Epoch 1889/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6068 - val_acc: 0.6000\n",
      "Epoch 1890/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6112 - val_acc: 0.6000\n",
      "Epoch 1891/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6147 - val_acc: 0.6000\n",
      "Epoch 1892/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6155 - val_acc: 0.6000\n",
      "Epoch 1893/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6167 - val_acc: 0.6000\n",
      "Epoch 1894/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6201 - val_acc: 0.6000\n",
      "Epoch 1895/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6214 - val_acc: 0.6000\n",
      "Epoch 1896/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6253 - val_acc: 0.6000\n",
      "Epoch 1897/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6269 - val_acc: 0.6000\n",
      "Epoch 1898/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6295 - val_acc: 0.6000\n",
      "Epoch 1899/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6310 - val_acc: 0.6000\n",
      "Epoch 1900/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6323 - val_acc: 0.6000\n",
      "Epoch 1901/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6338 - val_acc: 0.6000\n",
      "Epoch 1902/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6338 - val_acc: 0.6000\n",
      "Epoch 1903/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6357 - val_acc: 0.6000\n",
      "Epoch 1904/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6368 - val_acc: 0.6000\n",
      "Epoch 1905/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6373 - val_acc: 0.6000\n",
      "Epoch 1906/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6396 - val_acc: 0.6000\n",
      "Epoch 1907/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6422 - val_acc: 0.6000\n",
      "Epoch 1908/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6417 - val_acc: 0.6000\n",
      "Epoch 1909/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6439 - val_acc: 0.6000\n",
      "Epoch 1910/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6444 - val_acc: 0.6000\n",
      "Epoch 1911/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6449 - val_acc: 0.6000\n",
      "Epoch 1912/10000\n",
      "96/96 [==============================] - 0s 194us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5857 - val_acc: 0.6000\n",
      "Epoch 1913/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5910 - val_acc: 0.6000\n",
      "Epoch 1914/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5959 - val_acc: 0.6000\n",
      "Epoch 1915/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6013 - val_acc: 0.6000\n",
      "Epoch 1916/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6089 - val_acc: 0.6000\n",
      "Epoch 1917/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6136 - val_acc: 0.6000\n",
      "Epoch 1918/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6202 - val_acc: 0.6000\n",
      "Epoch 1919/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6230 - val_acc: 0.6000\n",
      "Epoch 1920/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6251 - val_acc: 0.6000\n",
      "Epoch 1921/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6295 - val_acc: 0.6000\n",
      "Epoch 1922/10000\n",
      "96/96 [==============================] - 0s 296us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6331 - val_acc: 0.6000\n",
      "Epoch 1923/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6359 - val_acc: 0.6000\n",
      "Epoch 1924/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5427 - val_acc: 0.6000\n",
      "Epoch 1925/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5549 - val_acc: 0.6000\n",
      "Epoch 1926/10000\n",
      "96/96 [==============================] - 0s 302us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5658 - val_acc: 0.6000\n",
      "Epoch 1927/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5767 - val_acc: 0.6000\n",
      "Epoch 1928/10000\n",
      "96/96 [==============================] - 0s 304us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5864 - val_acc: 0.6000\n",
      "Epoch 1929/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5952 - val_acc: 0.6000\n",
      "Epoch 1930/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6029 - val_acc: 0.6000\n",
      "Epoch 1931/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6106 - val_acc: 0.6000\n",
      "Epoch 1932/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6169 - val_acc: 0.6000\n",
      "Epoch 1933/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6206 - val_acc: 0.6000\n",
      "Epoch 1934/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6258 - val_acc: 0.6000\n",
      "Epoch 1935/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6292 - val_acc: 0.6000\n",
      "Epoch 1936/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5538 - val_acc: 0.6000\n",
      "Epoch 1937/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5639 - val_acc: 0.6000\n",
      "Epoch 1938/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5728 - val_acc: 0.6000\n",
      "Epoch 1939/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5815 - val_acc: 0.6000\n",
      "Epoch 1940/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5888 - val_acc: 0.6000\n",
      "Epoch 1941/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5968 - val_acc: 0.6000\n",
      "Epoch 1942/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6037 - val_acc: 0.6000\n",
      "Epoch 1943/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6086 - val_acc: 0.6000\n",
      "Epoch 1944/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6144 - val_acc: 0.6000\n",
      "Epoch 1945/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6199 - val_acc: 0.6000\n",
      "Epoch 1946/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6243 - val_acc: 0.6000\n",
      "Epoch 1947/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6297 - val_acc: 0.6000\n",
      "Epoch 1948/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6345 - val_acc: 0.6000\n",
      "Epoch 1949/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6356 - val_acc: 0.6000\n",
      "Epoch 1950/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6387 - val_acc: 0.6000\n",
      "Epoch 1951/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6407 - val_acc: 0.6000\n",
      "Epoch 1952/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6428 - val_acc: 0.6000\n",
      "Epoch 1953/10000\n",
      "96/96 [==============================] - 0s 295us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6442 - val_acc: 0.6000\n",
      "Epoch 1954/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6480 - val_acc: 0.6000\n",
      "Epoch 1955/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6107 - val_acc: 0.6000\n",
      "Epoch 1956/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6154 - val_acc: 0.6000\n",
      "Epoch 1957/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6179 - val_acc: 0.6000\n",
      "Epoch 1958/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6213 - val_acc: 0.6000\n",
      "Epoch 1959/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6266 - val_acc: 0.6000\n",
      "Epoch 1960/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6310 - val_acc: 0.6000\n",
      "Epoch 1961/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6356 - val_acc: 0.6000\n",
      "Epoch 1962/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6376 - val_acc: 0.6000\n",
      "Epoch 1963/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5725 - val_acc: 0.6000\n",
      "Epoch 1964/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5799 - val_acc: 0.6000\n",
      "Epoch 1965/10000\n",
      "96/96 [==============================] - 0s 294us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5852 - val_acc: 0.6000\n",
      "Epoch 1966/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5913 - val_acc: 0.6000\n",
      "Epoch 1967/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5967 - val_acc: 0.6000\n",
      "Epoch 1968/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6013 - val_acc: 0.6000\n",
      "Epoch 1969/10000\n",
      "96/96 [==============================] - 0s 194us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6075 - val_acc: 0.6000\n",
      "Epoch 1970/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6126 - val_acc: 0.6000\n",
      "Epoch 1971/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6170 - val_acc: 0.6000\n",
      "Epoch 1972/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6201 - val_acc: 0.6000\n",
      "Epoch 1973/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6220 - val_acc: 0.6000\n",
      "Epoch 1974/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6257 - val_acc: 0.6000\n",
      "Epoch 1975/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6281 - val_acc: 0.6000\n",
      "Epoch 1976/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6320 - val_acc: 0.6000\n",
      "Epoch 1977/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6359 - val_acc: 0.6000\n",
      "Epoch 1978/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6401 - val_acc: 0.6000\n",
      "Epoch 1979/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6423 - val_acc: 0.6000\n",
      "Epoch 1980/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6449 - val_acc: 0.6000\n",
      "Epoch 1981/10000\n",
      "96/96 [==============================] - 0s 317us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6467 - val_acc: 0.6000\n",
      "Epoch 1982/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6475 - val_acc: 0.6000\n",
      "Epoch 1983/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6497 - val_acc: 0.6000\n",
      "Epoch 1984/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4641 - val_acc: 0.6000\n",
      "Epoch 1985/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4781 - val_acc: 0.6000\n",
      "Epoch 1986/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8333 - val_loss: 118.4887 - val_acc: 0.6000\n",
      "Epoch 1987/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.4903 - val_acc: 0.6000\n",
      "Epoch 1988/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5050 - val_acc: 0.6000\n",
      "Epoch 1989/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5199 - val_acc: 0.6000\n",
      "Epoch 1990/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5336 - val_acc: 0.6000\n",
      "Epoch 1991/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5466 - val_acc: 0.6000\n",
      "Epoch 1992/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5580 - val_acc: 0.6000\n",
      "Epoch 1993/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5686 - val_acc: 0.6000\n",
      "Epoch 1994/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5790 - val_acc: 0.6000\n",
      "Epoch 1995/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5885 - val_acc: 0.6000\n",
      "Epoch 1996/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5969 - val_acc: 0.6000\n",
      "Epoch 1997/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6053 - val_acc: 0.6000\n",
      "Epoch 1998/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6130 - val_acc: 0.6000\n",
      "Epoch 1999/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6194 - val_acc: 0.6000\n",
      "Epoch 2000/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6254 - val_acc: 0.6000\n",
      "Epoch 2001/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6310 - val_acc: 0.6000\n",
      "Epoch 2002/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6357 - val_acc: 0.6000\n",
      "Epoch 2003/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6388 - val_acc: 0.6000\n",
      "Epoch 2004/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6429 - val_acc: 0.6000\n",
      "Epoch 2005/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6461 - val_acc: 0.6000\n",
      "Epoch 2006/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6483 - val_acc: 0.6000\n",
      "Epoch 2007/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6518 - val_acc: 0.6000\n",
      "Epoch 2008/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6548 - val_acc: 0.6000\n",
      "Epoch 2009/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6592 - val_acc: 0.6000\n",
      "Epoch 2010/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6619 - val_acc: 0.6000\n",
      "Epoch 2011/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6652 - val_acc: 0.6000\n",
      "Epoch 2012/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6675 - val_acc: 0.6000\n",
      "Epoch 2013/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6696 - val_acc: 0.6000\n",
      "Epoch 2014/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6730 - val_acc: 0.6000\n",
      "Epoch 2015/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5797 - val_acc: 0.6000\n",
      "Epoch 2016/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5915 - val_acc: 0.6000\n",
      "Epoch 2017/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6017 - val_acc: 0.6000\n",
      "Epoch 2018/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6095 - val_acc: 0.6000\n",
      "Epoch 2019/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6176 - val_acc: 0.6000\n",
      "Epoch 2020/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6254 - val_acc: 0.6000\n",
      "Epoch 2021/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6323 - val_acc: 0.6000\n",
      "Epoch 2022/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6383 - val_acc: 0.6000\n",
      "Epoch 2023/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6446 - val_acc: 0.6000\n",
      "Epoch 2024/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6503 - val_acc: 0.6000\n",
      "Epoch 2025/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6554 - val_acc: 0.6000\n",
      "Epoch 2026/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6587 - val_acc: 0.6000\n",
      "Epoch 2027/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5834 - val_acc: 0.6000\n",
      "Epoch 2028/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5872 - val_acc: 0.6000\n",
      "Epoch 2029/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5945 - val_acc: 0.6000\n",
      "Epoch 2030/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6017 - val_acc: 0.6000\n",
      "Epoch 2031/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6102 - val_acc: 0.6000\n",
      "Epoch 2032/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6187 - val_acc: 0.6000\n",
      "Epoch 2033/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6240 - val_acc: 0.6000\n",
      "Epoch 2034/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6299 - val_acc: 0.6000\n",
      "Epoch 2035/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6362 - val_acc: 0.6000\n",
      "Epoch 2036/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6411 - val_acc: 0.6000\n",
      "Epoch 2037/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6457 - val_acc: 0.6000\n",
      "Epoch 2038/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6516 - val_acc: 0.6000\n",
      "Epoch 2039/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6557 - val_acc: 0.6000\n",
      "Epoch 2040/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6596 - val_acc: 0.6000\n",
      "Epoch 2041/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6614 - val_acc: 0.6000\n",
      "Epoch 2042/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6649 - val_acc: 0.6000\n",
      "Epoch 2043/10000\n",
      "96/96 [==============================] - 0s 295us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6674 - val_acc: 0.6000\n",
      "Epoch 2044/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6696 - val_acc: 0.6000\n",
      "Epoch 2045/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6717 - val_acc: 0.6000\n",
      "Epoch 2046/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5824 - val_acc: 0.6000\n",
      "Epoch 2047/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5911 - val_acc: 0.6000\n",
      "Epoch 2048/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5977 - val_acc: 0.6000\n",
      "Epoch 2049/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6054 - val_acc: 0.6000\n",
      "Epoch 2050/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6108 - val_acc: 0.6000\n",
      "Epoch 2051/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6179 - val_acc: 0.6000\n",
      "Epoch 2052/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6242 - val_acc: 0.6000\n",
      "Epoch 2053/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6285 - val_acc: 0.6000\n",
      "Epoch 2054/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6330 - val_acc: 0.6000\n",
      "Epoch 2055/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6381 - val_acc: 0.6000\n",
      "Epoch 2056/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6420 - val_acc: 0.6000\n",
      "Epoch 2057/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6473 - val_acc: 0.6000\n",
      "Epoch 2058/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6519 - val_acc: 0.6000\n",
      "Epoch 2059/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6548 - val_acc: 0.6000\n",
      "Epoch 2060/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6587 - val_acc: 0.6000\n",
      "Epoch 2061/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6622 - val_acc: 0.6000\n",
      "Epoch 2062/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6658 - val_acc: 0.6000\n",
      "Epoch 2063/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6686 - val_acc: 0.6000\n",
      "Epoch 2064/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6704 - val_acc: 0.6000\n",
      "Epoch 2065/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6704 - val_acc: 0.6000\n",
      "Epoch 2066/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6718 - val_acc: 0.6000\n",
      "Epoch 2067/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6725 - val_acc: 0.6000\n",
      "Epoch 2068/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6748 - val_acc: 0.6000\n",
      "Epoch 2069/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6754 - val_acc: 0.6000\n",
      "Epoch 2070/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6773 - val_acc: 0.6000\n",
      "Epoch 2071/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6781 - val_acc: 0.6000\n",
      "Epoch 2072/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6783 - val_acc: 0.6000\n",
      "Epoch 2073/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6805 - val_acc: 0.6000\n",
      "Epoch 2074/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6818 - val_acc: 0.6000\n",
      "Epoch 2075/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6836 - val_acc: 0.6000\n",
      "Epoch 2076/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6860 - val_acc: 0.6000\n",
      "Epoch 2077/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6881 - val_acc: 0.6000\n",
      "Epoch 2078/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6876 - val_acc: 0.6000\n",
      "Epoch 2079/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6871 - val_acc: 0.6000\n",
      "Epoch 2080/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6886 - val_acc: 0.6000\n",
      "Epoch 2081/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6894 - val_acc: 0.6000\n",
      "Epoch 2082/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6121 - val_acc: 0.6000\n",
      "Epoch 2083/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6202 - val_acc: 0.6000\n",
      "Epoch 2084/10000\n",
      "96/96 [==============================] - 0s 197us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6262 - val_acc: 0.6000\n",
      "Epoch 2085/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6332 - val_acc: 0.6000\n",
      "Epoch 2086/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6393 - val_acc: 0.6000\n",
      "Epoch 2087/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6446 - val_acc: 0.6000\n",
      "Epoch 2088/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6501 - val_acc: 0.6000\n",
      "Epoch 2089/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6542 - val_acc: 0.6000\n",
      "Epoch 2090/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6592 - val_acc: 0.6000\n",
      "Epoch 2091/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6617 - val_acc: 0.6000\n",
      "Epoch 2092/10000\n",
      "96/96 [==============================] - 0s 195us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6654 - val_acc: 0.6000\n",
      "Epoch 2093/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6699 - val_acc: 0.6000\n",
      "Epoch 2094/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6735 - val_acc: 0.6000\n",
      "Epoch 2095/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6763 - val_acc: 0.6000\n",
      "Epoch 2096/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6768 - val_acc: 0.6000\n",
      "Epoch 2097/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6217 - val_acc: 0.6000\n",
      "Epoch 2098/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6283 - val_acc: 0.6000\n",
      "Epoch 2099/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6339 - val_acc: 0.6000\n",
      "Epoch 2100/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6398 - val_acc: 0.6000\n",
      "Epoch 2101/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6459 - val_acc: 0.6000\n",
      "Epoch 2102/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6517 - val_acc: 0.6000\n",
      "Epoch 2103/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6585 - val_acc: 0.6000\n",
      "Epoch 2104/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6632 - val_acc: 0.6000\n",
      "Epoch 2105/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6658 - val_acc: 0.6000\n",
      "Epoch 2106/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6714 - val_acc: 0.6000\n",
      "Epoch 2107/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6753 - val_acc: 0.6000\n",
      "Epoch 2108/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6798 - val_acc: 0.6000\n",
      "Epoch 2109/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6823 - val_acc: 0.6000\n",
      "Epoch 2110/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6853 - val_acc: 0.6000\n",
      "Epoch 2111/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6893 - val_acc: 0.6000\n",
      "Epoch 2112/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6912 - val_acc: 0.6000\n",
      "Epoch 2113/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6947 - val_acc: 0.6000\n",
      "Epoch 2114/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6961 - val_acc: 0.6000\n",
      "Epoch 2115/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6993 - val_acc: 0.6000\n",
      "Epoch 2116/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7006 - val_acc: 0.6000\n",
      "Epoch 2117/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7010 - val_acc: 0.6000\n",
      "Epoch 2118/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7010 - val_acc: 0.6000\n",
      "Epoch 2119/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7010 - val_acc: 0.6000\n",
      "Epoch 2120/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7024 - val_acc: 0.6000\n",
      "Epoch 2121/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7026 - val_acc: 0.6000\n",
      "Epoch 2122/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6656 - val_acc: 0.6000\n",
      "Epoch 2123/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6034 - val_acc: 0.6000\n",
      "Epoch 2124/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6110 - val_acc: 0.6000\n",
      "Epoch 2125/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6175 - val_acc: 0.6000\n",
      "Epoch 2126/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6223 - val_acc: 0.6000\n",
      "Epoch 2127/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6272 - val_acc: 0.6000\n",
      "Epoch 2128/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6342 - val_acc: 0.6000\n",
      "Epoch 2129/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6393 - val_acc: 0.6000\n",
      "Epoch 2130/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6428 - val_acc: 0.6000\n",
      "Epoch 2131/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6473 - val_acc: 0.6000\n",
      "Epoch 2132/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6517 - val_acc: 0.6000\n",
      "Epoch 2133/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6564 - val_acc: 0.6000\n",
      "Epoch 2134/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6593 - val_acc: 0.6000\n",
      "Epoch 2135/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6636 - val_acc: 0.6000\n",
      "Epoch 2136/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6665 - val_acc: 0.6000\n",
      "Epoch 2137/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6694 - val_acc: 0.6000\n",
      "Epoch 2138/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6742 - val_acc: 0.6000\n",
      "Epoch 2139/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6767 - val_acc: 0.6000\n",
      "Epoch 2140/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6797 - val_acc: 0.6000\n",
      "Epoch 2141/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6821 - val_acc: 0.6000\n",
      "Epoch 2142/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6845 - val_acc: 0.6000\n",
      "Epoch 2143/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6870 - val_acc: 0.6000\n",
      "Epoch 2144/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6905 - val_acc: 0.6000\n",
      "Epoch 2145/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6909 - val_acc: 0.6000\n",
      "Epoch 2146/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6933 - val_acc: 0.6000\n",
      "Epoch 2147/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6959 - val_acc: 0.6000\n",
      "Epoch 2148/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6966 - val_acc: 0.6000\n",
      "Epoch 2149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 190us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6248 - val_acc: 0.6000\n",
      "Epoch 2150/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6266 - val_acc: 0.6000\n",
      "Epoch 2151/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6338 - val_acc: 0.6000\n",
      "Epoch 2152/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6412 - val_acc: 0.6000\n",
      "Epoch 2153/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6488 - val_acc: 0.6000\n",
      "Epoch 2154/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6552 - val_acc: 0.6000\n",
      "Epoch 2155/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6599 - val_acc: 0.6000\n",
      "Epoch 2156/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6645 - val_acc: 0.6000\n",
      "Epoch 2157/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6704 - val_acc: 0.6000\n",
      "Epoch 2158/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6744 - val_acc: 0.6000\n",
      "Epoch 2159/10000\n",
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6782 - val_acc: 0.6000\n",
      "Epoch 2160/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6824 - val_acc: 0.6000\n",
      "Epoch 2161/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6864 - val_acc: 0.6000\n",
      "Epoch 2162/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6902 - val_acc: 0.6000\n",
      "Epoch 2163/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6930 - val_acc: 0.6000\n",
      "Epoch 2164/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6944 - val_acc: 0.6000\n",
      "Epoch 2165/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6956 - val_acc: 0.6000\n",
      "Epoch 2166/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6986 - val_acc: 0.6000\n",
      "Epoch 2167/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6996 - val_acc: 0.6000\n",
      "Epoch 2168/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7024 - val_acc: 0.6000\n",
      "Epoch 2169/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7047 - val_acc: 0.6000\n",
      "Epoch 2170/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7052 - val_acc: 0.6000\n",
      "Epoch 2171/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7071 - val_acc: 0.6000\n",
      "Epoch 2172/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7072 - val_acc: 0.6000\n",
      "Epoch 2173/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6423 - val_acc: 0.6000\n",
      "Epoch 2174/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6494 - val_acc: 0.6000\n",
      "Epoch 2175/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6542 - val_acc: 0.6000\n",
      "Epoch 2176/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6602 - val_acc: 0.6000\n",
      "Epoch 2177/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6643 - val_acc: 0.6000\n",
      "Epoch 2178/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6691 - val_acc: 0.6000\n",
      "Epoch 2179/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6098 - val_acc: 0.6000\n",
      "Epoch 2180/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6174 - val_acc: 0.6000\n",
      "Epoch 2181/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6255 - val_acc: 0.6000\n",
      "Epoch 2182/10000\n",
      "96/96 [==============================] - 0s 182us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6343 - val_acc: 0.6000\n",
      "Epoch 2183/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6417 - val_acc: 0.6000\n",
      "Epoch 2184/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6476 - val_acc: 0.6000\n",
      "Epoch 2185/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6540 - val_acc: 0.6000\n",
      "Epoch 2186/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6606 - val_acc: 0.6000\n",
      "Epoch 2187/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6660 - val_acc: 0.6000\n",
      "Epoch 2188/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6716 - val_acc: 0.6000\n",
      "Epoch 2189/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6762 - val_acc: 0.6000\n",
      "Epoch 2190/10000\n",
      "96/96 [==============================] - 0s 187us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6799 - val_acc: 0.6000\n",
      "Epoch 2191/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6824 - val_acc: 0.6000\n",
      "Epoch 2192/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6861 - val_acc: 0.6000\n",
      "Epoch 2193/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6904 - val_acc: 0.6000\n",
      "Epoch 2194/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6937 - val_acc: 0.6000\n",
      "Epoch 2195/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6974 - val_acc: 0.6000\n",
      "Epoch 2196/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6597 - val_acc: 0.6000\n",
      "Epoch 2197/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6648 - val_acc: 0.6000\n",
      "Epoch 2198/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6690 - val_acc: 0.6000\n",
      "Epoch 2199/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6712 - val_acc: 0.6000\n",
      "Epoch 2200/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6760 - val_acc: 0.6000\n",
      "Epoch 2201/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6796 - val_acc: 0.6000\n",
      "Epoch 2202/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6842 - val_acc: 0.6000\n",
      "Epoch 2203/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6887 - val_acc: 0.6000\n",
      "Epoch 2204/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6916 - val_acc: 0.6000\n",
      "Epoch 2205/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6956 - val_acc: 0.6000\n",
      "Epoch 2206/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6974 - val_acc: 0.6000\n",
      "Epoch 2207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7013 - val_acc: 0.6000\n",
      "Epoch 2208/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7054 - val_acc: 0.6000\n",
      "Epoch 2209/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7085 - val_acc: 0.6000\n",
      "Epoch 2210/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7107 - val_acc: 0.6000\n",
      "Epoch 2211/10000\n",
      "96/96 [==============================] - 0s 297us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7105 - val_acc: 0.6000\n",
      "Epoch 2212/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7130 - val_acc: 0.6000\n",
      "Epoch 2213/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5674 - val_acc: 0.6000\n",
      "Epoch 2214/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5770 - val_acc: 0.6000\n",
      "Epoch 2215/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5867 - val_acc: 0.6000\n",
      "Epoch 2216/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.5954 - val_acc: 0.6000\n",
      "Epoch 2217/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6034 - val_acc: 0.6000\n",
      "Epoch 2218/10000\n",
      "96/96 [==============================] - 0s 289us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6100 - val_acc: 0.6000\n",
      "Epoch 2219/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6133 - val_acc: 0.6000\n",
      "Epoch 2220/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6223 - val_acc: 0.6000\n",
      "Epoch 2221/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6306 - val_acc: 0.6000\n",
      "Epoch 2222/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6394 - val_acc: 0.6000\n",
      "Epoch 2223/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6471 - val_acc: 0.6000\n",
      "Epoch 2224/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6548 - val_acc: 0.6000\n",
      "Epoch 2225/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6629 - val_acc: 0.6000\n",
      "Epoch 2226/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6694 - val_acc: 0.6000\n",
      "Epoch 2227/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6758 - val_acc: 0.6000\n",
      "Epoch 2228/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6805 - val_acc: 0.6000\n",
      "Epoch 2229/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6850 - val_acc: 0.6000\n",
      "Epoch 2230/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6894 - val_acc: 0.6000\n",
      "Epoch 2231/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6932 - val_acc: 0.6000\n",
      "Epoch 2232/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6975 - val_acc: 0.6000\n",
      "Epoch 2233/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7018 - val_acc: 0.6000\n",
      "Epoch 2234/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7041 - val_acc: 0.6000\n",
      "Epoch 2235/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7081 - val_acc: 0.6000\n",
      "Epoch 2236/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7102 - val_acc: 0.6000\n",
      "Epoch 2237/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7135 - val_acc: 0.6000\n",
      "Epoch 2238/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7152 - val_acc: 0.6000\n",
      "Epoch 2239/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7174 - val_acc: 0.6000\n",
      "Epoch 2240/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7194 - val_acc: 0.6000\n",
      "Epoch 2241/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7209 - val_acc: 0.6000\n",
      "Epoch 2242/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6238 - val_acc: 0.6000\n",
      "Epoch 2243/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6362 - val_acc: 0.6000\n",
      "Epoch 2244/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6461 - val_acc: 0.6000\n",
      "Epoch 2245/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6566 - val_acc: 0.6000\n",
      "Epoch 2246/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6645 - val_acc: 0.6000\n",
      "Epoch 2247/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6720 - val_acc: 0.6000\n",
      "Epoch 2248/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6794 - val_acc: 0.6000\n",
      "Epoch 2249/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6857 - val_acc: 0.6000\n",
      "Epoch 2250/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6915 - val_acc: 0.6000\n",
      "Epoch 2251/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6966 - val_acc: 0.6000\n",
      "Epoch 2252/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7018 - val_acc: 0.6000\n",
      "Epoch 2253/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7062 - val_acc: 0.6000\n",
      "Epoch 2254/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7102 - val_acc: 0.6000\n",
      "Epoch 2255/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7138 - val_acc: 0.6000\n",
      "Epoch 2256/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7170 - val_acc: 0.6000\n",
      "Epoch 2257/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7189 - val_acc: 0.6000\n",
      "Epoch 2258/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7226 - val_acc: 0.6000\n",
      "Epoch 2259/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7240 - val_acc: 0.6000\n",
      "Epoch 2260/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6649 - val_acc: 0.6000\n",
      "Epoch 2261/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6725 - val_acc: 0.6000\n",
      "Epoch 2262/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6792 - val_acc: 0.6000\n",
      "Epoch 2263/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6846 - val_acc: 0.6000\n",
      "Epoch 2264/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6884 - val_acc: 0.6000\n",
      "Epoch 2265/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6935 - val_acc: 0.6000\n",
      "Epoch 2266/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6978 - val_acc: 0.6000\n",
      "Epoch 2267/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7016 - val_acc: 0.6000\n",
      "Epoch 2268/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7063 - val_acc: 0.6000\n",
      "Epoch 2269/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7114 - val_acc: 0.6000\n",
      "Epoch 2270/10000\n",
      "96/96 [==============================] - 0s 318us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7155 - val_acc: 0.6000\n",
      "Epoch 2271/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7193 - val_acc: 0.6000\n",
      "Epoch 2272/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7227 - val_acc: 0.6000\n",
      "Epoch 2273/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7270 - val_acc: 0.6000\n",
      "Epoch 2274/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7310 - val_acc: 0.6000\n",
      "Epoch 2275/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7341 - val_acc: 0.6000\n",
      "Epoch 2276/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7347 - val_acc: 0.6000\n",
      "Epoch 2277/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7366 - val_acc: 0.6000\n",
      "Epoch 2278/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7376 - val_acc: 0.6000\n",
      "Epoch 2279/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7403 - val_acc: 0.6000\n",
      "Epoch 2280/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7427 - val_acc: 0.6000\n",
      "Epoch 2281/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7456 - val_acc: 0.6000\n",
      "Epoch 2282/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7466 - val_acc: 0.6000\n",
      "Epoch 2283/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7479 - val_acc: 0.6000\n",
      "Epoch 2284/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7475 - val_acc: 0.6000\n",
      "Epoch 2285/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7480 - val_acc: 0.6000\n",
      "Epoch 2286/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7492 - val_acc: 0.6000\n",
      "Epoch 2287/10000\n",
      "96/96 [==============================] - 0s 315us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7511 - val_acc: 0.6000\n",
      "Epoch 2288/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7519 - val_acc: 0.6000\n",
      "Epoch 2289/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7126 - val_acc: 0.6000\n",
      "Epoch 2290/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7165 - val_acc: 0.6000\n",
      "Epoch 2291/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7198 - val_acc: 0.6000\n",
      "Epoch 2292/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7220 - val_acc: 0.6000\n",
      "Epoch 2293/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7257 - val_acc: 0.6000\n",
      "Epoch 2294/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7288 - val_acc: 0.6000\n",
      "Epoch 2295/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7306 - val_acc: 0.6000\n",
      "Epoch 2296/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7333 - val_acc: 0.6000\n",
      "Epoch 2297/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7340 - val_acc: 0.6000\n",
      "Epoch 2298/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7364 - val_acc: 0.6000\n",
      "Epoch 2299/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7389 - val_acc: 0.6000\n",
      "Epoch 2300/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7405 - val_acc: 0.6000\n",
      "Epoch 2301/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6671 - val_acc: 0.6000\n",
      "Epoch 2302/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6728 - val_acc: 0.6000\n",
      "Epoch 2303/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6792 - val_acc: 0.6000\n",
      "Epoch 2304/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6867 - val_acc: 0.6000\n",
      "Epoch 2305/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6931 - val_acc: 0.6000\n",
      "Epoch 2306/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6989 - val_acc: 0.6000\n",
      "Epoch 2307/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7043 - val_acc: 0.6000\n",
      "Epoch 2308/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7107 - val_acc: 0.6000\n",
      "Epoch 2309/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7135 - val_acc: 0.6000\n",
      "Epoch 2310/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7189 - val_acc: 0.6000\n",
      "Epoch 2311/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7236 - val_acc: 0.6000\n",
      "Epoch 2312/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7279 - val_acc: 0.6000\n",
      "Epoch 2313/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7317 - val_acc: 0.6000\n",
      "Epoch 2314/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7331 - val_acc: 0.6000\n",
      "Epoch 2315/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7364 - val_acc: 0.6000\n",
      "Epoch 2316/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7380 - val_acc: 0.6000\n",
      "Epoch 2317/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7402 - val_acc: 0.6000\n",
      "Epoch 2318/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7422 - val_acc: 0.6000\n",
      "Epoch 2319/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7441 - val_acc: 0.6000\n",
      "Epoch 2320/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7455 - val_acc: 0.6000\n",
      "Epoch 2321/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7470 - val_acc: 0.6000\n",
      "Epoch 2322/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7470 - val_acc: 0.6000\n",
      "Epoch 2323/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7483 - val_acc: 0.6000\n",
      "Epoch 2324/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7501 - val_acc: 0.6000\n",
      "Epoch 2325/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7523 - val_acc: 0.6000\n",
      "Epoch 2326/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7543 - val_acc: 0.6000\n",
      "Epoch 2327/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7555 - val_acc: 0.6000\n",
      "Epoch 2328/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7562 - val_acc: 0.6000\n",
      "Epoch 2329/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7587 - val_acc: 0.6000\n",
      "Epoch 2330/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7597 - val_acc: 0.6000\n",
      "Epoch 2331/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7606 - val_acc: 0.6000\n",
      "Epoch 2332/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7624 - val_acc: 0.6000\n",
      "Epoch 2333/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7639 - val_acc: 0.6000\n",
      "Epoch 2334/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7641 - val_acc: 0.6000\n",
      "Epoch 2335/10000\n",
      "96/96 [==============================] - 0s 285us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7650 - val_acc: 0.6000\n",
      "Epoch 2336/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7656 - val_acc: 0.6000\n",
      "Epoch 2337/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7677 - val_acc: 0.6000\n",
      "Epoch 2338/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7678 - val_acc: 0.6000\n",
      "Epoch 2339/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7070 - val_acc: 0.6000\n",
      "Epoch 2340/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7117 - val_acc: 0.6000\n",
      "Epoch 2341/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7158 - val_acc: 0.6000\n",
      "Epoch 2342/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7221 - val_acc: 0.6000\n",
      "Epoch 2343/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7276 - val_acc: 0.6000\n",
      "Epoch 2344/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7332 - val_acc: 0.6000\n",
      "Epoch 2345/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7375 - val_acc: 0.6000\n",
      "Epoch 2346/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7412 - val_acc: 0.6000\n",
      "Epoch 2347/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7443 - val_acc: 0.6000\n",
      "Epoch 2348/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7469 - val_acc: 0.6000\n",
      "Epoch 2349/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7508 - val_acc: 0.6000\n",
      "Epoch 2350/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7551 - val_acc: 0.6000\n",
      "Epoch 2351/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7582 - val_acc: 0.6000\n",
      "Epoch 2352/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7612 - val_acc: 0.6000\n",
      "Epoch 2353/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7622 - val_acc: 0.6000\n",
      "Epoch 2354/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7652 - val_acc: 0.6000\n",
      "Epoch 2355/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7669 - val_acc: 0.6000\n",
      "Epoch 2356/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7683 - val_acc: 0.6000\n",
      "Epoch 2357/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7699 - val_acc: 0.6000\n",
      "Epoch 2358/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7711 - val_acc: 0.6000\n",
      "Epoch 2359/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7719 - val_acc: 0.6000\n",
      "Epoch 2360/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7741 - val_acc: 0.6000\n",
      "Epoch 2361/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7763 - val_acc: 0.6000\n",
      "Epoch 2362/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7770 - val_acc: 0.6000\n",
      "Epoch 2363/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7774 - val_acc: 0.6000\n",
      "Epoch 2364/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7785 - val_acc: 0.6000\n",
      "Epoch 2365/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7033 - val_acc: 0.6000\n",
      "Epoch 2366/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7066 - val_acc: 0.6000\n",
      "Epoch 2367/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7119 - val_acc: 0.6000\n",
      "Epoch 2368/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7180 - val_acc: 0.6000\n",
      "Epoch 2369/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7245 - val_acc: 0.6000\n",
      "Epoch 2370/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7303 - val_acc: 0.6000\n",
      "Epoch 2371/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7356 - val_acc: 0.6000\n",
      "Epoch 2372/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7392 - val_acc: 0.6000\n",
      "Epoch 2373/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7436 - val_acc: 0.6000\n",
      "Epoch 2374/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7469 - val_acc: 0.6000\n",
      "Epoch 2375/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7500 - val_acc: 0.6000\n",
      "Epoch 2376/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7536 - val_acc: 0.6000\n",
      "Epoch 2377/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7556 - val_acc: 0.6000\n",
      "Epoch 2378/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7097 - val_acc: 0.6000\n",
      "Epoch 2379/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6978 - val_acc: 0.6000\n",
      "Epoch 2380/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7045 - val_acc: 0.6000\n",
      "Epoch 2381/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7117 - val_acc: 0.6000\n",
      "Epoch 2382/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7187 - val_acc: 0.6000\n",
      "Epoch 2383/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7237 - val_acc: 0.6000\n",
      "Epoch 2384/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7286 - val_acc: 0.6000\n",
      "Epoch 2385/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7330 - val_acc: 0.6000\n",
      "Epoch 2386/10000\n",
      "96/96 [==============================] - 0s 337us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7374 - val_acc: 0.6000\n",
      "Epoch 2387/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7416 - val_acc: 0.6000\n",
      "Epoch 2388/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7442 - val_acc: 0.6000\n",
      "Epoch 2389/10000\n",
      "96/96 [==============================] - 0s 293us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7484 - val_acc: 0.6000\n",
      "Epoch 2390/10000\n",
      "96/96 [==============================] - 0s 300us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7511 - val_acc: 0.6000\n",
      "Epoch 2391/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7546 - val_acc: 0.6000\n",
      "Epoch 2392/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7580 - val_acc: 0.6000\n",
      "Epoch 2393/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7609 - val_acc: 0.6000\n",
      "Epoch 2394/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7631 - val_acc: 0.6000\n",
      "Epoch 2395/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7656 - val_acc: 0.6000\n",
      "Epoch 2396/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7664 - val_acc: 0.6000\n",
      "Epoch 2397/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7674 - val_acc: 0.6000\n",
      "Epoch 2398/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7130 - val_acc: 0.6000\n",
      "Epoch 2399/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7178 - val_acc: 0.6000\n",
      "Epoch 2400/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7237 - val_acc: 0.6000\n",
      "Epoch 2401/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7292 - val_acc: 0.6000\n",
      "Epoch 2402/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7339 - val_acc: 0.6000\n",
      "Epoch 2403/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7387 - val_acc: 0.6000\n",
      "Epoch 2404/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7426 - val_acc: 0.6000\n",
      "Epoch 2405/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7466 - val_acc: 0.6000\n",
      "Epoch 2406/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7497 - val_acc: 0.6000\n",
      "Epoch 2407/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7538 - val_acc: 0.6000\n",
      "Epoch 2408/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7559 - val_acc: 0.6000\n",
      "Epoch 2409/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7593 - val_acc: 0.6000\n",
      "Epoch 2410/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7611 - val_acc: 0.6000\n",
      "Epoch 2411/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7639 - val_acc: 0.6000\n",
      "Epoch 2412/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7661 - val_acc: 0.6000\n",
      "Epoch 2413/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7685 - val_acc: 0.6000\n",
      "Epoch 2414/10000\n",
      "96/96 [==============================] - 0s 296us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7695 - val_acc: 0.6000\n",
      "Epoch 2415/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7726 - val_acc: 0.6000\n",
      "Epoch 2416/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7347 - val_acc: 0.6000\n",
      "Epoch 2417/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7383 - val_acc: 0.6000\n",
      "Epoch 2418/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7420 - val_acc: 0.6000\n",
      "Epoch 2419/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7453 - val_acc: 0.6000\n",
      "Epoch 2420/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7479 - val_acc: 0.6000\n",
      "Epoch 2421/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7501 - val_acc: 0.6000\n",
      "Epoch 2422/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6875 - val_acc: 0.6000\n",
      "Epoch 2423/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6930 - val_acc: 0.6000\n",
      "Epoch 2424/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6980 - val_acc: 0.6000\n",
      "Epoch 2425/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7040 - val_acc: 0.6000\n",
      "Epoch 2426/10000\n",
      "96/96 [==============================] - 0s 194us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7090 - val_acc: 0.6000\n",
      "Epoch 2427/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7138 - val_acc: 0.6000\n",
      "Epoch 2428/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7186 - val_acc: 0.6000\n",
      "Epoch 2429/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7224 - val_acc: 0.6000\n",
      "Epoch 2430/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7262 - val_acc: 0.6000\n",
      "Epoch 2431/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7297 - val_acc: 0.6000\n",
      "Epoch 2432/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6711 - val_acc: 0.6000\n",
      "Epoch 2433/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6798 - val_acc: 0.6000\n",
      "Epoch 2434/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6870 - val_acc: 0.6000\n",
      "Epoch 2435/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6937 - val_acc: 0.6000\n",
      "Epoch 2436/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6994 - val_acc: 0.6000\n",
      "Epoch 2437/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7054 - val_acc: 0.6000\n",
      "Epoch 2438/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7114 - val_acc: 0.6000\n",
      "Epoch 2439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7182 - val_acc: 0.6000\n",
      "Epoch 2440/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7230 - val_acc: 0.6000\n",
      "Epoch 2441/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7272 - val_acc: 0.6000\n",
      "Epoch 2442/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7325 - val_acc: 0.6000\n",
      "Epoch 2443/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7368 - val_acc: 0.6000\n",
      "Epoch 2444/10000\n",
      "96/96 [==============================] - 0s 295us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7410 - val_acc: 0.6000\n",
      "Epoch 2445/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7432 - val_acc: 0.6000\n",
      "Epoch 2446/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7472 - val_acc: 0.6000\n",
      "Epoch 2447/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6747 - val_acc: 0.6000\n",
      "Epoch 2448/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6830 - val_acc: 0.6000\n",
      "Epoch 2449/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6903 - val_acc: 0.6000\n",
      "Epoch 2450/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6967 - val_acc: 0.6000\n",
      "Epoch 2451/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7032 - val_acc: 0.6000\n",
      "Epoch 2452/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7090 - val_acc: 0.6000\n",
      "Epoch 2453/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7159 - val_acc: 0.6000\n",
      "Epoch 2454/10000\n",
      "96/96 [==============================] - 0s 278us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7224 - val_acc: 0.6000\n",
      "Epoch 2455/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7274 - val_acc: 0.6000\n",
      "Epoch 2456/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7334 - val_acc: 0.6000\n",
      "Epoch 2457/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7378 - val_acc: 0.6000\n",
      "Epoch 2458/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7429 - val_acc: 0.6000\n",
      "Epoch 2459/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7481 - val_acc: 0.6000\n",
      "Epoch 2460/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7525 - val_acc: 0.6000\n",
      "Epoch 2461/10000\n",
      "96/96 [==============================] - 0s 292us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7542 - val_acc: 0.6000\n",
      "Epoch 2462/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7561 - val_acc: 0.6000\n",
      "Epoch 2463/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7588 - val_acc: 0.6000\n",
      "Epoch 2464/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7628 - val_acc: 0.6000\n",
      "Epoch 2465/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7662 - val_acc: 0.6000\n",
      "Epoch 2466/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7698 - val_acc: 0.6000\n",
      "Epoch 2467/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7717 - val_acc: 0.6000\n",
      "Epoch 2468/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7729 - val_acc: 0.6000\n",
      "Epoch 2469/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7752 - val_acc: 0.6000\n",
      "Epoch 2470/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6783 - val_acc: 0.6000\n",
      "Epoch 2471/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6889 - val_acc: 0.6000\n",
      "Epoch 2472/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6987 - val_acc: 0.6000\n",
      "Epoch 2473/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7088 - val_acc: 0.6000\n",
      "Epoch 2474/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7157 - val_acc: 0.6000\n",
      "Epoch 2475/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7226 - val_acc: 0.6000\n",
      "Epoch 2476/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7297 - val_acc: 0.6000\n",
      "Epoch 2477/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7369 - val_acc: 0.6000\n",
      "Epoch 2478/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7419 - val_acc: 0.6000\n",
      "Epoch 2479/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7473 - val_acc: 0.6000\n",
      "Epoch 2480/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7528 - val_acc: 0.6000\n",
      "Epoch 2481/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7577 - val_acc: 0.6000\n",
      "Epoch 2482/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7625 - val_acc: 0.6000\n",
      "Epoch 2483/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6939 - val_acc: 0.6000\n",
      "Epoch 2484/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7003 - val_acc: 0.6000\n",
      "Epoch 2485/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7070 - val_acc: 0.6000\n",
      "Epoch 2486/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7137 - val_acc: 0.6000\n",
      "Epoch 2487/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7209 - val_acc: 0.6000\n",
      "Epoch 2488/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7273 - val_acc: 0.6000\n",
      "Epoch 2489/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7335 - val_acc: 0.6000\n",
      "Epoch 2490/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7374 - val_acc: 0.6000\n",
      "Epoch 2491/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7420 - val_acc: 0.6000\n",
      "Epoch 2492/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7461 - val_acc: 0.6000\n",
      "Epoch 2493/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7507 - val_acc: 0.6000\n",
      "Epoch 2494/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7554 - val_acc: 0.6000\n",
      "Epoch 2495/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7591 - val_acc: 0.6000\n",
      "Epoch 2496/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7613 - val_acc: 0.6000\n",
      "Epoch 2497/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7645 - val_acc: 0.6000\n",
      "Epoch 2498/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7682 - val_acc: 0.6000\n",
      "Epoch 2499/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7697 - val_acc: 0.6000\n",
      "Epoch 2500/10000\n",
      "96/96 [==============================] - 0s 315us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7728 - val_acc: 0.6000\n",
      "Epoch 2501/10000\n",
      "96/96 [==============================] - 0s 331us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7758 - val_acc: 0.6000\n",
      "Epoch 2502/10000\n",
      "96/96 [==============================] - 0s 302us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7784 - val_acc: 0.6000\n",
      "Epoch 2503/10000\n",
      "96/96 [==============================] - 0s 315us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7806 - val_acc: 0.6000\n",
      "Epoch 2504/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7831 - val_acc: 0.6000\n",
      "Epoch 2505/10000\n",
      "96/96 [==============================] - 0s 295us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7834 - val_acc: 0.6000\n",
      "Epoch 2506/10000\n",
      "96/96 [==============================] - 0s 320us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7853 - val_acc: 0.6000\n",
      "Epoch 2507/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7865 - val_acc: 0.6000\n",
      "Epoch 2508/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7886 - val_acc: 0.6000\n",
      "Epoch 2509/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7899 - val_acc: 0.6000\n",
      "Epoch 2510/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7910 - val_acc: 0.6000\n",
      "Epoch 2511/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7913 - val_acc: 0.6000\n",
      "Epoch 2512/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7431 - val_acc: 0.6000\n",
      "Epoch 2513/10000\n",
      "96/96 [==============================] - 0s 294us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7452 - val_acc: 0.6000\n",
      "Epoch 2514/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7519 - val_acc: 0.6000\n",
      "Epoch 2515/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7574 - val_acc: 0.6000\n",
      "Epoch 2516/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7628 - val_acc: 0.6000\n",
      "Epoch 2517/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7680 - val_acc: 0.6000\n",
      "Epoch 2518/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7725 - val_acc: 0.6000\n",
      "Epoch 2519/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7766 - val_acc: 0.6000\n",
      "Epoch 2520/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7802 - val_acc: 0.6000\n",
      "Epoch 2521/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7837 - val_acc: 0.6000\n",
      "Epoch 2522/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7878 - val_acc: 0.6000\n",
      "Epoch 2523/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7914 - val_acc: 0.6000\n",
      "Epoch 2524/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7945 - val_acc: 0.6000\n",
      "Epoch 2525/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7970 - val_acc: 0.6000\n",
      "Epoch 2526/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7990 - val_acc: 0.6000\n",
      "Epoch 2527/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8017 - val_acc: 0.6000\n",
      "Epoch 2528/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8041 - val_acc: 0.6000\n",
      "Epoch 2529/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8048 - val_acc: 0.6000\n",
      "Epoch 2530/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8063 - val_acc: 0.6000\n",
      "Epoch 2531/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8087 - val_acc: 0.6000\n",
      "Epoch 2532/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8089 - val_acc: 0.6000\n",
      "Epoch 2533/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8100 - val_acc: 0.6000\n",
      "Epoch 2534/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8110 - val_acc: 0.6000\n",
      "Epoch 2535/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8127 - val_acc: 0.6000\n",
      "Epoch 2536/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8127 - val_acc: 0.6000\n",
      "Epoch 2537/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8140 - val_acc: 0.6000\n",
      "Epoch 2538/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8131 - val_acc: 0.6000\n",
      "Epoch 2539/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7727 - val_acc: 0.6000\n",
      "Epoch 2540/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7758 - val_acc: 0.6000\n",
      "Epoch 2541/10000\n",
      "96/96 [==============================] - 0s 205us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7115 - val_acc: 0.6000\n",
      "Epoch 2542/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7164 - val_acc: 0.6000\n",
      "Epoch 2543/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7221 - val_acc: 0.6000\n",
      "Epoch 2544/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7287 - val_acc: 0.6000\n",
      "Epoch 2545/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7343 - val_acc: 0.6000\n",
      "Epoch 2546/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7396 - val_acc: 0.6000\n",
      "Epoch 2547/10000\n",
      "96/96 [==============================] - 0s 201us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7446 - val_acc: 0.6000\n",
      "Epoch 2548/10000\n",
      "96/96 [==============================] - 0s 327us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7491 - val_acc: 0.6000\n",
      "Epoch 2549/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7531 - val_acc: 0.6000\n",
      "Epoch 2550/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7567 - val_acc: 0.6000\n",
      "Epoch 2551/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7608 - val_acc: 0.6000\n",
      "Epoch 2552/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7639 - val_acc: 0.6000\n",
      "Epoch 2553/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7678 - val_acc: 0.6000\n",
      "Epoch 2554/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7699 - val_acc: 0.6000\n",
      "Epoch 2555/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7731 - val_acc: 0.6000\n",
      "Epoch 2556/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7756 - val_acc: 0.6000\n",
      "Epoch 2557/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7774 - val_acc: 0.6000\n",
      "Epoch 2558/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7799 - val_acc: 0.6000\n",
      "Epoch 2559/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7063 - val_acc: 0.6000\n",
      "Epoch 2560/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7105 - val_acc: 0.6000\n",
      "Epoch 2561/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7172 - val_acc: 0.6000\n",
      "Epoch 2562/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7229 - val_acc: 0.6000\n",
      "Epoch 2563/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7292 - val_acc: 0.6000\n",
      "Epoch 2564/10000\n",
      "96/96 [==============================] - 0s 324us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7344 - val_acc: 0.6000\n",
      "Epoch 2565/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7393 - val_acc: 0.6000\n",
      "Epoch 2566/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7451 - val_acc: 0.6000\n",
      "Epoch 2567/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7488 - val_acc: 0.6000\n",
      "Epoch 2568/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7516 - val_acc: 0.6000\n",
      "Epoch 2569/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7563 - val_acc: 0.6000\n",
      "Epoch 2570/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7600 - val_acc: 0.6000\n",
      "Epoch 2571/10000\n",
      "96/96 [==============================] - 0s 184us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7637 - val_acc: 0.6000\n",
      "Epoch 2572/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7655 - val_acc: 0.6000\n",
      "Epoch 2573/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7693 - val_acc: 0.6000\n",
      "Epoch 2574/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7736 - val_acc: 0.6000\n",
      "Epoch 2575/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7770 - val_acc: 0.6000\n",
      "Epoch 2576/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7787 - val_acc: 0.6000\n",
      "Epoch 2577/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7805 - val_acc: 0.6000\n",
      "Epoch 2578/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7832 - val_acc: 0.6000\n",
      "Epoch 2579/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7850 - val_acc: 0.6000\n",
      "Epoch 2580/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7876 - val_acc: 0.6000\n",
      "Epoch 2581/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7904 - val_acc: 0.6000\n",
      "Epoch 2582/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7296 - val_acc: 0.6000\n",
      "Epoch 2583/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7362 - val_acc: 0.6000\n",
      "Epoch 2584/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7415 - val_acc: 0.6000\n",
      "Epoch 2585/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7481 - val_acc: 0.6000\n",
      "Epoch 2586/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7543 - val_acc: 0.6000\n",
      "Epoch 2587/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7608 - val_acc: 0.6000\n",
      "Epoch 2588/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7661 - val_acc: 0.6000\n",
      "Epoch 2589/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7700 - val_acc: 0.6000\n",
      "Epoch 2590/10000\n",
      "96/96 [==============================] - 0s 301us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7752 - val_acc: 0.6000\n",
      "Epoch 2591/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7780 - val_acc: 0.6000\n",
      "Epoch 2592/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7806 - val_acc: 0.6000\n",
      "Epoch 2593/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7859 - val_acc: 0.6000\n",
      "Epoch 2594/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7899 - val_acc: 0.6000\n",
      "Epoch 2595/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7944 - val_acc: 0.6000\n",
      "Epoch 2596/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7981 - val_acc: 0.6000\n",
      "Epoch 2597/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8016 - val_acc: 0.6000\n",
      "Epoch 2598/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8043 - val_acc: 0.6000\n",
      "Epoch 2599/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8082 - val_acc: 0.6000\n",
      "Epoch 2600/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7133 - val_acc: 0.6000\n",
      "Epoch 2601/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7237 - val_acc: 0.6000\n",
      "Epoch 2602/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7341 - val_acc: 0.6000\n",
      "Epoch 2603/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7431 - val_acc: 0.6000\n",
      "Epoch 2604/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7508 - val_acc: 0.6000\n",
      "Epoch 2605/10000\n",
      "96/96 [==============================] - 0s 334us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7583 - val_acc: 0.6000\n",
      "Epoch 2606/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7654 - val_acc: 0.6000\n",
      "Epoch 2607/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7725 - val_acc: 0.6000\n",
      "Epoch 2608/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7773 - val_acc: 0.6000\n",
      "Epoch 2609/10000\n",
      "96/96 [==============================] - 0s 299us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7826 - val_acc: 0.6000\n",
      "Epoch 2610/10000\n",
      "96/96 [==============================] - 0s 180us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7880 - val_acc: 0.6000\n",
      "Epoch 2611/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7924 - val_acc: 0.6000\n",
      "Epoch 2612/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7965 - val_acc: 0.6000\n",
      "Epoch 2613/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8006 - val_acc: 0.6000\n",
      "Epoch 2614/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8048 - val_acc: 0.6000\n",
      "Epoch 2615/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8088 - val_acc: 0.6000\n",
      "Epoch 2616/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7449 - val_acc: 0.6000\n",
      "Epoch 2617/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7508 - val_acc: 0.6000\n",
      "Epoch 2618/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7563 - val_acc: 0.6000\n",
      "Epoch 2619/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7608 - val_acc: 0.6000\n",
      "Epoch 2620/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7251 - val_acc: 0.6000\n",
      "Epoch 2621/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7309 - val_acc: 0.6000\n",
      "Epoch 2622/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7363 - val_acc: 0.6000\n",
      "Epoch 2623/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7417 - val_acc: 0.6000\n",
      "Epoch 2624/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7476 - val_acc: 0.6000\n",
      "Epoch 2625/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7529 - val_acc: 0.6000\n",
      "Epoch 2626/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7578 - val_acc: 0.6000\n",
      "Epoch 2627/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7617 - val_acc: 0.6000\n",
      "Epoch 2628/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7663 - val_acc: 0.6000\n",
      "Epoch 2629/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7709 - val_acc: 0.6000\n",
      "Epoch 2630/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7734 - val_acc: 0.6000\n",
      "Epoch 2631/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7764 - val_acc: 0.6000\n",
      "Epoch 2632/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7808 - val_acc: 0.6000\n",
      "Epoch 2633/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7840 - val_acc: 0.6000\n",
      "Epoch 2634/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7875 - val_acc: 0.6000\n",
      "Epoch 2635/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7906 - val_acc: 0.6000\n",
      "Epoch 2636/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7924 - val_acc: 0.6000\n",
      "Epoch 2637/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7179 - val_acc: 0.6000\n",
      "Epoch 2638/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7244 - val_acc: 0.6000\n",
      "Epoch 2639/10000\n",
      "96/96 [==============================] - 0s 176us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7274 - val_acc: 0.6000\n",
      "Epoch 2640/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7342 - val_acc: 0.6000\n",
      "Epoch 2641/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7416 - val_acc: 0.6000\n",
      "Epoch 2642/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7481 - val_acc: 0.6000\n",
      "Epoch 2643/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7541 - val_acc: 0.6000\n",
      "Epoch 2644/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7597 - val_acc: 0.6000\n",
      "Epoch 2645/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7660 - val_acc: 0.6000\n",
      "Epoch 2646/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7698 - val_acc: 0.6000\n",
      "Epoch 2647/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7758 - val_acc: 0.6000\n",
      "Epoch 2648/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7793 - val_acc: 0.6000\n",
      "Epoch 2649/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7824 - val_acc: 0.6000\n",
      "Epoch 2650/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7869 - val_acc: 0.6000\n",
      "Epoch 2651/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7904 - val_acc: 0.6000\n",
      "Epoch 2652/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7932 - val_acc: 0.6000\n",
      "Epoch 2653/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7947 - val_acc: 0.6000\n",
      "Epoch 2654/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7975 - val_acc: 0.6000\n",
      "Epoch 2655/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8010 - val_acc: 0.6000\n",
      "Epoch 2656/10000\n",
      "96/96 [==============================] - 0s 211us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8032 - val_acc: 0.6000\n",
      "Epoch 2657/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8061 - val_acc: 0.6000\n",
      "Epoch 2658/10000\n",
      "96/96 [==============================] - 0s 215us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8069 - val_acc: 0.6000\n",
      "Epoch 2659/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8078 - val_acc: 0.6000\n",
      "Epoch 2660/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8086 - val_acc: 0.6000\n",
      "Epoch 2661/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8109 - val_acc: 0.6000\n",
      "Epoch 2662/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8126 - val_acc: 0.6000\n",
      "Epoch 2663/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8154 - val_acc: 0.6000\n",
      "Epoch 2664/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8159 - val_acc: 0.6000\n",
      "Epoch 2665/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8186 - val_acc: 0.6000\n",
      "Epoch 2666/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8196 - val_acc: 0.6000\n",
      "Epoch 2667/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8216 - val_acc: 0.6000\n",
      "Epoch 2668/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8227 - val_acc: 0.6000\n",
      "Epoch 2669/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8242 - val_acc: 0.6000\n",
      "Epoch 2670/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8254 - val_acc: 0.6000\n",
      "Epoch 2671/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8269 - val_acc: 0.6000\n",
      "Epoch 2672/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8263 - val_acc: 0.6000\n",
      "Epoch 2673/10000\n",
      "96/96 [==============================] - 0s 197us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8276 - val_acc: 0.6000\n",
      "Epoch 2674/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8276 - val_acc: 0.6000\n",
      "Epoch 2675/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7686 - val_acc: 0.6000\n",
      "Epoch 2676/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7752 - val_acc: 0.6000\n",
      "Epoch 2677/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7800 - val_acc: 0.6000\n",
      "Epoch 2678/10000\n",
      "96/96 [==============================] - 0s 212us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7854 - val_acc: 0.6000\n",
      "Epoch 2679/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7899 - val_acc: 0.6000\n",
      "Epoch 2680/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7949 - val_acc: 0.6000\n",
      "Epoch 2681/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7990 - val_acc: 0.6000\n",
      "Epoch 2682/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8035 - val_acc: 0.6000\n",
      "Epoch 2683/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8075 - val_acc: 0.6000\n",
      "Epoch 2684/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8096 - val_acc: 0.6000\n",
      "Epoch 2685/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8119 - val_acc: 0.6000\n",
      "Epoch 2686/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8148 - val_acc: 0.6000\n",
      "Epoch 2687/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8173 - val_acc: 0.6000\n",
      "Epoch 2688/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8207 - val_acc: 0.6000\n",
      "Epoch 2689/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8216 - val_acc: 0.6000\n",
      "Epoch 2690/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8222 - val_acc: 0.6000\n",
      "Epoch 2691/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8243 - val_acc: 0.6000\n",
      "Epoch 2692/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8268 - val_acc: 0.6000\n",
      "Epoch 2693/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8297 - val_acc: 0.6000\n",
      "Epoch 2694/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8319 - val_acc: 0.6000\n",
      "Epoch 2695/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8338 - val_acc: 0.6000\n",
      "Epoch 2696/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8344 - val_acc: 0.6000\n",
      "Epoch 2697/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8355 - val_acc: 0.6000\n",
      "Epoch 2698/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7171 - val_acc: 0.6000\n",
      "Epoch 2699/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7252 - val_acc: 0.6000\n",
      "Epoch 2700/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7326 - val_acc: 0.6000\n",
      "Epoch 2701/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7405 - val_acc: 0.6000\n",
      "Epoch 2702/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7474 - val_acc: 0.6000\n",
      "Epoch 2703/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7550 - val_acc: 0.6000\n",
      "Epoch 2704/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7611 - val_acc: 0.6000\n",
      "Epoch 2705/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7676 - val_acc: 0.6000\n",
      "Epoch 2706/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7737 - val_acc: 0.6000\n",
      "Epoch 2707/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7792 - val_acc: 0.6000\n",
      "Epoch 2708/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7848 - val_acc: 0.6000\n",
      "Epoch 2709/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7895 - val_acc: 0.6000\n",
      "Epoch 2710/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7933 - val_acc: 0.6000\n",
      "Epoch 2711/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7978 - val_acc: 0.6000\n",
      "Epoch 2712/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8007 - val_acc: 0.6000\n",
      "Epoch 2713/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8047 - val_acc: 0.6000\n",
      "Epoch 2714/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8071 - val_acc: 0.6000\n",
      "Epoch 2715/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8112 - val_acc: 0.6000\n",
      "Epoch 2716/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8139 - val_acc: 0.6000\n",
      "Epoch 2717/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8166 - val_acc: 0.6000\n",
      "Epoch 2718/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8181 - val_acc: 0.6000\n",
      "Epoch 2719/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8215 - val_acc: 0.6000\n",
      "Epoch 2720/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8234 - val_acc: 0.6000\n",
      "Epoch 2721/10000\n",
      "96/96 [==============================] - 0s 189us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8259 - val_acc: 0.6000\n",
      "Epoch 2722/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8285 - val_acc: 0.6000\n",
      "Epoch 2723/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8305 - val_acc: 0.6000\n",
      "Epoch 2724/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8317 - val_acc: 0.6000\n",
      "Epoch 2725/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8328 - val_acc: 0.6000\n",
      "Epoch 2726/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8344 - val_acc: 0.6000\n",
      "Epoch 2727/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8340 - val_acc: 0.6000\n",
      "Epoch 2728/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8359 - val_acc: 0.6000\n",
      "Epoch 2729/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8361 - val_acc: 0.6000\n",
      "Epoch 2730/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8378 - val_acc: 0.6000\n",
      "Epoch 2731/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8390 - val_acc: 0.6000\n",
      "Epoch 2732/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8384 - val_acc: 0.6000\n",
      "Epoch 2733/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6681 - val_acc: 0.6000\n",
      "Epoch 2734/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6819 - val_acc: 0.6000\n",
      "Epoch 2735/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.6950 - val_acc: 0.6000\n",
      "Epoch 2736/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7077 - val_acc: 0.6000\n",
      "Epoch 2737/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7198 - val_acc: 0.6000\n",
      "Epoch 2738/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7306 - val_acc: 0.6000\n",
      "Epoch 2739/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7415 - val_acc: 0.6000\n",
      "Epoch 2740/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7507 - val_acc: 0.6000\n",
      "Epoch 2741/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7593 - val_acc: 0.6000\n",
      "Epoch 2742/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7678 - val_acc: 0.6000\n",
      "Epoch 2743/10000\n",
      "96/96 [==============================] - 0s 249us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7742 - val_acc: 0.6000\n",
      "Epoch 2744/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7810 - val_acc: 0.6000\n",
      "Epoch 2745/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7860 - val_acc: 0.6000\n",
      "Epoch 2746/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7913 - val_acc: 0.6000\n",
      "Epoch 2747/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7975 - val_acc: 0.6000\n",
      "Epoch 2748/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8030 - val_acc: 0.6000\n",
      "Epoch 2749/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8075 - val_acc: 0.6000\n",
      "Epoch 2750/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8123 - val_acc: 0.6000\n",
      "Epoch 2751/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8163 - val_acc: 0.6000\n",
      "Epoch 2752/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8203 - val_acc: 0.6000\n",
      "Epoch 2753/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8240 - val_acc: 0.6000\n",
      "Epoch 2754/10000\n",
      "96/96 [==============================] - 0s 205us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8255 - val_acc: 0.6000\n",
      "Epoch 2755/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8288 - val_acc: 0.6000\n",
      "Epoch 2756/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8307 - val_acc: 0.6000\n",
      "Epoch 2757/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8326 - val_acc: 0.6000\n",
      "Epoch 2758/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8341 - val_acc: 0.6000\n",
      "Epoch 2759/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8369 - val_acc: 0.6000\n",
      "Epoch 2760/10000\n",
      "96/96 [==============================] - 0s 257us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8379 - val_acc: 0.6000\n",
      "Epoch 2761/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7979 - val_acc: 0.6000\n",
      "Epoch 2762/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8003 - val_acc: 0.6000\n",
      "Epoch 2763/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8045 - val_acc: 0.6000\n",
      "Epoch 2764/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8077 - val_acc: 0.6000\n",
      "Epoch 2765/10000\n",
      "96/96 [==============================] - 0s 220us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8120 - val_acc: 0.6000\n",
      "Epoch 2766/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8141 - val_acc: 0.6000\n",
      "Epoch 2767/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8164 - val_acc: 0.6000\n",
      "Epoch 2768/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8198 - val_acc: 0.6000\n",
      "Epoch 2769/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8221 - val_acc: 0.6000\n",
      "Epoch 2770/10000\n",
      "96/96 [==============================] - 0s 216us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8244 - val_acc: 0.6000\n",
      "Epoch 2771/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8264 - val_acc: 0.6000\n",
      "Epoch 2772/10000\n",
      "96/96 [==============================] - 0s 208us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7654 - val_acc: 0.6000\n",
      "Epoch 2773/10000\n",
      "96/96 [==============================] - 0s 200us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7718 - val_acc: 0.6000\n",
      "Epoch 2774/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7781 - val_acc: 0.6000\n",
      "Epoch 2775/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7836 - val_acc: 0.6000\n",
      "Epoch 2776/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7900 - val_acc: 0.6000\n",
      "Epoch 2777/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7946 - val_acc: 0.6000\n",
      "Epoch 2778/10000\n",
      "96/96 [==============================] - 0s 210us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8005 - val_acc: 0.6000\n",
      "Epoch 2779/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8052 - val_acc: 0.6000\n",
      "Epoch 2780/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8096 - val_acc: 0.6000\n",
      "Epoch 2781/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8140 - val_acc: 0.6000\n",
      "Epoch 2782/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8179 - val_acc: 0.6000\n",
      "Epoch 2783/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8212 - val_acc: 0.6000\n",
      "Epoch 2784/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8240 - val_acc: 0.6000\n",
      "Epoch 2785/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8277 - val_acc: 0.6000\n",
      "Epoch 2786/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8295 - val_acc: 0.6000\n",
      "Epoch 2787/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 202us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8315 - val_acc: 0.6000\n",
      "Epoch 2788/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8351 - val_acc: 0.6000\n",
      "Epoch 2789/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8383 - val_acc: 0.6000\n",
      "Epoch 2790/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8408 - val_acc: 0.6000\n",
      "Epoch 2791/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8433 - val_acc: 0.6000\n",
      "Epoch 2792/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8462 - val_acc: 0.6000\n",
      "Epoch 2793/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8477 - val_acc: 0.6000\n",
      "Epoch 2794/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8493 - val_acc: 0.6000\n",
      "Epoch 2795/10000\n",
      "96/96 [==============================] - 0s 274us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8513 - val_acc: 0.6000\n",
      "Epoch 2796/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8527 - val_acc: 0.6000\n",
      "Epoch 2797/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8549 - val_acc: 0.6000\n",
      "Epoch 2798/10000\n",
      "96/96 [==============================] - 0s 219us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8559 - val_acc: 0.6000\n",
      "Epoch 2799/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8576 - val_acc: 0.6000\n",
      "Epoch 2800/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8570 - val_acc: 0.6000\n",
      "Epoch 2801/10000\n",
      "96/96 [==============================] - 0s 256us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8578 - val_acc: 0.6000\n",
      "Epoch 2802/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8591 - val_acc: 0.6000\n",
      "Epoch 2803/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8591 - val_acc: 0.6000\n",
      "Epoch 2804/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8607 - val_acc: 0.6000\n",
      "Epoch 2805/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8620 - val_acc: 0.6000\n",
      "Epoch 2806/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8620 - val_acc: 0.6000\n",
      "Epoch 2807/10000\n",
      "96/96 [==============================] - 0s 255us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8623 - val_acc: 0.6000\n",
      "Epoch 2808/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8631 - val_acc: 0.6000\n",
      "Epoch 2809/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8633 - val_acc: 0.6000\n",
      "Epoch 2810/10000\n",
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8651 - val_acc: 0.6000\n",
      "Epoch 2811/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8673 - val_acc: 0.6000\n",
      "Epoch 2812/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8647 - val_acc: 0.6000\n",
      "Epoch 2813/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7908 - val_acc: 0.6000\n",
      "Epoch 2814/10000\n",
      "96/96 [==============================] - 0s 276us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7976 - val_acc: 0.6000\n",
      "Epoch 2815/10000\n",
      "96/96 [==============================] - 0s 288us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8035 - val_acc: 0.6000\n",
      "Epoch 2816/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8088 - val_acc: 0.6000\n",
      "Epoch 2817/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8145 - val_acc: 0.6000\n",
      "Epoch 2818/10000\n",
      "96/96 [==============================] - 0s 258us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8191 - val_acc: 0.6000\n",
      "Epoch 2819/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8238 - val_acc: 0.6000\n",
      "Epoch 2820/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8285 - val_acc: 0.6000\n",
      "Epoch 2821/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8331 - val_acc: 0.6000\n",
      "Epoch 2822/10000\n",
      "96/96 [==============================] - 0s 209us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8358 - val_acc: 0.6000\n",
      "Epoch 2823/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8396 - val_acc: 0.6000\n",
      "Epoch 2824/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8412 - val_acc: 0.6000\n",
      "Epoch 2825/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8446 - val_acc: 0.6000\n",
      "Epoch 2826/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8480 - val_acc: 0.6000\n",
      "Epoch 2827/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8511 - val_acc: 0.6000\n",
      "Epoch 2828/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8533 - val_acc: 0.6000\n",
      "Epoch 2829/10000\n",
      "96/96 [==============================] - 0s 206us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8544 - val_acc: 0.6000\n",
      "Epoch 2830/10000\n",
      "96/96 [==============================] - 0s 189us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8561 - val_acc: 0.6000\n",
      "Epoch 2831/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8574 - val_acc: 0.6000\n",
      "Epoch 2832/10000\n",
      "96/96 [==============================] - 0s 193us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8597 - val_acc: 0.6000\n",
      "Epoch 2833/10000\n",
      "96/96 [==============================] - 0s 169us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8619 - val_acc: 0.6000\n",
      "Epoch 2834/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8639 - val_acc: 0.6000\n",
      "Epoch 2835/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8638 - val_acc: 0.6000\n",
      "Epoch 2836/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8653 - val_acc: 0.6000\n",
      "Epoch 2837/10000\n",
      "96/96 [==============================] - 0s 319us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8665 - val_acc: 0.6000\n",
      "Epoch 2838/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8674 - val_acc: 0.6000\n",
      "Epoch 2839/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8685 - val_acc: 0.6000\n",
      "Epoch 2840/10000\n",
      "96/96 [==============================] - 0s 207us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8690 - val_acc: 0.6000\n",
      "Epoch 2841/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8683 - val_acc: 0.6000\n",
      "Epoch 2842/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8697 - val_acc: 0.6000\n",
      "Epoch 2843/10000\n",
      "96/96 [==============================] - 0s 228us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8706 - val_acc: 0.6000\n",
      "Epoch 2844/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8707 - val_acc: 0.6000\n",
      "Epoch 2845/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8729 - val_acc: 0.6000\n",
      "Epoch 2846/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8728 - val_acc: 0.6000\n",
      "Epoch 2847/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8740 - val_acc: 0.6000\n",
      "Epoch 2848/10000\n",
      "96/96 [==============================] - 0s 271us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8746 - val_acc: 0.6000\n",
      "Epoch 2849/10000\n",
      "96/96 [==============================] - 0s 204us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8750 - val_acc: 0.6000\n",
      "Epoch 2850/10000\n",
      "96/96 [==============================] - 0s 298us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8351 - val_acc: 0.6000\n",
      "Epoch 2851/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8370 - val_acc: 0.6000\n",
      "Epoch 2852/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8401 - val_acc: 0.6000\n",
      "Epoch 2853/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8423 - val_acc: 0.6000\n",
      "Epoch 2854/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8451 - val_acc: 0.6000\n",
      "Epoch 2855/10000\n",
      "96/96 [==============================] - 0s 281us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8487 - val_acc: 0.6000\n",
      "Epoch 2856/10000\n",
      "96/96 [==============================] - 0s 323us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8517 - val_acc: 0.6000\n",
      "Epoch 2857/10000\n",
      "96/96 [==============================] - 0s 290us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8534 - val_acc: 0.6000\n",
      "Epoch 2858/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8555 - val_acc: 0.6000\n",
      "Epoch 2859/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8569 - val_acc: 0.6000\n",
      "Epoch 2860/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8577 - val_acc: 0.6000\n",
      "Epoch 2861/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8606 - val_acc: 0.6000\n",
      "Epoch 2862/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8629 - val_acc: 0.6000\n",
      "Epoch 2863/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8634 - val_acc: 0.6000\n",
      "Epoch 2864/10000\n",
      "96/96 [==============================] - 0s 287us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8644 - val_acc: 0.6000\n",
      "Epoch 2865/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8663 - val_acc: 0.6000\n",
      "Epoch 2866/10000\n",
      "96/96 [==============================] - 0s 286us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8679 - val_acc: 0.6000\n",
      "Epoch 2867/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8680 - val_acc: 0.6000\n",
      "Epoch 2868/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8691 - val_acc: 0.6000\n",
      "Epoch 2869/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8710 - val_acc: 0.6000\n",
      "Epoch 2870/10000\n",
      "96/96 [==============================] - 0s 314us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8713 - val_acc: 0.6000\n",
      "Epoch 2871/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8092 - val_acc: 0.6000\n",
      "Epoch 2872/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8149 - val_acc: 0.6000\n",
      "Epoch 2873/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8206 - val_acc: 0.6000\n",
      "Epoch 2874/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8264 - val_acc: 0.6000\n",
      "Epoch 2875/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8306 - val_acc: 0.6000\n",
      "Epoch 2876/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8357 - val_acc: 0.6000\n",
      "Epoch 2877/10000\n",
      "96/96 [==============================] - 0s 311us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8410 - val_acc: 0.6000\n",
      "Epoch 2878/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8441 - val_acc: 0.6000\n",
      "Epoch 2879/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8480 - val_acc: 0.6000\n",
      "Epoch 2880/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8516 - val_acc: 0.6000\n",
      "Epoch 2881/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8540 - val_acc: 0.6000\n",
      "Epoch 2882/10000\n",
      "96/96 [==============================] - 0s 235us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8566 - val_acc: 0.6000\n",
      "Epoch 2883/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8606 - val_acc: 0.6000\n",
      "Epoch 2884/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8637 - val_acc: 0.6000\n",
      "Epoch 2885/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8664 - val_acc: 0.6000\n",
      "Epoch 2886/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8689 - val_acc: 0.6000\n",
      "Epoch 2887/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8718 - val_acc: 0.6000\n",
      "Epoch 2888/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8722 - val_acc: 0.6000\n",
      "Epoch 2889/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8752 - val_acc: 0.6000\n",
      "Epoch 2890/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8762 - val_acc: 0.6000\n",
      "Epoch 2891/10000\n",
      "96/96 [==============================] - 0s 190us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8777 - val_acc: 0.6000\n",
      "Epoch 2892/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8776 - val_acc: 0.6000\n",
      "Epoch 2893/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8143 - val_acc: 0.6000\n",
      "Epoch 2894/10000\n",
      "96/96 [==============================] - 0s 213us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8203 - val_acc: 0.6000\n",
      "Epoch 2895/10000\n",
      "96/96 [==============================] - 0s 229us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7522 - val_acc: 0.6000\n",
      "Epoch 2896/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7599 - val_acc: 0.6000\n",
      "Epoch 2897/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7684 - val_acc: 0.6000\n",
      "Epoch 2898/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7763 - val_acc: 0.6000\n",
      "Epoch 2899/10000\n",
      "96/96 [==============================] - 0s 222us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7838 - val_acc: 0.6000\n",
      "Epoch 2900/10000\n",
      "96/96 [==============================] - 0s 262us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7908 - val_acc: 0.6000\n",
      "Epoch 2901/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7973 - val_acc: 0.6000\n",
      "Epoch 2902/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8028 - val_acc: 0.6000\n",
      "Epoch 2903/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8084 - val_acc: 0.6000\n",
      "Epoch 2904/10000\n",
      "96/96 [==============================] - 0s 270us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8144 - val_acc: 0.6000\n",
      "Epoch 2905/10000\n",
      "96/96 [==============================] - 0s 225us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8203 - val_acc: 0.6000\n",
      "Epoch 2906/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8253 - val_acc: 0.6000\n",
      "Epoch 2907/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8295 - val_acc: 0.6000\n",
      "Epoch 2908/10000\n",
      "96/96 [==============================] - 0s 306us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8340 - val_acc: 0.6000\n",
      "Epoch 2909/10000\n",
      "96/96 [==============================] - 0s 240us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8374 - val_acc: 0.6000\n",
      "Epoch 2910/10000\n",
      "96/96 [==============================] - 0s 259us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8418 - val_acc: 0.6000\n",
      "Epoch 2911/10000\n",
      "96/96 [==============================] - 0s 223us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8454 - val_acc: 0.6000\n",
      "Epoch 2912/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8485 - val_acc: 0.6000\n",
      "Epoch 2913/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8512 - val_acc: 0.6000\n",
      "Epoch 2914/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8536 - val_acc: 0.6000\n",
      "Epoch 2915/10000\n",
      "96/96 [==============================] - 0s 254us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8558 - val_acc: 0.6000\n",
      "Epoch 2916/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8590 - val_acc: 0.6000\n",
      "Epoch 2917/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8605 - val_acc: 0.6000\n",
      "Epoch 2918/10000\n",
      "96/96 [==============================] - 0s 251us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8628 - val_acc: 0.6000\n",
      "Epoch 2919/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8657 - val_acc: 0.6000\n",
      "Epoch 2920/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8668 - val_acc: 0.6000\n",
      "Epoch 2921/10000\n",
      "96/96 [==============================] - 0s 263us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8694 - val_acc: 0.6000\n",
      "Epoch 2922/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8700 - val_acc: 0.6000\n",
      "Epoch 2923/10000\n",
      "96/96 [==============================] - 0s 308us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8726 - val_acc: 0.6000\n",
      "Epoch 2924/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8732 - val_acc: 0.6000\n",
      "Epoch 2925/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8738 - val_acc: 0.6000\n",
      "Epoch 2926/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8744 - val_acc: 0.6000\n",
      "Epoch 2927/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8757 - val_acc: 0.6000\n",
      "Epoch 2928/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8784 - val_acc: 0.6000\n",
      "Epoch 2929/10000\n",
      "96/96 [==============================] - 0s 233us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8791 - val_acc: 0.6000\n",
      "Epoch 2930/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8808 - val_acc: 0.6000\n",
      "Epoch 2931/10000\n",
      "96/96 [==============================] - 0s 295us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8818 - val_acc: 0.6000\n",
      "Epoch 2932/10000\n",
      "96/96 [==============================] - 0s 226us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8837 - val_acc: 0.6000\n",
      "Epoch 2933/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8837 - val_acc: 0.6000\n",
      "Epoch 2934/10000\n",
      "96/96 [==============================] - 0s 264us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8845 - val_acc: 0.6000\n",
      "Epoch 2935/10000\n",
      "96/96 [==============================] - 0s 238us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8857 - val_acc: 0.6000\n",
      "Epoch 2936/10000\n",
      "96/96 [==============================] - 0s 239us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8867 - val_acc: 0.6000\n",
      "Epoch 2937/10000\n",
      "96/96 [==============================] - 0s 277us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8876 - val_acc: 0.6000\n",
      "Epoch 2938/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8889 - val_acc: 0.6000\n",
      "Epoch 2939/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8883 - val_acc: 0.6000\n",
      "Epoch 2940/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8901 - val_acc: 0.6000\n",
      "Epoch 2941/10000\n",
      "96/96 [==============================] - 0s 260us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8906 - val_acc: 0.6000\n",
      "Epoch 2942/10000\n",
      "96/96 [==============================] - 0s 242us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8913 - val_acc: 0.6000\n",
      "Epoch 2943/10000\n",
      "96/96 [==============================] - 0s 248us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8925 - val_acc: 0.6000\n",
      "Epoch 2944/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8936 - val_acc: 0.6000\n",
      "Epoch 2945/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8945 - val_acc: 0.6000\n",
      "Epoch 2946/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7834 - val_acc: 0.6000\n",
      "Epoch 2947/10000\n",
      "96/96 [==============================] - 0s 214us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7163 - val_acc: 0.6000\n",
      "Epoch 2948/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7247 - val_acc: 0.6000\n",
      "Epoch 2949/10000\n",
      "96/96 [==============================] - 0s 284us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7347 - val_acc: 0.6000\n",
      "Epoch 2950/10000\n",
      "96/96 [==============================] - 0s 205us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7445 - val_acc: 0.6000\n",
      "Epoch 2951/10000\n",
      "96/96 [==============================] - 0s 227us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7541 - val_acc: 0.6000\n",
      "Epoch 2952/10000\n",
      "96/96 [==============================] - 0s 261us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7623 - val_acc: 0.6000\n",
      "Epoch 2953/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7698 - val_acc: 0.6000\n",
      "Epoch 2954/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7774 - val_acc: 0.6000\n",
      "Epoch 2955/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7847 - val_acc: 0.6000\n",
      "Epoch 2956/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7923 - val_acc: 0.6000\n",
      "Epoch 2957/10000\n",
      "96/96 [==============================] - 0s 312us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7976 - val_acc: 0.6000\n",
      "Epoch 2958/10000\n",
      "96/96 [==============================] - 0s 218us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8038 - val_acc: 0.6000\n",
      "Epoch 2959/10000\n",
      "96/96 [==============================] - 0s 237us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8104 - val_acc: 0.6000\n",
      "Epoch 2960/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8156 - val_acc: 0.6000\n",
      "Epoch 2961/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 246us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8204 - val_acc: 0.6000\n",
      "Epoch 2962/10000\n",
      "96/96 [==============================] - 0s 224us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8241 - val_acc: 0.6000\n",
      "Epoch 2963/10000\n",
      "96/96 [==============================] - 0s 266us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8276 - val_acc: 0.6000\n",
      "Epoch 2964/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8275 - val_acc: 0.6000\n",
      "Epoch 2965/10000\n",
      "96/96 [==============================] - 0s 201us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8342 - val_acc: 0.6000\n",
      "Epoch 2966/10000\n",
      "96/96 [==============================] - 0s 268us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8402 - val_acc: 0.6000\n",
      "Epoch 2967/10000\n",
      "96/96 [==============================] - 0s 291us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8460 - val_acc: 0.6000\n",
      "Epoch 2968/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7531 - val_acc: 0.6000\n",
      "Epoch 2969/10000\n",
      "96/96 [==============================] - 0s 247us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7661 - val_acc: 0.6000\n",
      "Epoch 2970/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7777 - val_acc: 0.6000\n",
      "Epoch 2971/10000\n",
      "96/96 [==============================] - 0s 243us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7883 - val_acc: 0.6000\n",
      "Epoch 2972/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.7974 - val_acc: 0.6000\n",
      "Epoch 2973/10000\n",
      "96/96 [==============================] - 0s 250us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8070 - val_acc: 0.6000\n",
      "Epoch 2974/10000\n",
      "96/96 [==============================] - 0s 275us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8154 - val_acc: 0.6000\n",
      "Epoch 2975/10000\n",
      "96/96 [==============================] - 0s 236us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8223 - val_acc: 0.6000\n",
      "Epoch 2976/10000\n",
      "96/96 [==============================] - 0s 230us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8297 - val_acc: 0.6000\n",
      "Epoch 2977/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8361 - val_acc: 0.6000\n",
      "Epoch 2978/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8422 - val_acc: 0.6000\n",
      "Epoch 2979/10000\n",
      "96/96 [==============================] - 0s 330us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8469 - val_acc: 0.6000\n",
      "Epoch 2980/10000\n",
      "96/96 [==============================] - 0s 272us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8517 - val_acc: 0.6000\n",
      "Epoch 2981/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8569 - val_acc: 0.6000\n",
      "Epoch 2982/10000\n",
      "96/96 [==============================] - 0s 280us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8615 - val_acc: 0.6000\n",
      "Epoch 2983/10000\n",
      "96/96 [==============================] - 0s 283us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8659 - val_acc: 0.6000\n",
      "Epoch 2984/10000\n",
      "96/96 [==============================] - 0s 217us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8695 - val_acc: 0.6000\n",
      "Epoch 2985/10000\n",
      "96/96 [==============================] - 0s 234us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8719 - val_acc: 0.6000\n",
      "Epoch 2986/10000\n",
      "96/96 [==============================] - 0s 252us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8750 - val_acc: 0.6000\n",
      "Epoch 2987/10000\n",
      "96/96 [==============================] - 0s 253us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8768 - val_acc: 0.6000\n",
      "Epoch 2988/10000\n",
      "96/96 [==============================] - 0s 244us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8146 - val_acc: 0.6000\n",
      "Epoch 2989/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8221 - val_acc: 0.6000\n",
      "Epoch 2990/10000\n",
      "96/96 [==============================] - 0s 231us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8283 - val_acc: 0.6000\n",
      "Epoch 2991/10000\n",
      "96/96 [==============================] - 0s 269us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8328 - val_acc: 0.6000\n",
      "Epoch 2992/10000\n",
      "96/96 [==============================] - 0s 232us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8392 - val_acc: 0.6000\n",
      "Epoch 2993/10000\n",
      "96/96 [==============================] - 0s 282us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8451 - val_acc: 0.6000\n",
      "Epoch 2994/10000\n",
      "96/96 [==============================] - 0s 265us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8484 - val_acc: 0.6000\n",
      "Epoch 2995/10000\n",
      "96/96 [==============================] - 0s 221us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8521 - val_acc: 0.6000\n",
      "Epoch 2996/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8557 - val_acc: 0.6000\n",
      "Epoch 2997/10000\n",
      "96/96 [==============================] - 0s 279us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8601 - val_acc: 0.6000\n",
      "Epoch 2998/10000\n",
      "96/96 [==============================] - 0s 241us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8631 - val_acc: 0.6000\n",
      "Epoch 2999/10000\n",
      "96/96 [==============================] - 0s 273us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8671 - val_acc: 0.6000\n",
      "Epoch 3000/10000\n",
      "96/96 [==============================] - 0s 267us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8699 - val_acc: 0.6000\n",
      "Epoch 3001/10000\n",
      "96/96 [==============================] - 0s 245us/step - loss: 44.4018 - acc: 0.8438 - val_loss: 118.8735 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1215d6d30>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_point = keras.callbacks.ModelCheckpoint('./CheckPoint/extract_feature_model_checkpoint.hdf5', monitor='val_loss', verbose=0, \n",
    "                                              save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=3000, verbose=0,\n",
    "                              mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks = [check_point, early_stop]\n",
    "\n",
    "model.fit(np.array(list_vecOfNodeText), np.array(matrix_label), epochs=10000, batch_size=32,callbacks=callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.33114786e-12 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  3.46946554e-28 1.00000000e+00 0.00000000e+00 9.37452512e-21\n",
      "  1.00000000e+00 1.40506367e-18 0.00000000e+00 1.00000000e+00\n",
      "  9.96861794e-12 8.76475407e-22 1.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 8.10716689e-34 1.00000000e+00 0.00000000e+00\n",
      "  6.05765607e-15 2.52394626e-14 9.99994993e-01 1.00938615e-11\n",
      "  6.06451395e-18 6.68989100e-28 1.00000000e+00 1.25263636e-11\n",
      "  1.00000000e+00 1.24511246e-17 0.00000000e+00 1.00000000e+00\n",
      "  1.98601509e-12 9.59894837e-12 9.99995351e-01 2.30885821e-24\n",
      "  0.00000000e+00 5.96483349e-11 1.00000000e+00 7.74209313e-24\n",
      "  1.00000000e+00 1.32207814e-16 0.00000000e+00 1.00000000e+00\n",
      "  4.86026771e-21 1.89316386e-28 4.57437568e-14 1.00000000e+00]\n",
      " [9.99999642e-01 5.84066961e-14 0.00000000e+00 0.00000000e+00\n",
      "  4.85902016e-31 1.00000000e+00 1.06288576e-26 5.07410318e-29\n",
      "  9.99992847e-01 9.99999881e-01 1.28616445e-35 2.82683816e-13\n",
      "  9.99997497e-01 2.32392167e-26 8.80878615e-32 9.99998689e-01\n",
      "  5.06051671e-28 2.13413228e-12 1.00000000e+00 4.00192194e-25\n",
      "  0.00000000e+00 1.93572122e-31 9.99998808e-01 5.81266643e-13\n",
      "  1.06336885e-25 0.00000000e+00 9.99999881e-01 8.21238910e-12\n",
      "  2.72524661e-24 9.99993682e-01 1.00000000e+00 1.07982030e-13\n",
      "  2.81339876e-15 1.27788248e-16 9.99996901e-01 0.00000000e+00\n",
      "  9.99999642e-01 2.29948578e-26 1.22133564e-12 0.00000000e+00\n",
      "  9.99998331e-01 9.68146461e-13 0.00000000e+00 8.52337399e-27\n",
      "  1.00000000e+00 9.99998450e-01 1.38994550e-17 2.95075782e-22]\n",
      " [3.16275665e-14 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  1.05371890e-31 1.00000000e+00 0.00000000e+00 1.60911871e-27\n",
      "  1.00000000e+00 9.54724351e-22 0.00000000e+00 1.00000000e+00\n",
      "  1.42402107e-16 2.08735048e-33 1.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 4.28199564e-28 1.00000000e+00 0.00000000e+00\n",
      "  2.16188178e-26 9.99995112e-01 1.20480882e-12 3.27534072e-12\n",
      "  1.29033300e-18 2.59098769e-20 9.99995947e-01 2.99504206e-11\n",
      "  9.99999881e-01 2.93460971e-26 0.00000000e+00 1.00000000e+00\n",
      "  8.30227814e-14 4.13128533e-19 9.99994516e-01 8.95304495e-30\n",
      "  0.00000000e+00 8.33108437e-18 1.00000000e+00 1.16073353e-29\n",
      "  9.99995947e-01 2.97274060e-13 0.00000000e+00 1.00000000e+00\n",
      "  4.82415015e-16 2.89584054e-28 8.90480291e-25 1.00000000e+00]\n",
      " [1.00000000e+00 1.04564213e-24 0.00000000e+00 9.64622349e-24\n",
      "  2.36845135e-37 1.00000000e+00 9.99995708e-01 4.48540961e-11\n",
      "  1.11761309e-10 1.00000000e+00 0.00000000e+00 3.38956307e-19\n",
      "  1.00000000e+00 6.80221484e-29 0.00000000e+00 1.00000000e+00\n",
      "  1.56718141e-32 5.05346573e-17 8.38219424e-12 1.56579264e-20\n",
      "  1.00000000e+00 1.05774784e-13 2.87750071e-24 9.99993801e-01\n",
      "  1.28715547e-13 0.00000000e+00 9.99995947e-01 1.00000000e+00\n",
      "  0.00000000e+00 3.49135698e-14 0.00000000e+00 2.39718159e-16\n",
      "  1.00000000e+00 1.00897553e-27 4.30965519e-14 1.00000000e+00\n",
      "  2.62400785e-22 2.58816704e-24 1.00000000e+00 1.61909479e-18\n",
      "  8.32000015e-18 9.99999881e-01 0.00000000e+00 5.11808932e-24\n",
      "  1.00000000e+00 3.62630760e-24 6.30694227e-13 1.00000000e+00]\n",
      " [1.00000000e+00 5.46361957e-32 0.00000000e+00 2.09326832e-13\n",
      "  1.33668800e-16 9.99995947e-01 2.57369629e-11 6.09110862e-25\n",
      "  1.00000000e+00 9.99998331e-01 0.00000000e+00 1.27972979e-11\n",
      "  1.00000000e+00 1.74808823e-27 1.83413077e-31 1.00000000e+00\n",
      "  0.00000000e+00 2.04114527e-14 1.00000000e+00 9.04789734e-25\n",
      "  2.00309607e-16 1.00000000e+00 1.71215403e-11 7.80260925e-12\n",
      "  1.00000000e+00 0.00000000e+00 4.30619212e-12 1.00000000e+00\n",
      "  2.02413965e-19 2.35573849e-21 1.22695583e-23 1.00000000e+00\n",
      "  4.98124909e-11 1.61107499e-12 9.99993086e-01 2.58466380e-17\n",
      "  1.06084904e-17 2.67955812e-17 9.99999404e-01 9.99999762e-01\n",
      "  2.07581521e-12 5.82721441e-11 0.00000000e+00 2.91834581e-25\n",
      "  1.00000000e+00 1.00000000e+00 1.64842061e-21 5.29421472e-11]]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(np.array(list_vecOfNodeText))\n",
    "print(result[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
